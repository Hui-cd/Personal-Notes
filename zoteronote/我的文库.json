{
  "config": {
    "id": "36a3b0b5-bad0-4a04-b79b-441c7cef77db",
    "label": "BetterBibTeX JSON",
    "preferences": {
      "ascii": "",
      "asciiBibLaTeX": false,
      "asciiBibTeX": true,
      "autoAbbrev": false,
      "autoAbbrevStyle": "",
      "autoExport": "immediate",
      "autoExportDelay": 5,
      "autoExportIdleWait": 10,
      "autoExportPathReplaceDiacritics": false,
      "autoExportPathReplaceDirSep": "-",
      "autoExportPathReplaceSpace": " ",
      "automaticTags": true,
      "autoPinDelay": 0,
      "auxImport": false,
      "baseAttachmentPath": "",
      "biblatexExtendedDateFormat": true,
      "biblatexExtendedNameFormat": true,
      "biblatexExtractEprint": true,
      "bibtexEditionOrdinal": false,
      "bibtexParticleNoOp": false,
      "bibtexURL": "off",
      "cache": true,
      "cacheFlushInterval": 5,
      "charmap": "",
      "citeCommand": "cite",
      "citekeyCaseInsensitive": true,
      "citekeyFold": true,
      "citekeyFormat": "auth(n=0,m=1,creator=\"*\",initials=false).fold.lower + \"(\" + year + \")-\" + shorttitle(1,0).lower",
      "citekeySearch": true,
      "citekeyUnsafeChars": "\\\"#%'(),={}~",
      "csquotes": "",
      "DOIandURL": "both",
      "exportBibTeXStrings": "off",
      "exportBraceProtection": true,
      "exportTitleCase": true,
      "extraMergeCitekeys": false,
      "extraMergeCSL": false,
      "extraMergeTeX": false,
      "git": "config",
      "import": true,
      "importBibTeXStrings": true,
      "importCaseProtection": "as-needed",
      "importCitationKey": true,
      "importDetectURLs": true,
      "importExtra": true,
      "importJabRefAbbreviations": true,
      "importJabRefStrings": true,
      "importNoteToExtra": "",
      "importSentenceCase": "on+guess",
      "importSentenceCaseQuoted": true,
      "importUnknownTexCommand": "ignore",
      "itemObserverDelay": 5,
      "jabrefFormat": 0,
      "jieba": false,
      "keyConflictPolicy": "keep",
      "keyScope": "library",
      "kuroshiro": false,
      "language": "langid",
      "mapMath": "",
      "mapText": "",
      "packages": "",
      "parseParticles": true,
      "patchDates": "dateadded=dateAdded, date-added=dateAdded, datemodified=dateModified, date-modified=dateModified",
      "postscript": "",
      "postscriptOverride": "",
      "preferencesOverride": "",
      "qualityReport": false,
      "quickCopyEta": "",
      "quickCopyMode": "latex",
      "quickCopyOrgMode": "zotero",
      "quickCopyPandocBrackets": false,
      "quickCopySelectLink": "zotero",
      "rawImports": false,
      "rawLaTag": "#LaTeX",
      "relativeFilePaths": false,
      "retainCache": false,
      "separatorList": "and",
      "separatorNames": "and",
      "skipFields": "",
      "skipWords": "a,ab,aboard,about,above,across,after,against,al,along,amid,among,an,and,anti,around,as,at,before,behind,below,beneath,beside,besides,between,beyond,but,by,d,da,das,de,del,dell,dello,dei,degli,della,dell,delle,dem,den,der,des,despite,die,do,down,du,during,ein,eine,einem,einen,einer,eines,el,en,et,except,for,from,gli,i,il,in,inside,into,is,l,la,las,le,les,like,lo,los,near,nor,of,off,on,onto,or,over,past,per,plus,round,save,since,so,some,sur,than,the,through,to,toward,towards,un,una,unas,under,underneath,une,unlike,uno,unos,until,up,upon,versus,via,von,while,with,within,without,yet,zu,zum",
      "startupProgress": "popup",
      "strings": "",
      "stringsOverride": "",
      "verbatimFields": "url,doi,file,pdf,ids,eprint,/^verb[a-z]$/,groups,/^citeulike-linkout-[0-9]+$/, /^bdsk-url-[0-9]+$/, keywords",
      "warnBulkModify": 10,
      "warnTitleCased": false
    },
    "options": {
      "exportNotes": true,
      "exportFileData": false,
      "Items": true,
      "Preferences": true,
      "keepUpdated": false,
      "worker": true,
      "Normalize": false
    }
  },
  "version": {
    "zotero": "6.0.36",
    "bbt": "6.7.190"
  },
  "collections": {
    "49BIAB6R": {
      "key": "49BIAB6R",
      "parent": "",
      "name": "\u6570\u5b66",
      "collections": [],
      "items": [
        391
      ]
    },
    "SL42CSAH": {
      "key": "SL42CSAH",
      "parent": "",
      "name": "book",
      "collections": [],
      "items": [
        349,
        354,
        356,
        357,
        399,
        400,
        401
      ]
    },
    "NNUX237V": {
      "key": "NNUX237V",
      "parent": "",
      "name": "CV",
      "collections": [],
      "items": [
        14,
        389
      ]
    },
    "K84JTQUN": {
      "key": "K84JTQUN",
      "parent": "",
      "name": "DeepLearning",
      "collections": [],
      "items": [
        15,
        67,
        69,
        81,
        138,
        140,
        142,
        172,
        196,
        339,
        360,
        403,
        461,
        462,
        463,
        488,
        489,
        497,
        500,
        505,
        507,
        510,
        518,
        551,
        554,
        556,
        559,
        562,
        568,
        571,
        575,
        586,
        602
      ]
    },
    "73CE3P23": {
      "key": "73CE3P23",
      "parent": "",
      "name": "Network",
      "collections": [],
      "items": [
        514
      ]
    },
    "LIVRFJFF": {
      "key": "LIVRFJFF",
      "parent": "",
      "name": "NLP",
      "collections": [],
      "items": [
        15,
        358,
        516
      ]
    }
  },
  "items": [
    {
      "key": "LDI3WTJP",
      "version": 0,
      "itemType": "journalArticle",
      "title": "The Annotated Transformer",
      "language": "en",
      "libraryCatalog": "Zotero",
      "creators": [],
      "tags": [],
      "relations": {},
      "dateAdded": "2024-05-10T09:35:30Z",
      "dateModified": "2024-05-10T09:35:31Z",
      "uri": "http://zotero.org/users/10101446/items/LDI3WTJP",
      "itemID": 602,
      "attachments": [
        {
          "itemType": "attachment",
          "title": "The Annotated Transformer.pdf",
          "tags": [],
          "relations": {},
          "dateAdded": "2024-05-10T09:35:28Z",
          "dateModified": "2024-05-10T09:35:31Z",
          "uri": "http://zotero.org/users/10101446/items/FEVQQE43",
          "path": "C:\\Users\\gyh14\\Zotero\\storage\\FEVQQE43\\The Annotated Transformer.pdf",
          "select": "zotero://select/library/items/FEVQQE43"
        }
      ],
      "notes": [],
      "citationKey": "-annotated",
      "itemKey": "LDI3WTJP",
      "libraryID": 1,
      "select": "zotero://select/library/items/LDI3WTJP"
    },
    {
      "key": "R5FFXLA3",
      "version": 1375,
      "itemType": "preprint",
      "title": "Character-Level Language Modeling with Deeper Self-Attention",
      "abstractNote": "LSTMs and other RNN variants have shown strong performance on character-level language modeling. These models are typically trained using truncated backpropagation through time, and it is common to assume that their success stems from their ability to remember long-term contexts. In this paper, we show that a deep (64-layer) transformer model (Vaswani et al. 2017) with \ufb01xed context outperforms RNN variants by a large margin, achieving state of the art on two popular benchmarks: 1.13 bits per character on text8 and 1.06 on enwik8. To get good results at this depth, we show that it is important to add auxiliary losses, both at intermediate network layers and intermediate sequence positions.",
      "date": "2018-12-10",
      "language": "en",
      "libraryCatalog": "arXiv.org",
      "url": "http://arxiv.org/abs/1808.04444",
      "accessDate": "2024-04-26T06:18:01Z",
      "extra": "arXiv:1808.04444 [cs, stat]",
      "repository": "arXiv",
      "archiveID": "arXiv:1808.04444",
      "creators": [
        {
          "firstName": "Rami",
          "lastName": "Al-Rfou",
          "creatorType": "author"
        },
        {
          "firstName": "Dokook",
          "lastName": "Choe",
          "creatorType": "author"
        },
        {
          "firstName": "Noah",
          "lastName": "Constant",
          "creatorType": "author"
        },
        {
          "firstName": "Mandy",
          "lastName": "Guo",
          "creatorType": "author"
        },
        {
          "firstName": "Llion",
          "lastName": "Jones",
          "creatorType": "author"
        }
      ],
      "tags": [
        {
          "tag": "Computer Science - Computation and Language",
          "type": 1
        },
        {
          "tag": "Computer Science - Machine Learning",
          "type": 1
        },
        {
          "tag": "Computer Science - Artificial Intelligence",
          "type": 1
        },
        {
          "tag": "Statistics - Machine Learning",
          "type": 1
        }
      ],
      "relations": {},
      "dateAdded": "2024-04-26T06:18:01Z",
      "dateModified": "2024-04-26T06:18:02Z",
      "uri": "http://zotero.org/users/10101446/items/R5FFXLA3",
      "itemID": 568,
      "attachments": [
        {
          "itemType": "attachment",
          "title": "Al-Rfou \u7b49 - 2018 - Character-Level Language Modeling with Deeper Self.pdf",
          "tags": [],
          "relations": {},
          "dateAdded": "2024-04-26T06:17:56Z",
          "dateModified": "2024-04-26T06:18:02Z",
          "uri": "http://zotero.org/users/10101446/items/M7M5HVVV",
          "path": "C:\\Users\\gyh14\\Zotero\\storage\\M7M5HVVV\\Al-Rfou \u7b49 - 2018 - Character-Level Language Modeling with Deeper Self.pdf",
          "select": "zotero://select/library/items/M7M5HVVV"
        }
      ],
      "notes": [
        {
          "key": "5B5KQUP8",
          "version": 1375,
          "itemType": "note",
          "parentItem": "R5FFXLA3",
          "note": "Comment: 8 pages, 7 figures",
          "tags": [],
          "relations": {},
          "dateAdded": "2024-04-26T06:18:01Z",
          "dateModified": "2024-04-26T06:18:01Z",
          "uri": "http://zotero.org/users/10101446/items/5B5KQUP8"
        }
      ],
      "citationKey": "al-rfou2018-characterlevel",
      "itemKey": "R5FFXLA3",
      "libraryID": 1,
      "select": "zotero://select/library/items/R5FFXLA3"
    },
    {
      "key": "YTPK5T86",
      "version": 1121,
      "itemType": "conferencePaper",
      "title": "Social LSTM: Human Trajectory Prediction in Crowded Spaces",
      "abstractNote": "Pedestrians follow different trajectories to avoid obstacles and accommodate fellow pedestrians. Any autonomous vehicle navigating such a scene should be able to foresee the future positions of pedestrians and accordingly adjust its path to avoid collisions. This problem of trajectory prediction can be viewed as a sequence generation task, where we are interested in predicting the future trajectory of people based on their past positions. Following the recent success of Recurrent Neural Network (RNN) models for sequence prediction tasks, we propose an LSTM model which can learn general human movement and predict their future trajectories. This is in contrast to traditional approaches which use hand-crafted functions such as Social forces. We demonstrate the performance of our method on several public datasets. Our model outperforms state-of-the-art methods on some of these datasets . We also analyze the trajectories predicted by our model to demonstrate the motion behaviour learned by our model.",
      "date": "6/2016",
      "language": "en",
      "shortTitle": "Social LSTM",
      "libraryCatalog": "DOI.org (Crossref)",
      "url": "http://ieeexplore.ieee.org/document/7780479/",
      "accessDate": "2024-03-17T14:53:12Z",
      "place": "Las Vegas, NV, USA",
      "publisher": "IEEE",
      "ISBN": "978-1-4673-8851-1",
      "pages": "961-971",
      "proceedingsTitle": "2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)",
      "conferenceName": "2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)",
      "DOI": "10.1109/CVPR.2016.110",
      "creators": [
        {
          "firstName": "Alexandre",
          "lastName": "Alahi",
          "creatorType": "author"
        },
        {
          "firstName": "Kratarth",
          "lastName": "Goel",
          "creatorType": "author"
        },
        {
          "firstName": "Vignesh",
          "lastName": "Ramanathan",
          "creatorType": "author"
        },
        {
          "firstName": "Alexandre",
          "lastName": "Robicquet",
          "creatorType": "author"
        },
        {
          "firstName": "Li",
          "lastName": "Fei-Fei",
          "creatorType": "author"
        },
        {
          "firstName": "Silvio",
          "lastName": "Savarese",
          "creatorType": "author"
        }
      ],
      "tags": [],
      "relations": {},
      "dateAdded": "2024-03-17T14:53:12Z",
      "dateModified": "2024-03-17T14:53:17Z",
      "uri": "http://zotero.org/users/10101446/items/YTPK5T86",
      "itemID": 497,
      "attachments": [
        {
          "itemType": "attachment",
          "title": "Alahi \u7b49 - 2016 - Social LSTM Human Trajectory Prediction in Crowde.pdf",
          "tags": [],
          "relations": {},
          "dateAdded": "2024-03-17T14:53:07Z",
          "dateModified": "2024-03-17T14:53:17Z",
          "uri": "http://zotero.org/users/10101446/items/6A95U4PM",
          "path": "C:\\Users\\gyh14\\Zotero\\storage\\6A95U4PM\\Alahi \u7b49 - 2016 - Social LSTM Human Trajectory Prediction in Crowde.pdf",
          "select": "zotero://select/library/items/6A95U4PM"
        },
        {
          "itemType": "attachment",
          "title": "Social LSTM: Human Trajectory Prediction in Crowded Spaces",
          "tags": [],
          "relations": {},
          "dateAdded": "2024-03-17T14:53:17Z",
          "dateModified": "2024-03-17T14:53:17Z",
          "uri": "http://zotero.org/users/10101446/items/BU3HV5B4",
          "path": "C:\\Users\\gyh14\\Zotero\\storage\\BU3HV5B4\\alahi2016.pdf.pdf",
          "select": "zotero://select/library/items/BU3HV5B4"
        }
      ],
      "notes": [],
      "citationKey": "alahi2016-social",
      "itemKey": "YTPK5T86",
      "libraryID": 1,
      "select": "zotero://select/library/items/YTPK5T86"
    },
    {
      "key": "2QDAQPG3",
      "version": 122,
      "itemType": "attachment",
      "title": "cvpr20_san.pdf",
      "linkMode": "imported_file",
      "contentType": "application/pdf",
      "charset": "",
      "filename": "cvpr20_san.pdf",
      "tags": [],
      "collections": [
        "NNUX237V"
      ],
      "relations": {},
      "dateAdded": "2023-03-17T03:25:06Z",
      "dateModified": "2023-03-17T03:25:06Z",
      "uri": "http://zotero.org/users/10101446/items/2QDAQPG3",
      "itemID": 14,
      "localPath": "C:\\Users\\gyh14\\Zotero\\storage\\2QDAQPG3\\cvpr20_san.pdf",
      "defaultPath": "files/14/cvpr20_san.pdf",
      "itemKey": "2QDAQPG3",
      "libraryID": 1,
      "select": "zotero://select/library/items/2QDAQPG3"
    },
    {
      "key": "NAL7GLN3",
      "version": 589,
      "itemType": "attachment",
      "title": "Computer Organization and Architecture 10th - William Stallings.pdf",
      "linkMode": "imported_file",
      "contentType": "application/pdf",
      "charset": "",
      "filename": "Computer Organization and Architecture 10th - William Stallings.pdf",
      "tags": [],
      "collections": [
        "SL42CSAH"
      ],
      "relations": {},
      "dateAdded": "2023-11-13T05:09:48Z",
      "dateModified": "2023-11-13T05:09:48Z",
      "uri": "http://zotero.org/users/10101446/items/NAL7GLN3",
      "itemID": 349,
      "localPath": "C:\\Users\\gyh14\\Zotero\\storage\\NAL7GLN3\\Computer Organization and Architecture 10th - William Stallings.pdf",
      "defaultPath": "files/349/Computer Organization and Architecture 10th - William Stallings.pdf",
      "itemKey": "NAL7GLN3",
      "libraryID": 1,
      "select": "zotero://select/library/items/NAL7GLN3"
    },
    {
      "key": "FGINIMVC",
      "version": 629,
      "itemType": "attachment",
      "title": "Java\u6838\u5fc3\u6280\u672f \u5377I (\u7b2c8\u7248).pdf",
      "linkMode": "imported_file",
      "contentType": "application/pdf",
      "charset": "",
      "filename": "Java\u6838\u5fc3\u6280\u672f \u5377I (\u7b2c8\u7248).pdf",
      "tags": [],
      "collections": [
        "SL42CSAH"
      ],
      "relations": {},
      "dateAdded": "2023-11-18T03:56:44Z",
      "dateModified": "2023-11-18T03:56:44Z",
      "uri": "http://zotero.org/users/10101446/items/FGINIMVC",
      "itemID": 354,
      "localPath": "C:\\Users\\gyh14\\Zotero\\storage\\FGINIMVC\\Java\u6838\u5fc3\u6280\u672f \u5377I (\u7b2c8\u7248).pdf",
      "defaultPath": "files/354/Java\u6838\u5fc3\u6280\u672f \u5377I (\u7b2c8\u7248).pdf",
      "itemKey": "FGINIMVC",
      "libraryID": 1,
      "select": "zotero://select/library/items/FGINIMVC"
    },
    {
      "key": "ZA3XJUJQ",
      "version": 654,
      "itemType": "attachment",
      "title": "[Effective C++\u4e2d\u6587\u7248\u6539\u5584\u7a0b\u5e8f\u4e0e\u8bbe\u8ba1\u768455\u4e2a\u5177\u4f53\u505a\u6cd5].(\u7f8e)Scott_Meyers.pdf",
      "linkMode": "imported_file",
      "contentType": "application/pdf",
      "charset": "",
      "filename": "[Effective C++\u4e2d\u6587\u7248\u6539\u5584\u7a0b\u5e8f\u4e0e\u8bbe\u8ba1\u768455\u4e2a\u5177\u4f53\u505a\u6cd5].(\u7f8e)Scott_Meyers.pdf",
      "tags": [],
      "collections": [
        "SL42CSAH"
      ],
      "relations": {},
      "dateAdded": "2023-12-06T09:23:26Z",
      "dateModified": "2023-12-06T09:23:26Z",
      "uri": "http://zotero.org/users/10101446/items/ZA3XJUJQ",
      "itemID": 357,
      "localPath": "C:\\Users\\gyh14\\Zotero\\storage\\ZA3XJUJQ\\[Effective C++\u4e2d\u6587\u7248\u6539\u5584\u7a0b\u5e8f\u4e0e\u8bbe\u8ba1\u768455\u4e2a\u5177\u4f53\u505a\u6cd5].(\u7f8e)Scott_Meyers.pdf",
      "defaultPath": "files/357/[Effective C++\u4e2d\u6587\u7248\u6539\u5584\u7a0b\u5e8f\u4e0e\u8bbe\u8ba1\u768455\u4e2a\u5177\u4f53\u505a\u6cd5].(\u7f8e)Scott_Meyers.pdf",
      "itemKey": "ZA3XJUJQ",
      "libraryID": 1,
      "select": "zotero://select/library/items/ZA3XJUJQ"
    },
    {
      "key": "A4RNCTUB",
      "version": 663,
      "itemType": "attachment",
      "title": "gemini_1_report.pdf",
      "linkMode": "imported_file",
      "contentType": "application/pdf",
      "charset": "",
      "filename": "gemini_1_report.pdf",
      "tags": [],
      "collections": [
        "LIVRFJFF"
      ],
      "relations": {},
      "dateAdded": "2023-12-07T09:55:17Z",
      "dateModified": "2023-12-07T09:55:17Z",
      "uri": "http://zotero.org/users/10101446/items/A4RNCTUB",
      "itemID": 358,
      "localPath": "C:\\Users\\gyh14\\Zotero\\storage\\A4RNCTUB\\gemini_1_report.pdf",
      "defaultPath": "files/358/gemini_1_report.pdf",
      "itemKey": "A4RNCTUB",
      "libraryID": 1,
      "select": "zotero://select/library/items/A4RNCTUB"
    },
    {
      "key": "6TC89527",
      "version": 748,
      "itemType": "attachment",
      "title": "\u5de5\u7a0b\u6570\u5b66\u7ebf\u6027\u4ee3\u6570\u7b2c\u516d\u7248.pdf",
      "linkMode": "imported_file",
      "contentType": "application/pdf",
      "charset": "",
      "filename": "\u5de5\u7a0b\u6570\u5b66\u7ebf\u6027\u4ee3\u6570\u7b2c\u516d\u7248.pdf",
      "tags": [],
      "collections": [
        "49BIAB6R"
      ],
      "relations": {},
      "dateAdded": "2023-12-22T10:16:22Z",
      "dateModified": "2023-12-22T10:16:22Z",
      "uri": "http://zotero.org/users/10101446/items/6TC89527",
      "itemID": 391,
      "localPath": "C:\\Users\\gyh14\\Zotero\\storage\\6TC89527\\\u5de5\u7a0b\u6570\u5b66\u7ebf\u6027\u4ee3\u6570\u7b2c\u516d\u7248.pdf",
      "defaultPath": "files/391/\u5de5\u7a0b\u6570\u5b66\u7ebf\u6027\u4ee3\u6570\u7b2c\u516d\u7248.pdf",
      "itemKey": "6TC89527",
      "libraryID": 1,
      "select": "zotero://select/library/items/6TC89527"
    },
    {
      "key": "E2BYSVNY",
      "version": 761,
      "itemType": "attachment",
      "title": "\u8ba1\u7b97\u673a\u7ec4\u6210\u539f\u7406.pdf",
      "linkMode": "imported_file",
      "contentType": "application/pdf",
      "charset": "",
      "filename": "\u8ba1\u7b97\u673a\u7ec4\u6210\u539f\u7406.pdf",
      "tags": [],
      "collections": [
        "SL42CSAH"
      ],
      "relations": {},
      "dateAdded": "2023-12-28T08:17:09Z",
      "dateModified": "2023-12-28T08:17:09Z",
      "uri": "http://zotero.org/users/10101446/items/E2BYSVNY",
      "itemID": 399,
      "localPath": "C:\\Users\\gyh14\\Zotero\\storage\\E2BYSVNY\\\u8ba1\u7b97\u673a\u7ec4\u6210\u539f\u7406.pdf",
      "defaultPath": "files/399/\u8ba1\u7b97\u673a\u7ec4\u6210\u539f\u7406.pdf",
      "itemKey": "E2BYSVNY",
      "libraryID": 1,
      "select": "zotero://select/library/items/E2BYSVNY"
    },
    {
      "key": "ISFAHXLB",
      "version": 764,
      "itemType": "attachment",
      "title": "2023\u738b\u9053\u8ba1\u7b97\u673a\u7ec4\u6210\u539f\u7406\u8003\u7814\u590d\u4e60\u6307\u5bfc\u3010\u9ad8\u6e05\u65e0\u6c34\u5370\u3011.pdf",
      "linkMode": "imported_file",
      "contentType": "application/pdf",
      "charset": "",
      "filename": "2023\u738b\u9053\u8ba1\u7b97\u673a\u7ec4\u6210\u539f\u7406\u8003\u7814\u590d\u4e60\u6307\u5bfc\u3010\u9ad8\u6e05\u65e0\u6c34\u5370\u3011.pdf",
      "tags": [],
      "collections": [
        "SL42CSAH"
      ],
      "relations": {},
      "dateAdded": "2023-12-29T12:39:28Z",
      "dateModified": "2023-12-29T12:39:28Z",
      "uri": "http://zotero.org/users/10101446/items/ISFAHXLB",
      "itemID": 400,
      "localPath": "C:\\Users\\gyh14\\Zotero\\storage\\ISFAHXLB\\2023\u738b\u9053\u8ba1\u7b97\u673a\u7ec4\u6210\u539f\u7406\u8003\u7814\u590d\u4e60\u6307\u5bfc\u3010\u9ad8\u6e05\u65e0\u6c34\u5370\u3011.pdf",
      "defaultPath": "files/400/2023\u738b\u9053\u8ba1\u7b97\u673a\u7ec4\u6210\u539f\u7406\u8003\u7814\u590d\u4e60\u6307\u5bfc\u3010\u9ad8\u6e05\u65e0\u6c34\u5370\u3011.pdf",
      "itemKey": "ISFAHXLB",
      "libraryID": 1,
      "select": "zotero://select/library/items/ISFAHXLB"
    },
    {
      "key": "XJ8SHQRF",
      "version": 803,
      "itemType": "attachment",
      "title": "\u7b97\u6cd5\u5bfc\u8bba_\u539f\u4e66\u7b2c3\u7248_CHS.pdf",
      "linkMode": "imported_file",
      "contentType": "application/pdf",
      "charset": "",
      "filename": "\u7b97\u6cd5\u5bfc\u8bba_\u539f\u4e66\u7b2c3\u7248_CHS.pdf",
      "tags": [],
      "collections": [
        "SL42CSAH"
      ],
      "relations": {},
      "dateAdded": "2024-01-30T03:19:05Z",
      "dateModified": "2024-01-30T03:19:05Z",
      "uri": "http://zotero.org/users/10101446/items/XJ8SHQRF",
      "itemID": 401,
      "localPath": "C:\\Users\\gyh14\\Zotero\\storage\\XJ8SHQRF\\\u7b97\u6cd5\u5bfc\u8bba_\u539f\u4e66\u7b2c3\u7248_CHS.pdf",
      "defaultPath": "files/401/\u7b97\u6cd5\u5bfc\u8bba_\u539f\u4e66\u7b2c3\u7248_CHS.pdf",
      "itemKey": "XJ8SHQRF",
      "libraryID": 1,
      "select": "zotero://select/library/items/XJ8SHQRF"
    },
    {
      "key": "WVZPU5NR",
      "version": 667,
      "itemType": "preprint",
      "title": "Training a Helpful and Harmless Assistant with Reinforcement Learning from Human Feedback",
      "abstractNote": "We apply preference modeling and reinforcement learning from human feedback (RLHF) to \ufb01netune language models to act as helpful and harmless assistants. We \ufb01nd this alignment training improves performance on almost all NLP evaluations, and is fully compatible with training for specialized skills such as python coding and summarization. We explore an iterated online mode of training, where preference models and RL policies are updated on a weekly cadence with fresh human feedback data, ef\ufb01ciently improving our datasets and models. Finally, we investigate the robustness of RLHF training, and identify a roughly linear relation between the RL reward and the square root of the KL divergence between the policy and its initialization. Alongside our main results, we perform peripheral analyses on calibration, competing objectives, and the use of OOD detection, compare our models with human writers, and provide samples from our models using prompts appearing in recent related work.",
      "date": "2022-04-12",
      "language": "en",
      "libraryCatalog": "arXiv.org",
      "url": "http://arxiv.org/abs/2204.05862",
      "accessDate": "2023-12-16T06:43:39Z",
      "extra": "arXiv:2204.05862 [cs]",
      "repository": "arXiv",
      "archiveID": "arXiv:2204.05862",
      "creators": [
        {
          "firstName": "Yuntao",
          "lastName": "Bai",
          "creatorType": "author"
        },
        {
          "firstName": "Andy",
          "lastName": "Jones",
          "creatorType": "author"
        },
        {
          "firstName": "Kamal",
          "lastName": "Ndousse",
          "creatorType": "author"
        },
        {
          "firstName": "Amanda",
          "lastName": "Askell",
          "creatorType": "author"
        },
        {
          "firstName": "Anna",
          "lastName": "Chen",
          "creatorType": "author"
        },
        {
          "firstName": "Nova",
          "lastName": "DasSarma",
          "creatorType": "author"
        },
        {
          "firstName": "Dawn",
          "lastName": "Drain",
          "creatorType": "author"
        },
        {
          "firstName": "Stanislav",
          "lastName": "Fort",
          "creatorType": "author"
        },
        {
          "firstName": "Deep",
          "lastName": "Ganguli",
          "creatorType": "author"
        },
        {
          "firstName": "Tom",
          "lastName": "Henighan",
          "creatorType": "author"
        },
        {
          "firstName": "Nicholas",
          "lastName": "Joseph",
          "creatorType": "author"
        },
        {
          "firstName": "Saurav",
          "lastName": "Kadavath",
          "creatorType": "author"
        },
        {
          "firstName": "Jackson",
          "lastName": "Kernion",
          "creatorType": "author"
        },
        {
          "firstName": "Tom",
          "lastName": "Conerly",
          "creatorType": "author"
        },
        {
          "firstName": "Sheer",
          "lastName": "El-Showk",
          "creatorType": "author"
        },
        {
          "firstName": "Nelson",
          "lastName": "Elhage",
          "creatorType": "author"
        },
        {
          "firstName": "Zac",
          "lastName": "Hatfield-Dodds",
          "creatorType": "author"
        },
        {
          "firstName": "Danny",
          "lastName": "Hernandez",
          "creatorType": "author"
        },
        {
          "firstName": "Tristan",
          "lastName": "Hume",
          "creatorType": "author"
        },
        {
          "firstName": "Scott",
          "lastName": "Johnston",
          "creatorType": "author"
        },
        {
          "firstName": "Shauna",
          "lastName": "Kravec",
          "creatorType": "author"
        },
        {
          "firstName": "Liane",
          "lastName": "Lovitt",
          "creatorType": "author"
        },
        {
          "firstName": "Neel",
          "lastName": "Nanda",
          "creatorType": "author"
        },
        {
          "firstName": "Catherine",
          "lastName": "Olsson",
          "creatorType": "author"
        },
        {
          "firstName": "Dario",
          "lastName": "Amodei",
          "creatorType": "author"
        },
        {
          "firstName": "Tom",
          "lastName": "Brown",
          "creatorType": "author"
        },
        {
          "firstName": "Jack",
          "lastName": "Clark",
          "creatorType": "author"
        },
        {
          "firstName": "Sam",
          "lastName": "McCandlish",
          "creatorType": "author"
        },
        {
          "firstName": "Chris",
          "lastName": "Olah",
          "creatorType": "author"
        },
        {
          "firstName": "Ben",
          "lastName": "Mann",
          "creatorType": "author"
        },
        {
          "firstName": "Jared",
          "lastName": "Kaplan",
          "creatorType": "author"
        }
      ],
      "tags": [
        {
          "tag": "Computer Science - Computation and Language",
          "type": 1
        },
        {
          "tag": "Computer Science - Machine Learning",
          "type": 1
        }
      ],
      "relations": {},
      "dateAdded": "2023-12-16T06:43:39Z",
      "dateModified": "2023-12-16T06:43:40Z",
      "uri": "http://zotero.org/users/10101446/items/WVZPU5NR",
      "itemID": 360,
      "attachments": [
        {
          "itemType": "attachment",
          "title": "Bai \u7b49 - 2022 - Training a Helpful and Harmless Assistant with Rei.pdf",
          "tags": [],
          "relations": {},
          "dateAdded": "2023-12-16T06:43:33Z",
          "dateModified": "2023-12-16T06:43:40Z",
          "uri": "http://zotero.org/users/10101446/items/FA5R5JQT",
          "path": "C:\\Users\\gyh14\\Zotero\\storage\\FA5R5JQT\\Bai \u7b49 - 2022 - Training a Helpful and Harmless Assistant with Rei.pdf",
          "select": "zotero://select/library/items/FA5R5JQT"
        }
      ],
      "notes": [
        {
          "key": "YJTS9C3B",
          "version": 667,
          "itemType": "note",
          "parentItem": "WVZPU5NR",
          "note": "Comment: Data available at https://github.com/anthropics/hh-rlhf",
          "tags": [],
          "relations": {},
          "dateAdded": "2023-12-16T06:43:39Z",
          "dateModified": "2023-12-16T06:43:39Z",
          "uri": "http://zotero.org/users/10101446/items/YJTS9C3B"
        }
      ],
      "citationKey": "bai2022-training",
      "itemKey": "WVZPU5NR",
      "libraryID": 1,
      "select": "zotero://select/library/items/WVZPU5NR"
    },
    {
      "key": "367NAVYW",
      "version": 1179,
      "itemType": "preprint",
      "title": "COIG-CQIA: Quality is All You Need for Chinese Instruction Fine-tuning",
      "abstractNote": "Recently, there have been significant advancements in large language models (LLMs), particularly focused on the English language. These advancements have enabled these LLMs to understand and execute complex instructions with unprecedented accuracy and fluency. However, despite these advancements, there remains a noticeable gap in the development of Chinese instruction tuning. The unique linguistic features and cultural depth of the Chinese language pose challenges for instruction tuning tasks. Existing datasets are either derived from English-centric LLMs or are ill-suited for aligning with the interaction patterns of real-world Chinese users. To bridge this gap, we introduce COIG-CQIA, a high-quality Chinese instruction tuning dataset. Our aim is to build a diverse, wide-ranging instruction-tuning dataset to better align model behavior with human interactions. To this end, we collect a high-quality human-written corpus from various sources on the Chinese Internet, including Q&A communities, Wikis, examinations, and existing NLP datasets. This corpus was rigorously filtered and carefully processed to form the COIG-CQIA dataset. Furthermore, we train models of various scales on different subsets of CQIA, following in-depth evaluation and analyses. The findings from our experiments offer valuable insights for selecting and developing Chinese instruction-tuning datasets. We also find that models trained on CQIA-Subset achieve competitive results in human assessment as well as knowledge and security benchmarks. Data are available at https://huggingface.co/datasets/m-a-p/COIG-CQIA",
      "date": "2024-03-26",
      "language": "en",
      "shortTitle": "COIG-CQIA",
      "libraryCatalog": "arXiv.org",
      "url": "http://arxiv.org/abs/2403.18058",
      "accessDate": "2024-04-04T11:08:18Z",
      "extra": "arXiv:2403.18058 [cs]",
      "repository": "arXiv",
      "archiveID": "arXiv:2403.18058",
      "creators": [
        {
          "firstName": "Yuelin",
          "lastName": "Bai",
          "creatorType": "author"
        },
        {
          "firstName": "Xinrun",
          "lastName": "Du",
          "creatorType": "author"
        },
        {
          "firstName": "Yiming",
          "lastName": "Liang",
          "creatorType": "author"
        },
        {
          "firstName": "Yonggang",
          "lastName": "Jin",
          "creatorType": "author"
        },
        {
          "firstName": "Ziqiang",
          "lastName": "Liu",
          "creatorType": "author"
        },
        {
          "firstName": "Junting",
          "lastName": "Zhou",
          "creatorType": "author"
        },
        {
          "firstName": "Tianyu",
          "lastName": "Zheng",
          "creatorType": "author"
        },
        {
          "firstName": "Xincheng",
          "lastName": "Zhang",
          "creatorType": "author"
        },
        {
          "firstName": "Nuo",
          "lastName": "Ma",
          "creatorType": "author"
        },
        {
          "firstName": "Zekun",
          "lastName": "Wang",
          "creatorType": "author"
        },
        {
          "firstName": "Ruibin",
          "lastName": "Yuan",
          "creatorType": "author"
        },
        {
          "firstName": "Haihong",
          "lastName": "Wu",
          "creatorType": "author"
        },
        {
          "firstName": "Hongquan",
          "lastName": "Lin",
          "creatorType": "author"
        },
        {
          "firstName": "Wenhao",
          "lastName": "Huang",
          "creatorType": "author"
        },
        {
          "firstName": "Jiajun",
          "lastName": "Zhang",
          "creatorType": "author"
        },
        {
          "firstName": "Wenhu",
          "lastName": "Chen",
          "creatorType": "author"
        },
        {
          "firstName": "Chenghua",
          "lastName": "Lin",
          "creatorType": "author"
        },
        {
          "firstName": "Jie",
          "lastName": "Fu",
          "creatorType": "author"
        },
        {
          "firstName": "Min",
          "lastName": "Yang",
          "creatorType": "author"
        },
        {
          "firstName": "Shiwen",
          "lastName": "Ni",
          "creatorType": "author"
        },
        {
          "firstName": "Ge",
          "lastName": "Zhang",
          "creatorType": "author"
        }
      ],
      "tags": [
        {
          "tag": "Computer Science - Computation and Language",
          "type": 1
        },
        {
          "tag": "Computer Science - Artificial Intelligence",
          "type": 1
        }
      ],
      "relations": {},
      "dateAdded": "2024-04-04T11:08:18Z",
      "dateModified": "2024-04-04T11:08:18Z",
      "uri": "http://zotero.org/users/10101446/items/367NAVYW",
      "itemID": 516,
      "attachments": [
        {
          "itemType": "attachment",
          "title": "Bai \u7b49 - 2024 - COIG-CQIA Quality is All You Need for Chinese Ins.pdf",
          "tags": [],
          "relations": {},
          "dateAdded": "2024-04-04T11:08:12Z",
          "dateModified": "2024-04-04T11:08:19Z",
          "uri": "http://zotero.org/users/10101446/items/SIEUJ2RZ",
          "path": "C:\\Users\\gyh14\\Zotero\\storage\\SIEUJ2RZ\\Bai \u7b49 - 2024 - COIG-CQIA Quality is All You Need for Chinese Ins.pdf",
          "select": "zotero://select/library/items/SIEUJ2RZ"
        }
      ],
      "notes": [],
      "citationKey": "bai2024-coigcqia",
      "itemKey": "367NAVYW",
      "libraryID": 1,
      "select": "zotero://select/library/items/367NAVYW"
    },
    {
      "key": "2U4KY52L",
      "version": 1090,
      "itemType": "preprint",
      "title": "Robust Graph Representation Learning via Predictive Coding",
      "abstractNote": "Predictive coding is a message-passing framework initially developed to model information processing in the brain, and now also topic of research in machine learning due to some interesting properties. One of such properties is the natural ability of generative models to learn robust representations thanks to their peculiar credit assignment rule, that allows neural activities to converge to a solution before updating the synaptic weights. Graph neural networks are also message-passing models, which have recently shown outstanding results in diverse types of tasks in machine learning, providing interdisciplinary state-of-the-art performance on structured data. However, they are vulnerable to imperceptible adversarial attacks, and un\ufb01t for out-of-distribution generalization. In this work, we address this by building models that have the same structure of popular graph neural network architectures, but rely on the message-passing rule of predictive coding. Through an extensive set of experiments, we show that the proposed models are (i) comparable to standard ones in terms of performance in both inductive and transductive tasks, (ii) better calibrated, and (iii) robust against multiple kinds of adversarial attacks.",
      "date": "2022-12-08",
      "language": "en",
      "libraryCatalog": "arXiv.org",
      "url": "http://arxiv.org/abs/2212.04656",
      "accessDate": "2024-02-29T06:47:36Z",
      "extra": "arXiv:2212.04656 [cs]",
      "repository": "arXiv",
      "archiveID": "arXiv:2212.04656",
      "creators": [
        {
          "firstName": "Billy",
          "lastName": "Byiringiro",
          "creatorType": "author"
        },
        {
          "firstName": "Tommaso",
          "lastName": "Salvatori",
          "creatorType": "author"
        },
        {
          "firstName": "Thomas",
          "lastName": "Lukasiewicz",
          "creatorType": "author"
        }
      ],
      "tags": [
        {
          "tag": "Computer Science - Machine Learning",
          "type": 1
        }
      ],
      "relations": {},
      "dateAdded": "2024-02-29T06:47:36Z",
      "dateModified": "2024-02-29T06:47:36Z",
      "uri": "http://zotero.org/users/10101446/items/2U4KY52L",
      "itemID": 488,
      "attachments": [
        {
          "itemType": "attachment",
          "title": "Byiringiro \u7b49 - 2022 - Robust Graph Representation Learning via Predictiv.pdf",
          "tags": [],
          "relations": {},
          "dateAdded": "2024-02-29T06:47:30Z",
          "dateModified": "2024-02-29T06:47:37Z",
          "uri": "http://zotero.org/users/10101446/items/9JTQJ55G",
          "path": "C:\\Users\\gyh14\\Zotero\\storage\\9JTQJ55G\\Byiringiro \u7b49 - 2022 - Robust Graph Representation Learning via Predictiv.pdf",
          "select": "zotero://select/library/items/9JTQJ55G"
        }
      ],
      "notes": [
        {
          "key": "4SMJPCVL",
          "version": 1090,
          "itemType": "note",
          "parentItem": "2U4KY52L",
          "note": "Comment: 27 Pages, 31 Figures",
          "tags": [],
          "relations": {},
          "dateAdded": "2024-02-29T06:47:36Z",
          "dateModified": "2024-02-29T06:47:36Z",
          "uri": "http://zotero.org/users/10101446/items/4SMJPCVL"
        }
      ],
      "citationKey": "byiringiro2022-robust",
      "itemKey": "2U4KY52L",
      "libraryID": 1,
      "select": "zotero://select/library/items/2U4KY52L"
    },
    {
      "key": "9N89MYXQ",
      "version": 1122,
      "itemType": "conferencePaper",
      "title": "Unsupervised Sampling Promoting for Stochastic Human Trajectory Prediction",
      "abstractNote": "The indeterminate nature of human motion requires trajectory prediction systems to use a probabilistic model to formulate the multi-modality phenomenon and infer a finite set of future trajectories. However, the inference processes of most existing methods rely on Monte Carlo random sampling, which is insufficient to cover the realistic paths with finite samples, due to the long tail effect of the predicted distribution. To promote the sampling process of stochastic prediction, we propose a novel method, called BOsampler , to adaptively mine potential paths with Bayesian optimization in an unsupervised manner, as a sequential design strategy in which new prediction is dependent on the previously drawn samples. Specifically, we model the trajectory sampling as a Gaussian process and construct an acquisition function to measure the potential sampling value. This acquisition function applies the original distribution as prior and encourages exploring paths in the long-tail region. This sampling method can be integrated with existing stochastic predictive models without retraining. Experimental results on various baseline methods demonstrate the effectiveness of our method. The source code is released in this link.",
      "date": "6/2023",
      "language": "en",
      "libraryCatalog": "DOI.org (Crossref)",
      "url": "https://ieeexplore.ieee.org/document/10203123/",
      "accessDate": "2024-03-17T14:53:24Z",
      "place": "Vancouver, BC, Canada",
      "publisher": "IEEE",
      "ISBN": "9798350301298",
      "pages": "17874-17884",
      "proceedingsTitle": "2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)",
      "conferenceName": "2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)",
      "DOI": "10.1109/CVPR52729.2023.01714",
      "creators": [
        {
          "firstName": "Guangyi",
          "lastName": "Chen",
          "creatorType": "author"
        },
        {
          "firstName": "Zhenhao",
          "lastName": "Chen",
          "creatorType": "author"
        },
        {
          "firstName": "Shunxing",
          "lastName": "Fan",
          "creatorType": "author"
        },
        {
          "firstName": "Kun",
          "lastName": "Zhang",
          "creatorType": "author"
        }
      ],
      "tags": [],
      "relations": {},
      "dateAdded": "2024-03-17T14:53:24Z",
      "dateModified": "2024-03-17T14:53:31Z",
      "uri": "http://zotero.org/users/10101446/items/9N89MYXQ",
      "itemID": 500,
      "attachments": [
        {
          "itemType": "attachment",
          "title": "Chen \u7b49 - 2023 - Unsupervised Sampling Promoting for Stochastic Hum.pdf",
          "tags": [],
          "relations": {},
          "dateAdded": "2024-03-17T14:53:19Z",
          "dateModified": "2024-03-17T14:53:31Z",
          "uri": "http://zotero.org/users/10101446/items/2XS9G975",
          "path": "C:\\Users\\gyh14\\Zotero\\storage\\2XS9G975\\Chen \u7b49 - 2023 - Unsupervised Sampling Promoting for Stochastic Hum.pdf",
          "select": "zotero://select/library/items/2XS9G975"
        }
      ],
      "notes": [],
      "citationKey": "chen2023-unsupervised",
      "itemKey": "9N89MYXQ",
      "libraryID": 1,
      "select": "zotero://select/library/items/9N89MYXQ"
    },
    {
      "key": "9XR6FCUM",
      "version": 815,
      "itemType": "preprint",
      "title": "Deconstructing Denoising Diffusion Models for Self-Supervised Learning",
      "abstractNote": "In this study, we examine the representation learning abilities of Denoising Diffusion Models (DDM) that were originally purposed for image generation. Our philosophy is to deconstruct a DDM, gradually transforming it into a classical Denoising Autoencoder (DAE). This deconstructive procedure allows us to explore how various components of modern DDMs influence self-supervised representation learning. We observe that only a very few modern components are critical for learning good representations, while many others are nonessential. Our study ultimately arrives at an approach that is highly simplified and to a large extent resembles a classical DAE. We hope our study will rekindle interest in a family of classical methods within the realm of modern self-supervised learning.",
      "date": "2024-01-25",
      "language": "en",
      "libraryCatalog": "arXiv.org",
      "url": "http://arxiv.org/abs/2401.14404",
      "accessDate": "2024-02-05T16:06:26Z",
      "extra": "arXiv:2401.14404 [cs]",
      "repository": "arXiv",
      "archiveID": "arXiv:2401.14404",
      "creators": [
        {
          "firstName": "Xinlei",
          "lastName": "Chen",
          "creatorType": "author"
        },
        {
          "firstName": "Zhuang",
          "lastName": "Liu",
          "creatorType": "author"
        },
        {
          "firstName": "Saining",
          "lastName": "Xie",
          "creatorType": "author"
        },
        {
          "firstName": "Kaiming",
          "lastName": "He",
          "creatorType": "author"
        }
      ],
      "tags": [
        {
          "tag": "Computer Science - Computer Vision and Pattern Recognition",
          "type": 1
        },
        {
          "tag": "Computer Science - Machine Learning",
          "type": 1
        }
      ],
      "relations": {},
      "dateAdded": "2024-02-05T16:06:26Z",
      "dateModified": "2024-02-05T16:06:27Z",
      "uri": "http://zotero.org/users/10101446/items/9XR6FCUM",
      "itemID": 403,
      "attachments": [
        {
          "itemType": "attachment",
          "title": "Chen \u7b49 - 2024 - Deconstructing Denoising Diffusion Models for Self.pdf",
          "tags": [],
          "relations": {},
          "dateAdded": "2024-02-05T16:06:20Z",
          "dateModified": "2024-02-05T16:06:27Z",
          "uri": "http://zotero.org/users/10101446/items/QR5R49NP",
          "path": "C:\\Users\\gyh14\\Zotero\\storage\\QR5R49NP\\Chen \u7b49 - 2024 - Deconstructing Denoising Diffusion Models for Self.pdf",
          "select": "zotero://select/library/items/QR5R49NP"
        }
      ],
      "notes": [
        {
          "key": "3WIVFGXQ",
          "version": 815,
          "itemType": "note",
          "parentItem": "9XR6FCUM",
          "note": "Comment: Technical report, 10 pages",
          "tags": [],
          "relations": {},
          "dateAdded": "2024-02-05T16:06:26Z",
          "dateModified": "2024-02-05T16:06:26Z",
          "uri": "http://zotero.org/users/10101446/items/3WIVFGXQ"
        }
      ],
      "citationKey": "chen2024-deconstructing",
      "itemKey": "9XR6FCUM",
      "libraryID": 1,
      "select": "zotero://select/library/items/9XR6FCUM"
    },
    {
      "key": "65XF6I4U",
      "version": 1366,
      "itemType": "preprint",
      "title": "Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context",
      "abstractNote": "Transformers have a potential of learning longer-term dependency, but are limited by a \ufb01xed-length context in the setting of language modeling. We propose a novel neural architecture Transformer-XL that enables learning dependency beyond a \ufb01xed length without disrupting temporal coherence. It consists of a segment-level recurrence mechanism and a novel positional encoding scheme. Our method not only enables capturing longer-term dependency, but also resolves the context fragmentation problem. As a result, TransformerXL learns dependency that is 80% longer than RNNs and 450% longer than vanilla Transformers, achieves better performance on both short and long sequences, and is up to 1,800+ times faster than vanilla Transformers during evaluation. Notably, we improve the state-ofthe-art results of bpc/perplexity to 0.99 on enwiki8, 1.08 on text8, 18.3 on WikiText-103, 21.8 on One Billion Word, and 54.5 on Penn Treebank (without \ufb01netuning). When trained only on WikiText-103, Transformer-XL manages to generate reasonably coherent, novel text articles with thousands of tokens. Our code, pretrained models, and hyperparameters are available in both Tensor\ufb02ow and PyTorch1.",
      "date": "2019-06-02",
      "language": "en",
      "shortTitle": "Transformer-XL",
      "libraryCatalog": "arXiv.org",
      "url": "http://arxiv.org/abs/1901.02860",
      "accessDate": "2024-04-26T05:59:33Z",
      "extra": "arXiv:1901.02860 [cs, stat]",
      "repository": "arXiv",
      "archiveID": "arXiv:1901.02860",
      "creators": [
        {
          "firstName": "Zihang",
          "lastName": "Dai",
          "creatorType": "author"
        },
        {
          "firstName": "Zhilin",
          "lastName": "Yang",
          "creatorType": "author"
        },
        {
          "firstName": "Yiming",
          "lastName": "Yang",
          "creatorType": "author"
        },
        {
          "firstName": "Jaime",
          "lastName": "Carbonell",
          "creatorType": "author"
        },
        {
          "firstName": "Quoc V.",
          "lastName": "Le",
          "creatorType": "author"
        },
        {
          "firstName": "Ruslan",
          "lastName": "Salakhutdinov",
          "creatorType": "author"
        }
      ],
      "tags": [
        {
          "tag": "Computer Science - Computation and Language",
          "type": 1
        },
        {
          "tag": "Computer Science - Machine Learning",
          "type": 1
        },
        {
          "tag": "Statistics - Machine Learning",
          "type": 1
        }
      ],
      "relations": {},
      "dateAdded": "2024-04-26T05:59:33Z",
      "dateModified": "2024-04-26T05:59:33Z",
      "uri": "http://zotero.org/users/10101446/items/65XF6I4U",
      "itemID": 562,
      "attachments": [
        {
          "itemType": "attachment",
          "title": "Dai \u7b49 - 2019 - Transformer-XL Attentive Language Models Beyond a.pdf",
          "tags": [],
          "relations": {},
          "dateAdded": "2024-04-26T05:59:27Z",
          "dateModified": "2024-04-26T05:59:34Z",
          "uri": "http://zotero.org/users/10101446/items/JPQFKMCR",
          "path": "C:\\Users\\gyh14\\Zotero\\storage\\JPQFKMCR\\Dai \u7b49 - 2019 - Transformer-XL Attentive Language Models Beyond a.pdf",
          "select": "zotero://select/library/items/JPQFKMCR"
        }
      ],
      "notes": [
        {
          "key": "H8G59BCT",
          "version": 1366,
          "itemType": "note",
          "parentItem": "65XF6I4U",
          "note": "Comment: ACL 2019 long paper. Code and pretrained models are available at https://github.com/kimiyoung/transformer-xl",
          "tags": [],
          "relations": {},
          "dateAdded": "2024-04-26T05:59:33Z",
          "dateModified": "2024-04-26T05:59:33Z",
          "uri": "http://zotero.org/users/10101446/items/H8G59BCT"
        }
      ],
      "citationKey": "dai2019-transformerxl",
      "itemKey": "65XF6I4U",
      "libraryID": 1,
      "select": "zotero://select/library/items/65XF6I4U"
    },
    {
      "key": "YEFMDXK5",
      "version": 501,
      "itemType": "preprint",
      "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding",
      "abstractNote": "We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models (Peters et al., 2018a; Radford et al., 2018), BERT is designed to pretrain deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be \ufb01netuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial taskspeci\ufb01c architecture modi\ufb01cations.",
      "date": "2019-05-24",
      "language": "en",
      "shortTitle": "BERT",
      "libraryCatalog": "arXiv.org",
      "url": "http://arxiv.org/abs/1810.04805",
      "accessDate": "2023-09-25T03:28:37Z",
      "extra": "arXiv:1810.04805 [cs]",
      "repository": "arXiv",
      "archiveID": "arXiv:1810.04805",
      "creators": [
        {
          "firstName": "Jacob",
          "lastName": "Devlin",
          "creatorType": "author"
        },
        {
          "firstName": "Ming-Wei",
          "lastName": "Chang",
          "creatorType": "author"
        },
        {
          "firstName": "Kenton",
          "lastName": "Lee",
          "creatorType": "author"
        },
        {
          "firstName": "Kristina",
          "lastName": "Toutanova",
          "creatorType": "author"
        }
      ],
      "tags": [
        {
          "tag": "Computer Science - Computation and Language",
          "type": 1
        }
      ],
      "relations": {},
      "dateAdded": "2023-09-25T03:28:37Z",
      "dateModified": "2023-10-02T03:18:28Z",
      "uri": "http://zotero.org/users/10101446/items/YEFMDXK5",
      "itemID": 196,
      "attachments": [
        {
          "itemType": "attachment",
          "title": "Devlin \u7b49 - 2019 - BERT Pre-training of Deep Bidirectional Transform.pdf",
          "tags": [],
          "relations": {},
          "dateAdded": "2023-09-25T03:28:32Z",
          "dateModified": "2023-09-25T03:28:37Z",
          "uri": "http://zotero.org/users/10101446/items/K4FEEV4X",
          "path": "C:\\Users\\gyh14\\Zotero\\storage\\K4FEEV4X\\Devlin \u7b49 - 2019 - BERT Pre-training of Deep Bidirectional Transform.pdf",
          "select": "zotero://select/library/items/K4FEEV4X"
        }
      ],
      "notes": [],
      "citationKey": "devlin2019-bert",
      "itemKey": "YEFMDXK5",
      "libraryID": 1,
      "select": "zotero://select/library/items/YEFMDXK5"
    },
    {
      "key": "PP7AZZUT",
      "version": 1003,
      "itemType": "preprint",
      "title": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale",
      "abstractNote": "While the Transformer architecture has become the de-facto standard for natural language processing tasks, its applications to computer vision remain limited. In vision, attention is either applied in conjunction with convolutional networks, or used to replace certain components of convolutional networks while keeping their overall structure in place. We show that this reliance on CNNs is not necessary and a pure transformer applied directly to sequences of image patches can perform very well on image classification tasks. When pre-trained on large amounts of data and transferred to multiple mid-sized or small image recognition benchmarks (ImageNet, CIFAR-100, VTAB, etc.), Vision Transformer (ViT) attains excellent results compared to state-of-the-art convolutional networks while requiring substantially fewer computational resources to train.",
      "date": "2021-06-03",
      "language": "en",
      "shortTitle": "An Image is Worth 16x16 Words",
      "libraryCatalog": "arXiv.org",
      "url": "http://arxiv.org/abs/2010.11929",
      "accessDate": "2024-02-22T07:03:21Z",
      "extra": "arXiv:2010.11929 [cs]",
      "repository": "arXiv",
      "archiveID": "arXiv:2010.11929",
      "creators": [
        {
          "firstName": "Alexey",
          "lastName": "Dosovitskiy",
          "creatorType": "author"
        },
        {
          "firstName": "Lucas",
          "lastName": "Beyer",
          "creatorType": "author"
        },
        {
          "firstName": "Alexander",
          "lastName": "Kolesnikov",
          "creatorType": "author"
        },
        {
          "firstName": "Dirk",
          "lastName": "Weissenborn",
          "creatorType": "author"
        },
        {
          "firstName": "Xiaohua",
          "lastName": "Zhai",
          "creatorType": "author"
        },
        {
          "firstName": "Thomas",
          "lastName": "Unterthiner",
          "creatorType": "author"
        },
        {
          "firstName": "Mostafa",
          "lastName": "Dehghani",
          "creatorType": "author"
        },
        {
          "firstName": "Matthias",
          "lastName": "Minderer",
          "creatorType": "author"
        },
        {
          "firstName": "Georg",
          "lastName": "Heigold",
          "creatorType": "author"
        },
        {
          "firstName": "Sylvain",
          "lastName": "Gelly",
          "creatorType": "author"
        },
        {
          "firstName": "Jakob",
          "lastName": "Uszkoreit",
          "creatorType": "author"
        },
        {
          "firstName": "Neil",
          "lastName": "Houlsby",
          "creatorType": "author"
        }
      ],
      "tags": [
        {
          "tag": "Computer Science - Computer Vision and Pattern Recognition",
          "type": 1
        },
        {
          "tag": "Computer Science - Machine Learning",
          "type": 1
        },
        {
          "tag": "Computer Science - Artificial Intelligence",
          "type": 1
        }
      ],
      "relations": {},
      "dateAdded": "2024-02-22T07:03:21Z",
      "dateModified": "2024-02-22T07:03:22Z",
      "uri": "http://zotero.org/users/10101446/items/PP7AZZUT",
      "itemID": 462,
      "attachments": [
        {
          "itemType": "attachment",
          "title": "Dosovitskiy \u7b49 - 2021 - An Image is Worth 16x16 Words Transformers for Im.pdf",
          "tags": [],
          "relations": {},
          "dateAdded": "2024-02-22T07:03:15Z",
          "dateModified": "2024-02-22T07:03:23Z",
          "uri": "http://zotero.org/users/10101446/items/B9K9EGSK",
          "path": "C:\\Users\\gyh14\\Zotero\\storage\\B9K9EGSK\\Dosovitskiy \u7b49 - 2021 - An Image is Worth 16x16 Words Transformers for Im.pdf",
          "select": "zotero://select/library/items/B9K9EGSK"
        }
      ],
      "notes": [
        {
          "key": "7TRIC3AW",
          "version": 1003,
          "itemType": "note",
          "parentItem": "PP7AZZUT",
          "note": "Comment: Fine-tuning code and pre-trained models are available at https://github.com/google-research/vision_transformer. ICLR camera-ready version with 2 small modifications: 1) Added a discussion of CLS vs GAP classifier in the appendix, 2) Fixed an error in exaFLOPs computation in Figure 5 and Table 6 (relative performance of models is basically not affected)",
          "tags": [],
          "relations": {},
          "dateAdded": "2024-02-22T07:03:21Z",
          "dateModified": "2024-02-22T07:03:21Z",
          "uri": "http://zotero.org/users/10101446/items/7TRIC3AW"
        }
      ],
      "citationKey": "dosovitskiy2021-image",
      "itemKey": "PP7AZZUT",
      "libraryID": 1,
      "select": "zotero://select/library/items/PP7AZZUT"
    },
    {
      "key": "KG9PPYPL",
      "version": 633,
      "itemType": "journalArticle",
      "title": "Networks, Crowds, and Markets:",
      "language": "en",
      "libraryCatalog": "Zotero",
      "creators": [
        {
          "firstName": "David",
          "lastName": "Easley",
          "creatorType": "author"
        },
        {
          "firstName": "Jon",
          "lastName": "Kleinberg",
          "creatorType": "author"
        }
      ],
      "tags": [],
      "relations": {},
      "dateAdded": "2023-11-28T09:48:27Z",
      "dateModified": "2023-11-28T09:48:27Z",
      "uri": "http://zotero.org/users/10101446/items/KG9PPYPL",
      "itemID": 356,
      "attachments": [
        {
          "itemType": "attachment",
          "title": "Easley \u548c Kleinberg - Networks, Crowds, and Markets.pdf",
          "tags": [],
          "relations": {},
          "dateAdded": "2023-11-28T09:48:23Z",
          "dateModified": "2023-11-28T09:48:28Z",
          "uri": "http://zotero.org/users/10101446/items/CR4R2JRG",
          "path": "C:\\Users\\gyh14\\Zotero\\storage\\CR4R2JRG\\Easley \u548c Kleinberg - Networks, Crowds, and Markets.pdf",
          "select": "zotero://select/library/items/CR4R2JRG"
        }
      ],
      "notes": [],
      "citationKey": "easley-networks",
      "itemKey": "KG9PPYPL",
      "libraryID": 1,
      "select": "zotero://select/library/items/KG9PPYPL"
    },
    {
      "key": "TC8XWH8A",
      "version": 97,
      "itemType": "preprint",
      "title": "Texture Synthesis Using Convolutional Neural Networks",
      "abstractNote": "Here we introduce a new model of natural textures based on the feature spaces of convolutional neural networks optimised for object recognition. Samples from the model are of high perceptual quality demonstrating the generative power of neural networks trained in a purely discriminative fashion. Within the model, textures are represented by the correlations between feature maps in several layers of the network. We show that across layers the texture representations increasingly capture the statistical properties of natural images while making object information more and more explicit. The model provides a new tool to generate stimuli for neuroscience and might offer insights into the deep representations learned by convolutional neural networks.",
      "date": "2015-11-06",
      "language": "en",
      "libraryCatalog": "arXiv.org",
      "url": "http://arxiv.org/abs/1505.07376",
      "accessDate": "2023-03-07T07:15:56Z",
      "extra": "arXiv:1505.07376 [cs, q-bio]",
      "repository": "arXiv",
      "archiveID": "arXiv:1505.07376",
      "creators": [
        {
          "firstName": "Leon A.",
          "lastName": "Gatys",
          "creatorType": "author"
        },
        {
          "firstName": "Alexander S.",
          "lastName": "Ecker",
          "creatorType": "author"
        },
        {
          "firstName": "Matthias",
          "lastName": "Bethge",
          "creatorType": "author"
        }
      ],
      "tags": [
        {
          "tag": "Computer Science - Computer Vision and Pattern Recognition",
          "type": 1
        },
        {
          "tag": "Computer Science - Neural and Evolutionary Computing",
          "type": 1
        },
        {
          "tag": "Quantitative Biology - Neurons and Cognition",
          "type": 1
        }
      ],
      "relations": {},
      "dateAdded": "2023-03-07T07:15:56Z",
      "dateModified": "2023-03-07T07:15:56Z",
      "uri": "http://zotero.org/users/10101446/items/TC8XWH8A",
      "itemID": 1,
      "attachments": [
        {
          "itemType": "attachment",
          "title": "Gatys \u7b49 - 2015 - Texture Synthesis Using Convolutional Neural Netwo.pdf",
          "tags": [],
          "relations": {},
          "dateAdded": "2023-03-07T07:15:52Z",
          "dateModified": "2023-03-07T07:15:57Z",
          "uri": "http://zotero.org/users/10101446/items/RNTUP68M",
          "path": "C:\\Users\\gyh14\\Zotero\\storage\\RNTUP68M\\Gatys \u7b49 - 2015 - Texture Synthesis Using Convolutional Neural Netwo.pdf",
          "select": "zotero://select/library/items/RNTUP68M"
        }
      ],
      "notes": [
        {
          "key": "FVXVPZAU",
          "version": 97,
          "itemType": "note",
          "parentItem": "TC8XWH8A",
          "note": "Comment: Revision for NIPS 2015 Camera Ready. In line with reviewer's comments we now focus on the texture model and texture synthesis performance. We limit the relationship of our texture model to the ventral stream and its potential use for neuroscience to the discussion of the paper",
          "tags": [],
          "relations": {},
          "dateAdded": "2023-03-07T07:15:56Z",
          "dateModified": "2023-03-07T07:15:56Z",
          "uri": "http://zotero.org/users/10101446/items/FVXVPZAU"
        }
      ],
      "citationKey": "gatysTextureSynthesisUsing2015",
      "itemKey": "TC8XWH8A",
      "libraryID": 1,
      "select": "zotero://select/library/items/TC8XWH8A"
    },
    {
      "key": "9QZ5UITK",
      "version": 1005,
      "itemType": "preprint",
      "title": "Denoising Diffusion Probabilistic Models",
      "abstractNote": "We present high quality image synthesis results using diffusion probabilistic models, a class of latent variable models inspired by considerations from nonequilibrium thermodynamics. Our best results are obtained by training on a weighted variational bound designed according to a novel connection between diffusion probabilistic models and denoising score matching with Langevin dynamics, and our models naturally admit a progressive lossy decompression scheme that can be interpreted as a generalization of autoregressive decoding. On the unconditional CIFAR10 dataset, we obtain an Inception score of 9.46 and a state-of-the-art FID score of 3.17. On 256x256 LSUN, we obtain sample quality similar to ProgressiveGAN. Our implementation is available at https://github.com/hojonathanho/diffusion.",
      "date": "2020-12-16",
      "language": "en",
      "libraryCatalog": "arXiv.org",
      "url": "http://arxiv.org/abs/2006.11239",
      "accessDate": "2024-02-22T07:03:32Z",
      "extra": "arXiv:2006.11239 [cs, stat]",
      "repository": "arXiv",
      "archiveID": "arXiv:2006.11239",
      "creators": [
        {
          "firstName": "Jonathan",
          "lastName": "Ho",
          "creatorType": "author"
        },
        {
          "firstName": "Ajay",
          "lastName": "Jain",
          "creatorType": "author"
        },
        {
          "firstName": "Pieter",
          "lastName": "Abbeel",
          "creatorType": "author"
        }
      ],
      "tags": [
        {
          "tag": "Computer Science - Machine Learning",
          "type": 1
        },
        {
          "tag": "Statistics - Machine Learning",
          "type": 1
        }
      ],
      "relations": {},
      "dateAdded": "2024-02-22T07:03:32Z",
      "dateModified": "2024-02-22T07:03:32Z",
      "uri": "http://zotero.org/users/10101446/items/9QZ5UITK",
      "itemID": 461,
      "attachments": [
        {
          "itemType": "attachment",
          "title": "Ho \u7b49 - 2020 - Denoising Diffusion Probabilistic Models.pdf",
          "tags": [],
          "relations": {},
          "dateAdded": "2024-02-22T07:03:25Z",
          "dateModified": "2024-02-22T07:03:33Z",
          "uri": "http://zotero.org/users/10101446/items/B7DYLMHM",
          "path": "C:\\Users\\gyh14\\Zotero\\storage\\B7DYLMHM\\Ho \u7b49 - 2020 - Denoising Diffusion Probabilistic Models.pdf",
          "select": "zotero://select/library/items/B7DYLMHM"
        }
      ],
      "notes": [],
      "citationKey": "ho2020-denoising",
      "itemKey": "9QZ5UITK",
      "libraryID": 1,
      "select": "zotero://select/library/items/9QZ5UITK"
    },
    {
      "key": "3K59BSFN",
      "version": 731,
      "itemType": "preprint",
      "title": "Label-Free Liver Tumor Segmentation",
      "abstractNote": "We demonstrate that AI models can accurately segment liver tumors without the need for manual annotation by using synthetic tumors in CT scans. Our synthetic tumors have two intriguing advantages: (I) realistic in shape and texture, which even medical professionals can confuse with real tumors; (II) effective for training AI models, which can perform liver tumor segmentation similarly to the model trained on real tumors\u2014this result is exciting because no existing work, using synthetic tumors only, has thus far reached a similar or even close performance to real tumors. This result also implies that manual efforts for annotating tumors voxel by voxel (which took years to create) can be signi\ufb01cantly reduced in the future. Moreover, our synthetic tumors can automatically generate many examples of small (or even tiny) synthetic tumors and have the potential to improve the success rate of detecting small liver tumors, which is critical for detecting the early stages of cancer. In addition to enriching the training data, our synthesizing strategy also enables us to rigorously assess the AI robustness.",
      "date": "2023-03-26",
      "language": "en",
      "libraryCatalog": "arXiv.org",
      "url": "http://arxiv.org/abs/2303.14869",
      "accessDate": "2023-12-19T11:38:57Z",
      "extra": "arXiv:2303.14869 [cs, eess]",
      "repository": "arXiv",
      "archiveID": "arXiv:2303.14869",
      "creators": [
        {
          "firstName": "Qixin",
          "lastName": "Hu",
          "creatorType": "author"
        },
        {
          "firstName": "Yixiong",
          "lastName": "Chen",
          "creatorType": "author"
        },
        {
          "firstName": "Junfei",
          "lastName": "Xiao",
          "creatorType": "author"
        },
        {
          "firstName": "Shuwen",
          "lastName": "Sun",
          "creatorType": "author"
        },
        {
          "firstName": "Jieneng",
          "lastName": "Chen",
          "creatorType": "author"
        },
        {
          "firstName": "Alan",
          "lastName": "Yuille",
          "creatorType": "author"
        },
        {
          "firstName": "Zongwei",
          "lastName": "Zhou",
          "creatorType": "author"
        }
      ],
      "tags": [
        {
          "tag": "Computer Science - Computer Vision and Pattern Recognition",
          "type": 1
        },
        {
          "tag": "Computer Science - Machine Learning",
          "type": 1
        },
        {
          "tag": "Electrical Engineering and Systems Science - Image and Video Processing",
          "type": 1
        }
      ],
      "relations": {},
      "dateAdded": "2023-12-19T11:38:57Z",
      "dateModified": "2023-12-19T11:38:57Z",
      "uri": "http://zotero.org/users/10101446/items/3K59BSFN",
      "itemID": 389,
      "attachments": [
        {
          "itemType": "attachment",
          "title": "Hu \u7b49 - 2023 - Label-Free Liver Tumor Segmentation.pdf",
          "tags": [],
          "relations": {},
          "dateAdded": "2023-12-19T11:38:51Z",
          "dateModified": "2023-12-19T11:38:58Z",
          "uri": "http://zotero.org/users/10101446/items/PKUQPJ4G",
          "path": "C:\\Users\\gyh14\\Zotero\\storage\\PKUQPJ4G\\Hu \u7b49 - 2023 - Label-Free Liver Tumor Segmentation.pdf",
          "select": "zotero://select/library/items/PKUQPJ4G"
        }
      ],
      "notes": [
        {
          "key": "API5EMGU",
          "version": 731,
          "itemType": "note",
          "parentItem": "3K59BSFN",
          "note": "Comment: CVPR 2023",
          "tags": [],
          "relations": {},
          "dateAdded": "2023-12-19T11:38:57Z",
          "dateModified": "2023-12-19T11:38:57Z",
          "uri": "http://zotero.org/users/10101446/items/API5EMGU"
        }
      ],
      "citationKey": "hu2023-labelfree",
      "itemKey": "3K59BSFN",
      "libraryID": 1,
      "select": "zotero://select/library/items/3K59BSFN"
    },
    {
      "key": "XBBRUGC7",
      "version": 166,
      "itemType": "preprint",
      "title": "Language Is Not All You Need: Aligning Perception with Language Models",
      "abstractNote": "A big convergence of language, multimodal perception, action, and world modeling is a key step toward arti\ufb01cial general intelligence. In this work, we introduce KOSMOS-12, a Multimodal Large Language Model (MLLM) that can perceive general modalities, learn in context (i.e., few-shot), and follow instructions (i.e., zero-shot). Speci\ufb01cally, we train KOSMOS-1 from scratch on web-scale multimodal corpora, including arbitrarily interleaved text and images, image-caption pairs, and text data. We evaluate various settings, including zero-shot, few-shot, and multimodal chain-of-thought prompting, on a wide range of tasks without any gradient updates or \ufb01netuning. Experimental results show that KOSMOS-1 achieves impressive performance on (i) language understanding, generation, and even OCR-free NLP (directly fed with document images), (ii) perception-language tasks, including multimodal dialogue, image captioning, visual question answering, and (iii) vision tasks, such as image recognition with descriptions (specifying classi\ufb01cation via text instructions). We also show that MLLMs can bene\ufb01t from cross-modal transfer, i.e., transfer knowledge from language to multimodal, and from multimodal to language. In addition, we introduce a dataset of Raven IQ test, which diagnoses the nonverbal reasoning capability of MLLMs.",
      "date": "2023-03-01",
      "language": "en",
      "shortTitle": "Language Is Not All You Need",
      "libraryCatalog": "arXiv.org",
      "url": "http://arxiv.org/abs/2302.14045",
      "accessDate": "2023-06-17T14:39:14Z",
      "extra": "arXiv:2302.14045 [cs]",
      "repository": "arXiv",
      "archiveID": "arXiv:2302.14045",
      "creators": [
        {
          "firstName": "Shaohan",
          "lastName": "Huang",
          "creatorType": "author"
        },
        {
          "firstName": "Li",
          "lastName": "Dong",
          "creatorType": "author"
        },
        {
          "firstName": "Wenhui",
          "lastName": "Wang",
          "creatorType": "author"
        },
        {
          "firstName": "Yaru",
          "lastName": "Hao",
          "creatorType": "author"
        },
        {
          "firstName": "Saksham",
          "lastName": "Singhal",
          "creatorType": "author"
        },
        {
          "firstName": "Shuming",
          "lastName": "Ma",
          "creatorType": "author"
        },
        {
          "firstName": "Tengchao",
          "lastName": "Lv",
          "creatorType": "author"
        },
        {
          "firstName": "Lei",
          "lastName": "Cui",
          "creatorType": "author"
        },
        {
          "firstName": "Owais Khan",
          "lastName": "Mohammed",
          "creatorType": "author"
        },
        {
          "firstName": "Barun",
          "lastName": "Patra",
          "creatorType": "author"
        },
        {
          "firstName": "Qiang",
          "lastName": "Liu",
          "creatorType": "author"
        },
        {
          "firstName": "Kriti",
          "lastName": "Aggarwal",
          "creatorType": "author"
        },
        {
          "firstName": "Zewen",
          "lastName": "Chi",
          "creatorType": "author"
        },
        {
          "firstName": "Johan",
          "lastName": "Bjorck",
          "creatorType": "author"
        },
        {
          "firstName": "Vishrav",
          "lastName": "Chaudhary",
          "creatorType": "author"
        },
        {
          "firstName": "Subhojit",
          "lastName": "Som",
          "creatorType": "author"
        },
        {
          "firstName": "Xia",
          "lastName": "Song",
          "creatorType": "author"
        },
        {
          "firstName": "Furu",
          "lastName": "Wei",
          "creatorType": "author"
        }
      ],
      "tags": [
        {
          "tag": "Computer Science - Computer Vision and Pattern Recognition",
          "type": 1
        },
        {
          "tag": "Computer Science - Computation and Language",
          "type": 1
        }
      ],
      "relations": {},
      "dateAdded": "2023-06-17T14:39:14Z",
      "dateModified": "2023-06-17T14:39:14Z",
      "uri": "http://zotero.org/users/10101446/items/XBBRUGC7",
      "itemID": 67,
      "attachments": [
        {
          "itemType": "attachment",
          "title": "Huang \u7b49 - 2023 - Language Is Not All You Need Aligning Perception .pdf",
          "tags": [],
          "relations": {},
          "dateAdded": "2023-06-17T14:39:08Z",
          "dateModified": "2023-06-17T14:39:14Z",
          "uri": "http://zotero.org/users/10101446/items/U76G4KL2",
          "path": "C:\\Users\\gyh14\\Zotero\\storage\\U76G4KL2\\Huang \u7b49 - 2023 - Language Is Not All You Need Aligning Perception .pdf",
          "select": "zotero://select/library/items/U76G4KL2"
        }
      ],
      "notes": [],
      "citationKey": "huangLanguageNotAll2023",
      "itemKey": "XBBRUGC7",
      "libraryID": 1,
      "select": "zotero://select/library/items/XBBRUGC7"
    },
    {
      "key": "ZALHAE8W",
      "version": 1138,
      "itemType": "conferencePaper",
      "title": "Benchmark for Evaluating Pedestrian Action Prediction",
      "abstractNote": "Pedestrian action prediction has been a topic of active research in recent years resulting in many new algorithmic solutions. However, measuring the overall progress towards solving this problem is dif\ufb01cult due to the lack of publicly available benchmarks and common training and evaluation procedures. To this end, we introduce a benchmark based on two public datasets for pedestrian behavior understanding. Using the proposed evaluation procedures, we rank a number of baseline and state-of-theart models and analyze their performance with respect to various properties of the data. Based on these \ufb01ndings we propose a new model for pedestrian crossing action prediction that uses attention mechanisms to effectively combine implicit and explicit features and demonstrate new state-of-the-art results. The code for models and evaluation is available at https://github.com/ ykotseruba/PedestrianActionBenchmark.",
      "date": "1/2021",
      "language": "en",
      "libraryCatalog": "DOI.org (Crossref)",
      "url": "https://ieeexplore.ieee.org/document/9423436/",
      "accessDate": "2024-03-17T14:55:22Z",
      "place": "Waikoloa, HI, USA",
      "publisher": "IEEE",
      "ISBN": "978-1-66540-477-8",
      "pages": "1257-1267",
      "proceedingsTitle": "2021 IEEE Winter Conference on Applications of Computer Vision (WACV)",
      "conferenceName": "2021 IEEE Winter Conference on Applications of Computer Vision (WACV)",
      "DOI": "10.1109/WACV48630.2021.00130",
      "creators": [
        {
          "firstName": "Iuliia",
          "lastName": "Kotseruba",
          "creatorType": "author"
        },
        {
          "firstName": "Amir",
          "lastName": "Rasouli",
          "creatorType": "author"
        },
        {
          "firstName": "John K.",
          "lastName": "Tsotsos",
          "creatorType": "author"
        }
      ],
      "tags": [],
      "relations": {},
      "dateAdded": "2024-03-17T14:55:22Z",
      "dateModified": "2024-03-17T14:55:25Z",
      "uri": "http://zotero.org/users/10101446/items/ZALHAE8W",
      "itemID": 510,
      "attachments": [
        {
          "itemType": "attachment",
          "title": "Benchmark for Evaluating Pedestrian Action Prediction",
          "tags": [],
          "relations": {},
          "dateAdded": "2024-03-17T14:55:25Z",
          "dateModified": "2024-03-17T14:55:25Z",
          "uri": "http://zotero.org/users/10101446/items/MZWTYN7G",
          "path": "C:\\Users\\gyh14\\Zotero\\storage\\MZWTYN7G\\kotseruba2021.pdf.pdf",
          "select": "zotero://select/library/items/MZWTYN7G"
        },
        {
          "itemType": "attachment",
          "title": "Kotseruba \u7b49 - 2021 - Benchmark for Evaluating Pedestrian Action Predict.pdf",
          "tags": [],
          "relations": {},
          "dateAdded": "2024-03-17T14:55:19Z",
          "dateModified": "2024-03-17T14:55:26Z",
          "uri": "http://zotero.org/users/10101446/items/GP5U5ZNV",
          "path": "C:\\Users\\gyh14\\Zotero\\storage\\GP5U5ZNV\\Kotseruba \u7b49 - 2021 - Benchmark for Evaluating Pedestrian Action Predict.pdf",
          "select": "zotero://select/library/items/GP5U5ZNV"
        }
      ],
      "notes": [],
      "citationKey": "kotseruba2021-benchmark",
      "itemKey": "ZALHAE8W",
      "libraryID": 1,
      "select": "zotero://select/library/items/ZALHAE8W"
    },
    {
      "key": "4VLNSMS8",
      "version": 1339,
      "itemType": "preprint",
      "title": "A Decade's Battle on Dataset Bias: Are We There Yet?",
      "abstractNote": "We revisit the \u201cdataset classification\u201d experiment suggested by Torralba and Efros a decade ago [51], in the new era with largescale, diverse, and hopefully less biased datasets as well as more capable neural network architectures. Surprisingly, we observe that modern neural networks can achieve excellent accuracy in classifying which dataset an image is from: e.g., we report 84.7% accuracy on held-out validation data for the three-way classification problem consisting of the YFCC, CC, and DataComp datasets. Our further experiments show that such a dataset classifier could learn semantic features that are generalizable and transferable, which cannot be simply explained by memorization. We hope our discovery will inspire the community to rethink the issue involving dataset bias and model capabilities.",
      "date": "2024-03-13",
      "language": "en",
      "shortTitle": "A Decade's Battle on Dataset Bias",
      "libraryCatalog": "arXiv.org",
      "url": "http://arxiv.org/abs/2403.08632",
      "accessDate": "2024-04-19T05:37:33Z",
      "extra": "arXiv:2403.08632 [cs]",
      "repository": "arXiv",
      "archiveID": "arXiv:2403.08632",
      "creators": [
        {
          "firstName": "Zhuang",
          "lastName": "Liu",
          "creatorType": "author"
        },
        {
          "firstName": "Kaiming",
          "lastName": "He",
          "creatorType": "author"
        }
      ],
      "tags": [
        {
          "tag": "Computer Science - Computer Vision and Pattern Recognition",
          "type": 1
        },
        {
          "tag": "Computer Science - Machine Learning",
          "type": 1
        }
      ],
      "relations": {},
      "dateAdded": "2024-04-19T05:37:33Z",
      "dateModified": "2024-04-19T05:37:33Z",
      "uri": "http://zotero.org/users/10101446/items/4VLNSMS8",
      "itemID": 554,
      "attachments": [
        {
          "itemType": "attachment",
          "title": "Liu \u548c He - 2024 - A Decade's Battle on Dataset Bias Are We There Ye.pdf",
          "tags": [],
          "relations": {},
          "dateAdded": "2024-04-19T05:37:27Z",
          "dateModified": "2024-04-19T05:37:34Z",
          "uri": "http://zotero.org/users/10101446/items/UDKR9SPM",
          "path": "C:\\Users\\gyh14\\Zotero\\storage\\UDKR9SPM\\Liu \u548c He - 2024 - A Decade's Battle on Dataset Bias Are We There Ye.pdf",
          "select": "zotero://select/library/items/UDKR9SPM"
        }
      ],
      "notes": [],
      "citationKey": "liu2024-decade",
      "itemKey": "4VLNSMS8",
      "libraryID": 1,
      "select": "zotero://select/library/items/4VLNSMS8"
    },
    {
      "key": "XY6IAYYG",
      "version": 1422,
      "itemType": "preprint",
      "title": "KAN: Kolmogorov-Arnold Networks",
      "abstractNote": "Inspired by the Kolmogorov-Arnold representation theorem, we propose KolmogorovArnold Networks (KANs) as promising alternatives to Multi-Layer Perceptrons (MLPs). While MLPs have fixed activation functions on nodes (\u201cneurons\u201d), KANs have learnable activation functions on edges (\u201cweights\u201d). KANs have no linear weights at all \u2013 every weight parameter is replaced by a univariate function parametrized as a spline. We show that this seemingly simple change makes KANs outperform MLPs in terms of accuracy and interpretability. For accuracy, much smaller KANs can achieve comparable or better accuracy than much larger MLPs in data fitting and PDE solving. Theoretically and empirically, KANs possess faster neural scaling laws than MLPs. For interpretability, KANs can be intuitively visualized and can easily interact with human users. Through two examples in mathematics and physics, KANs are shown to be useful \u201ccollaborators\u201d helping scientists (re)discover mathematical and physical laws. In summary, KANs are promising alternatives for MLPs, opening opportunities for further improving today\u2019s deep learning models which rely heavily on MLPs.",
      "date": "2024-04-30",
      "language": "en",
      "shortTitle": "KAN",
      "libraryCatalog": "arXiv.org",
      "url": "http://arxiv.org/abs/2404.19756",
      "accessDate": "2024-05-02T10:31:19Z",
      "extra": "arXiv:2404.19756 [cond-mat, stat]",
      "repository": "arXiv",
      "archiveID": "arXiv:2404.19756",
      "creators": [
        {
          "firstName": "Ziming",
          "lastName": "Liu",
          "creatorType": "author"
        },
        {
          "firstName": "Yixuan",
          "lastName": "Wang",
          "creatorType": "author"
        },
        {
          "firstName": "Sachin",
          "lastName": "Vaidya",
          "creatorType": "author"
        },
        {
          "firstName": "Fabian",
          "lastName": "Ruehle",
          "creatorType": "author"
        },
        {
          "firstName": "James",
          "lastName": "Halverson",
          "creatorType": "author"
        },
        {
          "firstName": "Marin",
          "lastName": "Solja\u010di\u0107",
          "creatorType": "author"
        },
        {
          "firstName": "Thomas Y.",
          "lastName": "Hou",
          "creatorType": "author"
        },
        {
          "firstName": "Max",
          "lastName": "Tegmark",
          "creatorType": "author"
        }
      ],
      "tags": [
        {
          "tag": "Computer Science - Machine Learning",
          "type": 1
        },
        {
          "tag": "Computer Science - Artificial Intelligence",
          "type": 1
        },
        {
          "tag": "Statistics - Machine Learning",
          "type": 1
        },
        {
          "tag": "Condensed Matter - Disordered Systems and Neural Networks",
          "type": 1
        }
      ],
      "relations": {},
      "dateAdded": "2024-05-02T10:31:19Z",
      "dateModified": "2024-05-02T10:31:19Z",
      "uri": "http://zotero.org/users/10101446/items/XY6IAYYG",
      "itemID": 586,
      "attachments": [
        {
          "itemType": "attachment",
          "title": "Liu \u7b49 - 2024 - KAN Kolmogorov-Arnold Networks.pdf",
          "tags": [],
          "relations": {},
          "dateAdded": "2024-05-02T10:31:11Z",
          "dateModified": "2024-05-02T10:31:20Z",
          "uri": "http://zotero.org/users/10101446/items/TQPXPF7R",
          "path": "C:\\Users\\gyh14\\Zotero\\storage\\TQPXPF7R\\Liu \u7b49 - 2024 - KAN Kolmogorov-Arnold Networks.pdf",
          "select": "zotero://select/library/items/TQPXPF7R"
        }
      ],
      "notes": [
        {
          "key": "N3JXZAP5",
          "version": 1422,
          "itemType": "note",
          "parentItem": "XY6IAYYG",
          "note": "Comment: 48 pages, 20 figures. Codes are available at https://github.com/KindXiaoming/pykan",
          "tags": [],
          "relations": {},
          "dateAdded": "2024-05-02T10:31:19Z",
          "dateModified": "2024-05-02T10:31:19Z",
          "uri": "http://zotero.org/users/10101446/items/N3JXZAP5"
        }
      ],
      "citationKey": "liu2024-kan",
      "itemKey": "XY6IAYYG",
      "libraryID": 1,
      "select": "zotero://select/library/items/XY6IAYYG"
    },
    {
      "key": "MD8EYSTU",
      "version": 1384,
      "itemType": "preprint",
      "title": "Megalodon: Efficient LLM Pretraining and Inference with Unlimited Context Length",
      "abstractNote": "The quadratic complexity and weak length extrapolation of Transformers limits their ability to scale to long sequences, and while sub-quadratic solutions like linear attention and state space models exist, they empirically underperform Transformers in pretraining efficiency and downstream task accuracy. We introduce Megalodon, a neural architecture for efficient sequence modeling with unlimited context length. Megalodon inherits the architecture of Mega (exponential moving average with gated attention), and further introduces multiple technical components to improve its capability and stability, including complex exponential moving average (CEMA), timestep normalization layer, normalized attention mechanism and pre-norm with two-hop residual configuration. In a controlled head-to-head comparison with Llama2, Megalodon achieves better efficiency than Transformer in the scale of 7 billion parameters and 2 trillion training tokens. Megalodon reaches a training loss of 1.70, landing mid-way between Llama2-7B (1.75) and 13B (1.67). Code: https://github.com/XuezheMax/megalodon",
      "date": "2024-04-16",
      "language": "en",
      "shortTitle": "Megalodon",
      "libraryCatalog": "arXiv.org",
      "url": "http://arxiv.org/abs/2404.08801",
      "accessDate": "2024-04-26T07:00:11Z",
      "extra": "arXiv:2404.08801 [cs]",
      "repository": "arXiv",
      "archiveID": "arXiv:2404.08801",
      "creators": [
        {
          "firstName": "Xuezhe",
          "lastName": "Ma",
          "creatorType": "author"
        },
        {
          "firstName": "Xiaomeng",
          "lastName": "Yang",
          "creatorType": "author"
        },
        {
          "firstName": "Wenhan",
          "lastName": "Xiong",
          "creatorType": "author"
        },
        {
          "firstName": "Beidi",
          "lastName": "Chen",
          "creatorType": "author"
        },
        {
          "firstName": "Lili",
          "lastName": "Yu",
          "creatorType": "author"
        },
        {
          "firstName": "Hao",
          "lastName": "Zhang",
          "creatorType": "author"
        },
        {
          "firstName": "Jonathan",
          "lastName": "May",
          "creatorType": "author"
        },
        {
          "firstName": "Luke",
          "lastName": "Zettlemoyer",
          "creatorType": "author"
        },
        {
          "firstName": "Omer",
          "lastName": "Levy",
          "creatorType": "author"
        },
        {
          "firstName": "Chunting",
          "lastName": "Zhou",
          "creatorType": "author"
        }
      ],
      "tags": [
        {
          "tag": "Computer Science - Computation and Language",
          "type": 1
        },
        {
          "tag": "Computer Science - Machine Learning",
          "type": 1
        }
      ],
      "relations": {},
      "dateAdded": "2024-04-26T07:00:11Z",
      "dateModified": "2024-04-26T07:00:12Z",
      "uri": "http://zotero.org/users/10101446/items/MD8EYSTU",
      "itemID": 575,
      "attachments": [
        {
          "itemType": "attachment",
          "title": "Ma \u7b49 - 2024 - Megalodon Efficient LLM Pretraining and Inference.pdf",
          "tags": [],
          "relations": {},
          "dateAdded": "2024-04-26T07:00:06Z",
          "dateModified": "2024-04-26T07:00:12Z",
          "uri": "http://zotero.org/users/10101446/items/QQ9KBEUB",
          "path": "C:\\Users\\gyh14\\Zotero\\storage\\QQ9KBEUB\\Ma \u7b49 - 2024 - Megalodon Efficient LLM Pretraining and Inference.pdf",
          "select": "zotero://select/library/items/QQ9KBEUB"
        }
      ],
      "notes": [
        {
          "key": "JFXNLIVK",
          "version": 1384,
          "itemType": "note",
          "parentItem": "MD8EYSTU",
          "note": "Comment: 9 pages, 6 figures and 8 tables",
          "tags": [],
          "relations": {},
          "dateAdded": "2024-04-26T07:00:11Z",
          "dateModified": "2024-04-26T07:00:11Z",
          "uri": "http://zotero.org/users/10101446/items/JFXNLIVK"
        }
      ],
      "citationKey": "ma2024-megalodon",
      "itemKey": "MD8EYSTU",
      "libraryID": 1,
      "select": "zotero://select/library/items/MD8EYSTU"
    },
    {
      "key": "VP7ADWWH",
      "version": 1162,
      "itemType": "conferencePaper",
      "title": "A Dataset of Networks of Computing Hosts",
      "abstractNote": "We are making public a dataset of 21 disjoint graphs representing communications among machines running different distributed applications in various enterprises. We provide a ground truth grouping for one graph. The grouping is useful for evaluating tasks such as clustering hosts based on network communications. We describe the graphs and present a brief exploratory analysis to illustrate some of the properties, possible uses of the data, and some of the challenges.",
      "date": "2022-04-18",
      "language": "en",
      "libraryCatalog": "DOI.org (Crossref)",
      "url": "https://dl.acm.org/doi/10.1145/3510548.3519368",
      "accessDate": "2024-04-04T07:07:31Z",
      "place": "Baltimore MD USA",
      "publisher": "ACM",
      "ISBN": "978-1-4503-9230-3",
      "pages": "100-104",
      "proceedingsTitle": "Proceedings of the 2022 ACM on International Workshop on Security and Privacy Analytics",
      "conferenceName": "CODASPY '22: Twelveth ACM Conference on Data and Application Security and Privacy",
      "DOI": "10.1145/3510548.3519368",
      "creators": [
        {
          "firstName": "Omid",
          "lastName": "Madani",
          "creatorType": "author"
        },
        {
          "firstName": "Sai Ankith",
          "lastName": "Averineni",
          "creatorType": "author"
        },
        {
          "firstName": "Shashidhar",
          "lastName": "Gandham",
          "creatorType": "author"
        }
      ],
      "tags": [],
      "relations": {},
      "dateAdded": "2024-04-04T07:07:31Z",
      "dateModified": "2024-04-04T07:07:38Z",
      "uri": "http://zotero.org/users/10101446/items/VP7ADWWH",
      "itemID": 514,
      "attachments": [
        {
          "itemType": "attachment",
          "title": "Madani \u7b49 - 2022 - A Dataset of Networks of Computing Hosts.pdf",
          "tags": [],
          "relations": {},
          "dateAdded": "2024-04-04T07:07:26Z",
          "dateModified": "2024-04-04T07:07:39Z",
          "uri": "http://zotero.org/users/10101446/items/FJIWMTJD",
          "path": "C:\\Users\\gyh14\\Zotero\\storage\\FJIWMTJD\\Madani \u7b49 - 2022 - A Dataset of Networks of Computing Hosts.pdf",
          "select": "zotero://select/library/items/FJIWMTJD"
        }
      ],
      "notes": [],
      "citationKey": "madani2022-dataset",
      "itemKey": "VP7ADWWH",
      "libraryID": 1,
      "select": "zotero://select/library/items/VP7ADWWH"
    },
    {
      "key": "GLENCQ2M",
      "version": 1305,
      "itemType": "preprint",
      "title": "Differentiable plasticity: training plastic neural networks with backpropagation",
      "abstractNote": "How can we build agents that keep learning from experience, quickly and ef\ufb01ciently, after their initial training? Here we take inspiration from the main mechanism of learning in biological brains: synaptic plasticity, carefully tuned by evolution to produce ef\ufb01cient lifelong learning. We show that plasticity, just like connection weights, can be optimized by gradient descent in large (millions of parameters) recurrent networks with Hebbian plastic connections. First, recurrent plastic networks with more than two million parameters can be trained to memorize and reconstruct sets of novel, high-dimensional (1,000+ pixels) natural images not seen during training. Crucially, traditional non-plastic recurrent networks fail to solve this task. Furthermore, trained plastic networks can also solve generic meta-learning tasks such as the Omniglot task, with competitive results and little parameter overhead. Finally, in reinforcement learning settings, plastic networks outperform a non-plastic equivalent in a maze exploration task. We conclude that differentiable plasticity may provide a powerful novel approach to the learning-to-learn problem.",
      "date": "2018-07-31",
      "language": "en",
      "shortTitle": "Differentiable plasticity",
      "libraryCatalog": "arXiv.org",
      "url": "http://arxiv.org/abs/1804.02464",
      "accessDate": "2024-04-15T08:21:18Z",
      "extra": "arXiv:1804.02464 [cs, stat]",
      "repository": "arXiv",
      "archiveID": "arXiv:1804.02464",
      "creators": [
        {
          "firstName": "Thomas",
          "lastName": "Miconi",
          "creatorType": "author"
        },
        {
          "firstName": "Jeff",
          "lastName": "Clune",
          "creatorType": "author"
        },
        {
          "firstName": "Kenneth O.",
          "lastName": "Stanley",
          "creatorType": "author"
        }
      ],
      "tags": [
        {
          "tag": "Computer Science - Neural and Evolutionary Computing",
          "type": 1
        },
        {
          "tag": "Computer Science - Machine Learning",
          "type": 1
        },
        {
          "tag": "Statistics - Machine Learning",
          "type": 1
        }
      ],
      "relations": {},
      "dateAdded": "2024-04-15T08:21:18Z",
      "dateModified": "2024-04-15T08:21:19Z",
      "uri": "http://zotero.org/users/10101446/items/GLENCQ2M",
      "itemID": 551,
      "attachments": [
        {
          "itemType": "attachment",
          "title": "Miconi \u7b49 - 2018 - Differentiable plasticity training plastic neural.pdf",
          "tags": [],
          "relations": {},
          "dateAdded": "2024-04-15T08:21:12Z",
          "dateModified": "2024-04-15T08:21:19Z",
          "uri": "http://zotero.org/users/10101446/items/D6YFN9V6",
          "path": "C:\\Users\\gyh14\\Zotero\\storage\\D6YFN9V6\\Miconi \u7b49 - 2018 - Differentiable plasticity training plastic neural.pdf",
          "select": "zotero://select/library/items/D6YFN9V6"
        }
      ],
      "notes": [
        {
          "key": "MJLCUL7Z",
          "version": 1305,
          "itemType": "note",
          "parentItem": "GLENCQ2M",
          "note": "Comment: Presented at ICML 2018",
          "tags": [],
          "relations": {},
          "dateAdded": "2024-04-15T08:21:18Z",
          "dateModified": "2024-04-15T08:21:18Z",
          "uri": "http://zotero.org/users/10101446/items/MJLCUL7Z"
        }
      ],
      "citationKey": "miconi2018-differentiable",
      "itemKey": "GLENCQ2M",
      "libraryID": 1,
      "select": "zotero://select/library/items/GLENCQ2M"
    },
    {
      "key": "FGMGNC62",
      "version": 1134,
      "itemType": "conferencePaper",
      "title": "Social-STGCNN: A Social Spatio-Temporal Graph Convolutional Neural Network for Human Trajectory Prediction",
      "date": "6/2020",
      "language": "en",
      "shortTitle": "Social-STGCNN",
      "libraryCatalog": "DOI.org (Crossref)",
      "url": "https://ieeexplore.ieee.org/document/9156583/",
      "accessDate": "2024-03-17T14:54:35Z",
      "place": "Seattle, WA, USA",
      "publisher": "IEEE",
      "ISBN": "978-1-72817-168-5",
      "pages": "14412-14420",
      "proceedingsTitle": "2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)",
      "conferenceName": "2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)",
      "DOI": "10.1109/CVPR42600.2020.01443",
      "creators": [
        {
          "firstName": "Abduallah",
          "lastName": "Mohamed",
          "creatorType": "author"
        },
        {
          "firstName": "Kun",
          "lastName": "Qian",
          "creatorType": "author"
        },
        {
          "firstName": "Mohamed",
          "lastName": "Elhoseiny",
          "creatorType": "author"
        },
        {
          "firstName": "Christian",
          "lastName": "Claudel",
          "creatorType": "author"
        }
      ],
      "tags": [],
      "relations": {},
      "dateAdded": "2024-03-17T14:54:35Z",
      "dateModified": "2024-03-17T14:54:38Z",
      "uri": "http://zotero.org/users/10101446/items/FGMGNC62",
      "itemID": 507,
      "attachments": [
        {
          "itemType": "attachment",
          "title": "Mohamed \u7b49 - 2020 - Social-STGCNN A Social Spatio-Temporal Graph Conv.pdf",
          "tags": [],
          "relations": {},
          "dateAdded": "2024-03-17T14:54:31Z",
          "dateModified": "2024-03-17T14:54:38Z",
          "uri": "http://zotero.org/users/10101446/items/YUYFYCIB",
          "path": "C:\\Users\\gyh14\\Zotero\\storage\\YUYFYCIB\\Mohamed \u7b49 - 2020 - Social-STGCNN A Social Spatio-Temporal Graph Conv.pdf",
          "select": "zotero://select/library/items/YUYFYCIB"
        },
        {
          "itemType": "attachment",
          "title": "Social-STGCNN: A Social Spatio-Temporal Graph Convolutional Neural Network for Human Trajectory Prediction",
          "tags": [],
          "relations": {},
          "dateAdded": "2024-03-17T14:54:38Z",
          "dateModified": "2024-03-17T14:54:38Z",
          "uri": "http://zotero.org/users/10101446/items/ASQ5IU3F",
          "path": "C:\\Users\\gyh14\\Zotero\\storage\\ASQ5IU3F\\mohamed2020.pdf.pdf",
          "select": "zotero://select/library/items/ASQ5IU3F"
        }
      ],
      "notes": [],
      "citationKey": "mohamed2020-socialstgcnn",
      "itemKey": "FGMGNC62",
      "libraryID": 1,
      "select": "zotero://select/library/items/FGMGNC62"
    },
    {
      "key": "7NK5V74U",
      "version": 1190,
      "itemType": "preprint",
      "title": "Leave No Context Behind: Efficient Infinite Context Transformers with Infini-attention",
      "abstractNote": "This work introduces an efficient method to scale Transformer-based Large Language Models (LLMs) to infinitely long inputs with bounded memory and computation. A key component in our proposed approach is a new attention technique dubbed Infini-attention. The Infini-attention incorporates a compressive memory into the vanilla attention mechanism and builds in both masked local attention and long-term linear attention mechanisms in a single Transformer block. We demonstrate the effectiveness of our approach on long-context language modeling benchmarks, 1M sequence length passkey context block retrieval and 500K length book summarization tasks with 1B and 8B LLMs. Our approach introduces minimal bounded memory parameters and enables fast streaming inference for LLMs.",
      "date": "2024-04-10",
      "language": "en",
      "shortTitle": "Leave No Context Behind",
      "libraryCatalog": "arXiv.org",
      "url": "http://arxiv.org/abs/2404.07143",
      "accessDate": "2024-04-13T06:31:28Z",
      "extra": "arXiv:2404.07143 [cs]",
      "repository": "arXiv",
      "archiveID": "arXiv:2404.07143",
      "creators": [
        {
          "firstName": "Tsendsuren",
          "lastName": "Munkhdalai",
          "creatorType": "author"
        },
        {
          "firstName": "Manaal",
          "lastName": "Faruqui",
          "creatorType": "author"
        },
        {
          "firstName": "Siddharth",
          "lastName": "Gopal",
          "creatorType": "author"
        }
      ],
      "tags": [
        {
          "tag": "Computer Science - Neural and Evolutionary Computing",
          "type": 1
        },
        {
          "tag": "Computer Science - Computation and Language",
          "type": 1
        },
        {
          "tag": "Computer Science - Machine Learning",
          "type": 1
        },
        {
          "tag": "Computer Science - Artificial Intelligence",
          "type": 1
        }
      ],
      "relations": {},
      "dateAdded": "2024-04-13T06:31:28Z",
      "dateModified": "2024-04-13T06:31:29Z",
      "uri": "http://zotero.org/users/10101446/items/7NK5V74U",
      "itemID": 518,
      "attachments": [
        {
          "itemType": "attachment",
          "title": "Munkhdalai \u7b49 - 2024 - Leave No Context Behind Efficient Infinite Contex.pdf",
          "tags": [],
          "relations": {},
          "dateAdded": "2024-04-13T06:31:22Z",
          "dateModified": "2024-04-13T06:31:29Z",
          "uri": "http://zotero.org/users/10101446/items/IMMZ7FWL",
          "path": "C:\\Users\\gyh14\\Zotero\\storage\\IMMZ7FWL\\Munkhdalai \u7b49 - 2024 - Leave No Context Behind Efficient Infinite Contex.pdf",
          "select": "zotero://select/library/items/IMMZ7FWL"
        }
      ],
      "notes": [
        {
          "key": "LSAXSL6I",
          "version": 1190,
          "itemType": "note",
          "parentItem": "7NK5V74U",
          "note": "Comment: 9 pages, 4 figures, 4 tables",
          "tags": [],
          "relations": {},
          "dateAdded": "2024-04-13T06:31:28Z",
          "dateModified": "2024-04-13T06:31:28Z",
          "uri": "http://zotero.org/users/10101446/items/LSAXSL6I"
        }
      ],
      "citationKey": "munkhdalai2024-leave",
      "itemKey": "7NK5V74U",
      "libraryID": 1,
      "select": "zotero://select/library/items/7NK5V74U"
    },
    {
      "key": "6JZ2ZFBE",
      "version": 360,
      "itemType": "note",
      "note": "<div data-citation-items=\"%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F10101446%2Fitems%2FZRJI4HYN%22%5D%2C%22itemData%22%3A%7B%22id%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F10101446%2Fitems%2FZRJI4HYN%22%2C%22type%22%3A%22article%22%2C%22abstract%22%3A%22The%20dominant%20sequence%20transduction%20models%20are%20based%20on%20complex%20recurrent%20or%20convolutional%20neural%20networks%20that%20include%20an%20encoder%20and%20a%20decoder.%20The%20best%20performing%20models%20also%20connect%20the%20encoder%20and%20decoder%20through%20an%20attention%20mechanism.%20We%20propose%20a%20new%20simple%20network%20architecture%2C%20the%20Transformer%2C%20based%20solely%20on%20attention%20mechanisms%2C%20dispensing%20with%20recurrence%20and%20convolutions%20entirely.%20Experiments%20on%20two%20machine%20translation%20tasks%20show%20these%20models%20to%20be%20superior%20in%20quality%20while%20being%20more%20parallelizable%20and%20requiring%20signi%EF%AC%81cantly%20less%20time%20to%20train.%20Our%20model%20achieves%2028.4%20BLEU%20on%20the%20WMT%202014%20Englishto-German%20translation%20task%2C%20improving%20over%20the%20existing%20best%20results%2C%20including%20ensembles%2C%20by%20over%202%20BLEU.%20On%20the%20WMT%202014%20English-to-French%20translation%20task%2C%20our%20model%20establishes%20a%20new%20single-model%20state-of-the-art%20BLEU%20score%20of%2041.8%20after%20training%20for%203.5%20days%20on%20eight%20GPUs%2C%20a%20small%20fraction%20of%20the%20training%20costs%20of%20the%20best%20models%20from%20the%20literature.%20We%20show%20that%20the%20Transformer%20generalizes%20well%20to%20other%20tasks%20by%20applying%20it%20successfully%20to%20English%20constituency%20parsing%20both%20with%20large%20and%20limited%20training%20data.%22%2C%22language%22%3A%22en%22%2C%22note%22%3A%22arXiv%3A1706.03762%20%5Bcs%5D%22%2C%22number%22%3A%22arXiv%3A1706.03762%22%2C%22publisher%22%3A%22arXiv%22%2C%22source%22%3A%22arXiv.org%22%2C%22title%22%3A%22Attention%20Is%20All%20You%20Need%22%2C%22URL%22%3A%22http%3A%2F%2Farxiv.org%2Fabs%2F1706.03762%22%2C%22author%22%3A%5B%7B%22family%22%3A%22Vaswani%22%2C%22given%22%3A%22Ashish%22%7D%2C%7B%22family%22%3A%22Shazeer%22%2C%22given%22%3A%22Noam%22%7D%2C%7B%22family%22%3A%22Parmar%22%2C%22given%22%3A%22Niki%22%7D%2C%7B%22family%22%3A%22Uszkoreit%22%2C%22given%22%3A%22Jakob%22%7D%2C%7B%22family%22%3A%22Jones%22%2C%22given%22%3A%22Llion%22%7D%2C%7B%22family%22%3A%22Gomez%22%2C%22given%22%3A%22Aidan%20N.%22%7D%2C%7B%22family%22%3A%22Kaiser%22%2C%22given%22%3A%22Lukasz%22%7D%2C%7B%22family%22%3A%22Polosukhin%22%2C%22given%22%3A%22Illia%22%7D%5D%2C%22accessed%22%3A%7B%22date-parts%22%3A%5B%5B%222023%22%2C6%2C17%5D%5D%7D%2C%22issued%22%3A%7B%22date-parts%22%3A%5B%5B%222017%22%2C12%2C5%5D%5D%7D%7D%7D%5D\" data-schema-version=\"8\"><h1>Transformer</h1>\n<h2>\u4e3a\u4ec0\u4e48\u4f7f\u7528self-attention</h2>\n<ul>\n<li>\ncomputational complexity\n</li>\n<li>\nParallel computation\n</li>\n<li>\npath length between long-range dependencies in the network\n</li>\n</ul>\n<p></p>\n<p></p>\n</div>",
      "tags": [],
      "collections": [
        "K84JTQUN"
      ],
      "relations": {
        "dc:relation": [
          "http://zotero.org/users/10101446/items/ZRJI4HYN"
        ]
      },
      "dateAdded": "2023-09-23T15:28:23Z",
      "dateModified": "2023-09-24T07:53:49Z",
      "uri": "http://zotero.org/users/10101446/items/6JZ2ZFBE",
      "itemID": 172,
      "itemKey": "6JZ2ZFBE",
      "libraryID": 1,
      "select": "zotero://select/library/items/6JZ2ZFBE"
    },
    {
      "key": "HBXY5IN2",
      "version": 475,
      "itemType": "preprint",
      "title": "GPT-4 Technical Report",
      "abstractNote": "We report the development of GPT-4, a large-scale, multimodal model which can accept image and text inputs and produce text outputs. While less capable than humans in many real-world scenarios, GPT-4 exhibits human-level performance on various professional and academic benchmarks, including passing a simulated bar exam with a score around the top 10% of test takers. GPT-4 is a Transformerbased model pre-trained to predict the next token in a document. The post-training alignment process results in improved performance on measures of factuality and adherence to desired behavior. A core component of this project was developing infrastructure and optimization methods that behave predictably across a wide range of scales. This allowed us to accurately predict some aspects of GPT-4\u2019s performance based on models trained with no more than 1/1,000th the compute of GPT-4.",
      "date": "2023-03-27",
      "language": "en",
      "libraryCatalog": "arXiv.org",
      "url": "http://arxiv.org/abs/2303.08774",
      "accessDate": "2023-09-07T03:28:31Z",
      "extra": "arXiv:2303.08774 [cs]",
      "repository": "arXiv",
      "archiveID": "arXiv:2303.08774",
      "creators": [
        {
          "firstName": "",
          "lastName": "OpenAI",
          "creatorType": "author"
        }
      ],
      "tags": [
        {
          "tag": "Computer Science - Computation and Language",
          "type": 1
        },
        {
          "tag": "Computer Science - Artificial Intelligence",
          "type": 1
        },
        {
          "tag": "ObsCite"
        }
      ],
      "relations": {},
      "dateAdded": "2023-09-07T03:28:31Z",
      "dateModified": "2023-09-30T07:47:55Z",
      "uri": "http://zotero.org/users/10101446/items/HBXY5IN2",
      "itemID": 142,
      "attachments": [
        {
          "itemType": "attachment",
          "title": "OpenAI - 2023 - GPT-4 Technical Report.pdf",
          "tags": [],
          "relations": {},
          "dateAdded": "2023-09-07T03:28:18Z",
          "dateModified": "2023-09-07T03:28:32Z",
          "uri": "http://zotero.org/users/10101446/items/TJ3Z5A7Y",
          "path": "C:\\Users\\gyh14\\Zotero\\storage\\TJ3Z5A7Y\\OpenAI - 2023 - GPT-4 Technical Report.pdf",
          "select": "zotero://select/library/items/TJ3Z5A7Y"
        }
      ],
      "notes": [
        {
          "key": "C53J44VK",
          "version": 263,
          "itemType": "note",
          "parentItem": "HBXY5IN2",
          "note": "Comment: 100 pages",
          "tags": [],
          "relations": {},
          "dateAdded": "2023-09-07T03:28:31Z",
          "dateModified": "2023-09-07T03:28:31Z",
          "uri": "http://zotero.org/users/10101446/items/C53J44VK"
        }
      ],
      "citationKey": "openai2023-gpt4",
      "itemKey": "HBXY5IN2",
      "libraryID": 1,
      "select": "zotero://select/library/items/HBXY5IN2"
    },
    {
      "key": "FHB3VGYY",
      "version": 957,
      "itemType": "preprint",
      "title": "Scalable Diffusion Models with Transformers",
      "abstractNote": "We explore a new class of diffusion models based on the transformer architecture. We train latent diffusion models of images, replacing the commonly-used U-Net backbone with a transformer that operates on latent patches. We analyze the scalability of our Diffusion Transformers (DiTs) through the lens of forward pass complexity as measured by G\ufb02ops. We \ufb01nd that DiTs with higher G\ufb02ops\u2014through increased transformer depth/width or increased number of input tokens\u2014consistently have lower FID. In addition to possessing good scalability properties, our largest DiT-XL/2 models outperform all prior diffusion models on the classconditional ImageNet 512\u00d7512 and 256\u00d7256 benchmarks, achieving a state-of-the-art FID of 2.27 on the latter.",
      "date": "2023-03-02",
      "language": "en",
      "libraryCatalog": "arXiv.org",
      "url": "http://arxiv.org/abs/2212.09748",
      "accessDate": "2024-02-22T03:08:09Z",
      "extra": "arXiv:2212.09748 [cs]",
      "repository": "arXiv",
      "archiveID": "arXiv:2212.09748",
      "creators": [
        {
          "firstName": "William",
          "lastName": "Peebles",
          "creatorType": "author"
        },
        {
          "firstName": "Saining",
          "lastName": "Xie",
          "creatorType": "author"
        }
      ],
      "tags": [
        {
          "tag": "Computer Science - Computer Vision and Pattern Recognition",
          "type": 1
        },
        {
          "tag": "Computer Science - Machine Learning",
          "type": 1
        }
      ],
      "relations": {},
      "dateAdded": "2024-02-22T03:08:09Z",
      "dateModified": "2024-02-22T03:08:10Z",
      "uri": "http://zotero.org/users/10101446/items/FHB3VGYY",
      "itemID": 463,
      "attachments": [
        {
          "itemType": "attachment",
          "title": "Peebles \u548c Xie - 2023 - Scalable Diffusion Models with Transformers.pdf",
          "tags": [],
          "relations": {},
          "dateAdded": "2024-02-22T03:08:00Z",
          "dateModified": "2024-02-22T03:08:11Z",
          "uri": "http://zotero.org/users/10101446/items/V9JTI56I",
          "path": "C:\\Users\\gyh14\\Zotero\\storage\\V9JTI56I\\Peebles \u548c Xie - 2023 - Scalable Diffusion Models with Transformers.pdf",
          "select": "zotero://select/library/items/V9JTI56I"
        }
      ],
      "notes": [
        {
          "key": "NALVJWZC",
          "version": 957,
          "itemType": "note",
          "parentItem": "FHB3VGYY",
          "note": "Comment: Code, project page and videos available at https://www.wpeebles.com/DiT",
          "tags": [],
          "relations": {},
          "dateAdded": "2024-02-22T03:08:09Z",
          "dateModified": "2024-02-22T03:08:09Z",
          "uri": "http://zotero.org/users/10101446/items/NALVJWZC"
        }
      ],
      "citationKey": "peebles2023-scalable",
      "itemKey": "FHB3VGYY",
      "libraryID": 1,
      "select": "zotero://select/library/items/FHB3VGYY"
    },
    {
      "key": "AR3GIJFD",
      "version": 256,
      "itemType": "journalArticle",
      "title": "Improving Language Understanding by Generative Pre-Training",
      "abstractNote": "Natural language understanding comprises a wide range of diverse tasks such as textual entailment, question answering, semantic similarity assessment, and document classi\ufb01cation. Although large unlabeled text corpora are abundant, labeled data for learning these speci\ufb01c tasks is scarce, making it challenging for discriminatively trained models to perform adequately. We demonstrate that large gains on these tasks can be realized by generative pre-training of a language model on a diverse corpus of unlabeled text, followed by discriminative \ufb01ne-tuning on each speci\ufb01c task. In contrast to previous approaches, we make use of task-aware input transformations during \ufb01ne-tuning to achieve effective transfer while requiring minimal changes to the model architecture. We demonstrate the effectiveness of our approach on a wide range of benchmarks for natural language understanding. Our general task-agnostic model outperforms discriminatively trained models that use architectures speci\ufb01cally crafted for each task, signi\ufb01cantly improving upon the state of the art in 9 out of the 12 tasks studied. For instance, we achieve absolute improvements of 8.9% on commonsense reasoning (Stories Cloze Test), 5.7% on question answering (RACE), and 1.5% on textual entailment (MultiNLI).",
      "language": "en",
      "libraryCatalog": "Zotero",
      "creators": [
        {
          "firstName": "Alec",
          "lastName": "Radford",
          "creatorType": "author"
        },
        {
          "firstName": "Karthik",
          "lastName": "Narasimhan",
          "creatorType": "author"
        },
        {
          "firstName": "Tim",
          "lastName": "Salimans",
          "creatorType": "author"
        },
        {
          "firstName": "Ilya",
          "lastName": "Sutskever",
          "creatorType": "author"
        }
      ],
      "tags": [],
      "relations": {},
      "dateAdded": "2023-09-07T03:28:05Z",
      "dateModified": "2023-09-07T03:28:05Z",
      "uri": "http://zotero.org/users/10101446/items/AR3GIJFD",
      "itemID": 138,
      "attachments": [
        {
          "itemType": "attachment",
          "title": "Radford \u7b49 - Improving Language Understanding by Generative Pre.pdf",
          "tags": [],
          "relations": {},
          "dateAdded": "2023-09-07T03:28:02Z",
          "dateModified": "2023-09-07T03:28:05Z",
          "uri": "http://zotero.org/users/10101446/items/7IDJ5PYD",
          "path": "C:\\Users\\gyh14\\Zotero\\storage\\7IDJ5PYD\\Radford \u7b49 - Improving Language Understanding by Generative Pre.pdf",
          "select": "zotero://select/library/items/7IDJ5PYD"
        }
      ],
      "notes": [],
      "citationKey": "radfordImprovingLanguageUnderstanding",
      "itemKey": "AR3GIJFD",
      "libraryID": 1,
      "select": "zotero://select/library/items/AR3GIJFD"
    },
    {
      "key": "7T5MVX42",
      "version": 259,
      "itemType": "journalArticle",
      "title": "Language Models are Unsupervised Multitask Learners",
      "abstractNote": "Natural language processing tasks, such as question answering, machine translation, reading comprehension, and summarization, are typically approached with supervised learning on taskspeci\ufb01c datasets. We demonstrate that language models begin to learn these tasks without any explicit supervision when trained on a new dataset of millions of webpages called WebText. When conditioned on a document plus questions, the answers generated by the language model reach 55 F1 on the CoQA dataset - matching or exceeding the performance of 3 out of 4 baseline systems without using the 127,000+ training examples. The capacity of the language model is essential to the success of zero-shot task transfer and increasing it improves performance in a log-linear fashion across tasks. Our largest model, GPT-2, is a 1.5B parameter Transformer that achieves state of the art results on 7 out of 8 tested language modeling datasets in a zero-shot setting but still under\ufb01ts WebText. Samples from the model re\ufb02ect these improvements and contain coherent paragraphs of text. These \ufb01ndings suggest a promising path towards building language processing systems which learn to perform tasks from their naturally occurring demonstrations.",
      "language": "en",
      "libraryCatalog": "Zotero",
      "creators": [
        {
          "firstName": "Alec",
          "lastName": "Radford",
          "creatorType": "author"
        },
        {
          "firstName": "Jeffrey",
          "lastName": "Wu",
          "creatorType": "author"
        },
        {
          "firstName": "Rewon",
          "lastName": "Child",
          "creatorType": "author"
        },
        {
          "firstName": "David",
          "lastName": "Luan",
          "creatorType": "author"
        },
        {
          "firstName": "Dario",
          "lastName": "Amodei",
          "creatorType": "author"
        },
        {
          "firstName": "Ilya",
          "lastName": "Sutskever",
          "creatorType": "author"
        }
      ],
      "tags": [],
      "relations": {},
      "dateAdded": "2023-09-07T03:28:16Z",
      "dateModified": "2023-09-07T03:28:17Z",
      "uri": "http://zotero.org/users/10101446/items/7T5MVX42",
      "itemID": 140,
      "attachments": [
        {
          "itemType": "attachment",
          "title": "Radford \u7b49 - Language Models are Unsupervised Multitask Learner.pdf",
          "tags": [],
          "relations": {},
          "dateAdded": "2023-09-07T03:28:13Z",
          "dateModified": "2023-09-07T03:28:17Z",
          "uri": "http://zotero.org/users/10101446/items/QQBJYCUR",
          "path": "C:\\Users\\gyh14\\Zotero\\storage\\QQBJYCUR\\Radford \u7b49 - Language Models are Unsupervised Multitask Learner.pdf",
          "select": "zotero://select/library/items/QQBJYCUR"
        }
      ],
      "notes": [],
      "citationKey": "radfordLanguageModelsAre",
      "itemKey": "7T5MVX42",
      "libraryID": 1,
      "select": "zotero://select/library/items/7T5MVX42"
    },
    {
      "key": "PXZ7UMK4",
      "version": 1131,
      "itemType": "conferencePaper",
      "title": "Introvert: Human Trajectory Prediction via Conditional 3D Attention",
      "abstractNote": "Predicting human trajectories is an important component of autonomous moving platforms, such as social robots and self-driving cars. Human trajectories are affected by both the physical features of the environment and social interactions with other humans. Despite recent surge of studies on human path prediction, most works focus on static scene information, therefore, cannot leverage the rich dynamic visual information of the scene. In this work, we propose Introvert, a model which predicts human path based on his/her observed trajectory and the dynamic scene context, captured via a conditional 3D visual attention mechanism working on the input video. Introvert infers both environment constraints and social interactions through observing the dynamic scene instead of communicating with other humans, hence, its computational cost is independent of how crowded the surrounding of a target human is. In addition, to focus on relevant interactions and constraints for each human, Introvert conditions its 3D attention model on the observed trajectory of the target human to extract and focus on relevant spatio-temporal primitives. Our experiments on \ufb01ve publicly available datasets show that the Introvert improves the prediction errors of the state of the art.",
      "date": "6/2021",
      "language": "en",
      "shortTitle": "Introvert",
      "libraryCatalog": "DOI.org (Crossref)",
      "url": "https://ieeexplore.ieee.org/document/9577353/",
      "accessDate": "2024-03-17T14:54:05Z",
      "place": "Nashville, TN, USA",
      "publisher": "IEEE",
      "ISBN": "978-1-66544-509-2",
      "pages": "16810-16820",
      "proceedingsTitle": "2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)",
      "conferenceName": "2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)",
      "DOI": "10.1109/CVPR46437.2021.01654",
      "creators": [
        {
          "firstName": "Nasim",
          "lastName": "Shafiee",
          "creatorType": "author"
        },
        {
          "firstName": "Taskin",
          "lastName": "Padir",
          "creatorType": "author"
        },
        {
          "firstName": "Ehsan",
          "lastName": "Elhamifar",
          "creatorType": "author"
        }
      ],
      "tags": [],
      "relations": {},
      "dateAdded": "2024-03-17T14:54:05Z",
      "dateModified": "2024-03-17T14:54:08Z",
      "uri": "http://zotero.org/users/10101446/items/PXZ7UMK4",
      "itemID": 505,
      "attachments": [
        {
          "itemType": "attachment",
          "title": "Shafiee \u7b49 - 2021 - Introvert Human Trajectory Prediction via Conditi.pdf",
          "tags": [],
          "relations": {},
          "dateAdded": "2024-03-17T14:54:01Z",
          "dateModified": "2024-03-17T14:54:08Z",
          "uri": "http://zotero.org/users/10101446/items/YL858F9L",
          "path": "C:\\Users\\gyh14\\Zotero\\storage\\YL858F9L\\Shafiee \u7b49 - 2021 - Introvert Human Trajectory Prediction via Conditi.pdf",
          "select": "zotero://select/library/items/YL858F9L"
        }
      ],
      "notes": [],
      "citationKey": "shafiee2021-introvert",
      "itemKey": "PXZ7UMK4",
      "libraryID": 1,
      "select": "zotero://select/library/items/PXZ7UMK4"
    },
    {
      "key": "IGUCEVDS",
      "version": 1345,
      "itemType": "preprint",
      "title": "Sketch-guided Image Inpainting with Partial Discrete Diffusion Process",
      "abstractNote": "In this work, we study the task of sketch-guided image inpainting. Unlike the well-explored natural language-guided image inpainting, which excels in capturing semantic details, the relatively less-studied sketch-guided inpainting offers greater user control in specifying the object\u2019s shape and pose to be inpainted. As one of the early solutions to this task, we introduce a novel partial discrete diffusion process (PDDP). The forward pass of the PDDP corrupts the masked regions of the image and the backward pass reconstructs these masked regions conditioned on hand-drawn sketches using our proposed sketch-guided bi-directional transformer. The proposed novel transformer module accepts two inputs \u2013 the image containing the masked region to be inpainted and the query sketch to model the reverse diffusion process. This strategy effectively addresses the domain gap between sketches and natural images, thereby, enhancing the quality of inpainting results. In the absence of a large-scale dataset specific to this task, we synthesize a dataset from the MS-COCO to train and extensively evaluate our proposed framework against various competent approaches in the literature. The qualitative and quantitative results and user studies establish that the proposed method inpaints realistic objects that fit the context in terms of the visual appearance of the provided sketch. To aid further research, we have made our code publicly available here: https://github.com/vl2g/SketchInpainting.",
      "date": "2024-04-18",
      "language": "en",
      "libraryCatalog": "arXiv.org",
      "url": "http://arxiv.org/abs/2404.11949",
      "accessDate": "2024-04-19T05:41:35Z",
      "extra": "arXiv:2404.11949 [cs]",
      "repository": "arXiv",
      "archiveID": "arXiv:2404.11949",
      "creators": [
        {
          "firstName": "Nakul",
          "lastName": "Sharma",
          "creatorType": "author"
        },
        {
          "firstName": "Aditay",
          "lastName": "Tripathi",
          "creatorType": "author"
        },
        {
          "firstName": "Anirban",
          "lastName": "Chakraborty",
          "creatorType": "author"
        },
        {
          "firstName": "Anand",
          "lastName": "Mishra",
          "creatorType": "author"
        }
      ],
      "tags": [
        {
          "tag": "Computer Science - Computer Vision and Pattern Recognition",
          "type": 1
        },
        {
          "tag": "Computer Science - Machine Learning",
          "type": 1
        },
        {
          "tag": "Computer Science - Artificial Intelligence",
          "type": 1
        }
      ],
      "relations": {},
      "dateAdded": "2024-04-19T05:41:35Z",
      "dateModified": "2024-04-19T05:41:35Z",
      "uri": "http://zotero.org/users/10101446/items/IGUCEVDS",
      "itemID": 556,
      "attachments": [
        {
          "itemType": "attachment",
          "title": "Sharma \u7b49 - 2024 - Sketch-guided Image Inpainting with Partial Discre.pdf",
          "tags": [],
          "relations": {},
          "dateAdded": "2024-04-19T05:41:30Z",
          "dateModified": "2024-04-19T05:41:36Z",
          "uri": "http://zotero.org/users/10101446/items/F8U7XI54",
          "path": "C:\\Users\\gyh14\\Zotero\\storage\\F8U7XI54\\Sharma \u7b49 - 2024 - Sketch-guided Image Inpainting with Partial Discre.pdf",
          "select": "zotero://select/library/items/F8U7XI54"
        }
      ],
      "notes": [
        {
          "key": "DM5VPD44",
          "version": 1345,
          "itemType": "note",
          "parentItem": "IGUCEVDS",
          "note": "Comment: Accepted to NTIRE Workshop @ CVPR 2024",
          "tags": [],
          "relations": {},
          "dateAdded": "2024-04-19T05:41:35Z",
          "dateModified": "2024-04-19T05:41:35Z",
          "uri": "http://zotero.org/users/10101446/items/DM5VPD44"
        }
      ],
      "citationKey": "sharma2024-sketchguided",
      "itemKey": "IGUCEVDS",
      "libraryID": 1,
      "select": "zotero://select/library/items/IGUCEVDS"
    },
    {
      "key": "99BHSFSW",
      "version": 381,
      "itemType": "book",
      "title": "Distributed systems",
      "date": "2023",
      "language": "en",
      "libraryCatalog": "Open WorldCat",
      "extra": "OCLC: 1373659118",
      "place": "Place of publication not identified",
      "publisher": "Maarten van Steen",
      "ISBN": "978-90-815406-3-6",
      "edition": "4th edition, Version 01 (January 2023)",
      "creators": [
        {
          "firstName": "Maarten van",
          "lastName": "Steen",
          "creatorType": "author"
        },
        {
          "firstName": "Andrew S.",
          "lastName": "Tanenbaum",
          "creatorType": "author"
        }
      ],
      "tags": [],
      "relations": {},
      "dateAdded": "2023-09-24T08:32:54Z",
      "dateModified": "2023-09-24T08:32:54Z",
      "uri": "http://zotero.org/users/10101446/items/99BHSFSW",
      "itemID": 194,
      "attachments": [
        {
          "itemType": "attachment",
          "title": "Steen \u548c Tanenbaum - 2023 - Distributed systems.pdf",
          "tags": [],
          "relations": {},
          "dateAdded": "2023-09-24T08:32:41Z",
          "dateModified": "2023-09-24T08:32:55Z",
          "uri": "http://zotero.org/users/10101446/items/V28G345J",
          "path": "C:\\Users\\gyh14\\Zotero\\storage\\V28G345J\\Steen \u548c Tanenbaum - 2023 - Distributed systems.pdf",
          "select": "zotero://select/library/items/V28G345J"
        }
      ],
      "notes": [],
      "citationKey": "steenDistributedSystems2023",
      "itemKey": "99BHSFSW",
      "libraryID": 1,
      "select": "zotero://select/library/items/99BHSFSW"
    },
    {
      "key": "D38IHND8",
      "version": 565,
      "itemType": "preprint",
      "title": "Retentive Network: A Successor to Transformer for Large Language Models",
      "abstractNote": "In this work, we propose Retentive Network (RETNET) as a foundation architecture for large language models, simultaneously achieving training parallelism, low-cost inference, and good performance. We theoretically derive the connection between recurrence and attention. Then we propose the retention mechanism for sequence modeling, which supports three computation paradigms, i.e., parallel, recurrent, and chunkwise recurrent. Specifically, the parallel representation allows for training parallelism. The recurrent representation enables low-cost O(1) inference, which improves decoding throughput, latency, and GPU memory without sacrificing performance. The chunkwise recurrent representation facilitates efficient long-sequence modeling with linear complexity, where each chunk is encoded parallelly while recurrently summarizing the chunks. Experimental results on language modeling show that RETNET achieves favorable scaling results, parallel training, low-cost deployment, and efficient inference. The intriguing properties make RETNET a strong successor to Transformer for large language models. Code will be available at https://aka.ms/retnet.",
      "date": "2023-08-09",
      "language": "en",
      "shortTitle": "Retentive Network",
      "libraryCatalog": "arXiv.org",
      "url": "http://arxiv.org/abs/2307.08621",
      "accessDate": "2023-10-15T07:06:09Z",
      "extra": "arXiv:2307.08621 [cs]",
      "repository": "arXiv",
      "archiveID": "arXiv:2307.08621",
      "creators": [
        {
          "firstName": "Yutao",
          "lastName": "Sun",
          "creatorType": "author"
        },
        {
          "firstName": "Li",
          "lastName": "Dong",
          "creatorType": "author"
        },
        {
          "firstName": "Shaohan",
          "lastName": "Huang",
          "creatorType": "author"
        },
        {
          "firstName": "Shuming",
          "lastName": "Ma",
          "creatorType": "author"
        },
        {
          "firstName": "Yuqing",
          "lastName": "Xia",
          "creatorType": "author"
        },
        {
          "firstName": "Jilong",
          "lastName": "Xue",
          "creatorType": "author"
        },
        {
          "firstName": "Jianyong",
          "lastName": "Wang",
          "creatorType": "author"
        },
        {
          "firstName": "Furu",
          "lastName": "Wei",
          "creatorType": "author"
        }
      ],
      "tags": [
        {
          "tag": "Computer Science - Computation and Language",
          "type": 1
        },
        {
          "tag": "Computer Science - Machine Learning",
          "type": 1
        },
        {
          "tag": "ObsCite"
        }
      ],
      "relations": {},
      "dateAdded": "2023-10-15T07:06:09Z",
      "dateModified": "2023-10-18T01:29:18Z",
      "uri": "http://zotero.org/users/10101446/items/D38IHND8",
      "itemID": 339,
      "attachments": [
        {
          "itemType": "attachment",
          "title": "Sun \u7b49 - 2023 - Retentive Network A Successor to Transformer for .pdf",
          "tags": [],
          "relations": {},
          "dateAdded": "2023-10-15T07:05:57Z",
          "dateModified": "2023-10-15T07:06:09Z",
          "uri": "http://zotero.org/users/10101446/items/73EF3EEY",
          "path": "C:\\Users\\gyh14\\Zotero\\storage\\73EF3EEY\\Sun \u7b49 - 2023 - Retentive Network A Successor to Transformer for .pdf",
          "select": "zotero://select/library/items/73EF3EEY"
        }
      ],
      "notes": [],
      "citationKey": "sun2023-retentive",
      "itemKey": "D38IHND8",
      "libraryID": 1,
      "select": "zotero://select/library/items/D38IHND8"
    },
    {
      "key": "ZRJI4HYN",
      "version": 535,
      "itemType": "preprint",
      "title": "Attention Is All You Need",
      "abstractNote": "The dominant sequence transduction models are based on complex recurrent or convolutional neural networks that include an encoder and a decoder. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring signi\ufb01cantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 Englishto-German translation task, improving over the existing best results, including ensembles, by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.",
      "date": "2017-12-05",
      "language": "en",
      "libraryCatalog": "arXiv.org",
      "url": "http://arxiv.org/abs/1706.03762",
      "accessDate": "2023-06-17T14:40:13Z",
      "extra": "arXiv:1706.03762 [cs]",
      "repository": "arXiv",
      "archiveID": "arXiv:1706.03762",
      "creators": [
        {
          "firstName": "Ashish",
          "lastName": "Vaswani",
          "creatorType": "author"
        },
        {
          "firstName": "Noam",
          "lastName": "Shazeer",
          "creatorType": "author"
        },
        {
          "firstName": "Niki",
          "lastName": "Parmar",
          "creatorType": "author"
        },
        {
          "firstName": "Jakob",
          "lastName": "Uszkoreit",
          "creatorType": "author"
        },
        {
          "firstName": "Llion",
          "lastName": "Jones",
          "creatorType": "author"
        },
        {
          "firstName": "Aidan N.",
          "lastName": "Gomez",
          "creatorType": "author"
        },
        {
          "firstName": "Lukasz",
          "lastName": "Kaiser",
          "creatorType": "author"
        },
        {
          "firstName": "Illia",
          "lastName": "Polosukhin",
          "creatorType": "author"
        }
      ],
      "tags": [
        {
          "tag": "Computer Science - Computation and Language",
          "type": 1
        },
        {
          "tag": "Computer Science - Machine Learning",
          "type": 1
        }
      ],
      "relations": {
        "dc:relation": [
          "http://zotero.org/users/10101446/items/6JZ2ZFBE"
        ]
      },
      "dateAdded": "2023-06-17T14:40:13Z",
      "dateModified": "2023-10-12T09:36:21Z",
      "uri": "http://zotero.org/users/10101446/items/ZRJI4HYN",
      "itemID": 69,
      "attachments": [
        {
          "itemType": "attachment",
          "title": "Vaswani \u7b49 - 2017 - Attention Is All You Need.pdf",
          "tags": [],
          "relations": {},
          "dateAdded": "2023-06-17T14:40:09Z",
          "dateModified": "2023-06-17T14:40:13Z",
          "uri": "http://zotero.org/users/10101446/items/GXDZU4NV",
          "path": "C:\\Users\\gyh14\\Zotero\\storage\\GXDZU4NV\\Vaswani \u7b49 - 2017 - Attention Is All You Need.pdf",
          "select": "zotero://select/library/items/GXDZU4NV"
        }
      ],
      "notes": [
        {
          "key": "X5TJU3WQ",
          "version": 491,
          "itemType": "note",
          "parentItem": "ZRJI4HYN",
          "note": "<div data-citation-items=\"%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F10101446%2Fitems%2FZRJI4HYN%22%5D%2C%22itemData%22%3A%7B%22id%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F10101446%2Fitems%2FZRJI4HYN%22%2C%22type%22%3A%22article%22%2C%22abstract%22%3A%22The%20dominant%20sequence%20transduction%20models%20are%20based%20on%20complex%20recurrent%20or%20convolutional%20neural%20networks%20that%20include%20an%20encoder%20and%20a%20decoder.%20The%20best%20performing%20models%20also%20connect%20the%20encoder%20and%20decoder%20through%20an%20attention%20mechanism.%20We%20propose%20a%20new%20simple%20network%20architecture%2C%20the%20Transformer%2C%20based%20solely%20on%20attention%20mechanisms%2C%20dispensing%20with%20recurrence%20and%20convolutions%20entirely.%20Experiments%20on%20two%20machine%20translation%20tasks%20show%20these%20models%20to%20be%20superior%20in%20quality%20while%20being%20more%20parallelizable%20and%20requiring%20signi%EF%AC%81cantly%20less%20time%20to%20train.%20Our%20model%20achieves%2028.4%20BLEU%20on%20the%20WMT%202014%20Englishto-German%20translation%20task%2C%20improving%20over%20the%20existing%20best%20results%2C%20including%20ensembles%2C%20by%20over%202%20BLEU.%20On%20the%20WMT%202014%20English-to-French%20translation%20task%2C%20our%20model%20establishes%20a%20new%20single-model%20state-of-the-art%20BLEU%20score%20of%2041.8%20after%20training%20for%203.5%20days%20on%20eight%20GPUs%2C%20a%20small%20fraction%20of%20the%20training%20costs%20of%20the%20best%20models%20from%20the%20literature.%20We%20show%20that%20the%20Transformer%20generalizes%20well%20to%20other%20tasks%20by%20applying%20it%20successfully%20to%20English%20constituency%20parsing%20both%20with%20large%20and%20limited%20training%20data.%22%2C%22language%22%3A%22en%22%2C%22note%22%3A%22arXiv%3A1706.03762%20%5Bcs%5D%22%2C%22number%22%3A%22arXiv%3A1706.03762%22%2C%22publisher%22%3A%22arXiv%22%2C%22source%22%3A%22arXiv.org%22%2C%22title%22%3A%22Attention%20Is%20All%20You%20Need%22%2C%22URL%22%3A%22http%3A%2F%2Farxiv.org%2Fabs%2F1706.03762%22%2C%22author%22%3A%5B%7B%22family%22%3A%22Vaswani%22%2C%22given%22%3A%22Ashish%22%7D%2C%7B%22family%22%3A%22Shazeer%22%2C%22given%22%3A%22Noam%22%7D%2C%7B%22family%22%3A%22Parmar%22%2C%22given%22%3A%22Niki%22%7D%2C%7B%22family%22%3A%22Uszkoreit%22%2C%22given%22%3A%22Jakob%22%7D%2C%7B%22family%22%3A%22Jones%22%2C%22given%22%3A%22Llion%22%7D%2C%7B%22family%22%3A%22Gomez%22%2C%22given%22%3A%22Aidan%20N.%22%7D%2C%7B%22family%22%3A%22Kaiser%22%2C%22given%22%3A%22Lukasz%22%7D%2C%7B%22family%22%3A%22Polosukhin%22%2C%22given%22%3A%22Illia%22%7D%5D%2C%22accessed%22%3A%7B%22date-parts%22%3A%5B%5B%222023%22%2C6%2C17%5D%5D%7D%2C%22issued%22%3A%7B%22date-parts%22%3A%5B%5B%222017%22%2C12%2C5%5D%5D%7D%2C%22citation-key%22%3A%22vaswani2017-attention%22%7D%7D%5D\" data-schema-version=\"8\"><h1>\u6ce8\u91ca<br/>(2023/9/30 \u4e0b\u53483:56:10)</h1>\n<p><span class=\"highlight\" data-annotation=\"%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F10101446%2Fitems%2FGXDZU4NV%22%2C%22annotationKey%22%3A%225EC5JCXU%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%221%22%2C%22position%22%3A%7B%22pageIndex%22%3A0%2C%22rects%22%3A%5B%5B162.442%2C420.212%2C325.987%2C429.119%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F10101446%2Fitems%2FZRJI4HYN%22%5D%2C%22locator%22%3A%221%22%7D%7D\">\u201cdominant sequence transduction models\u201d</span> <span class=\"citation\" data-citation=\"%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F10101446%2Fitems%2FZRJI4HYN%22%5D%2C%22locator%22%3A%221%22%7D%5D%2C%22properties%22%3A%7B%7D%7D\">(<span class=\"citation-item\">Vaswani \u7b49, 2017, p. 1</span>)</span> \u663e\u6027\u5e8f\u5217\u8f6c\u5bfc\u6a21\u578b</p><p><span class=\"highlight\" data-annotation=\"%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F10101446%2Fitems%2FGXDZU4NV%22%2C%22annotationKey%22%3A%22XU6K6MYP%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%221%22%2C%22position%22%3A%7B%22pageIndex%22%3A0%2C%22rects%22%3A%5B%5B168.294%2C376.576%2C191.619%2C385.483%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F10101446%2Fitems%2FZRJI4HYN%22%5D%2C%22locator%22%3A%221%22%7D%7D\">\u201csolely\u201d</span> <span class=\"citation\" data-citation=\"%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F10101446%2Fitems%2FZRJI4HYN%22%5D%2C%22locator%22%3A%221%22%7D%5D%2C%22properties%22%3A%7B%7D%7D\">(<span class=\"citation-item\">Vaswani \u7b49, 2017, p. 1</span>)</span> \u4ec5\u4ec5<br><br>\u82f1<i>/</i>\u02c8s\u0259\u028alli<i>/</i></p><p><span class=\"highlight\" data-annotation=\"%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F10101446%2Fitems%2FGXDZU4NV%22%2C%22annotationKey%22%3A%22D9DPK8KC%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%221%22%2C%22position%22%3A%7B%22pageIndex%22%3A0%2C%22rects%22%3A%5B%5B295.09%2C376.576%2C336.858%2C385.483%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F10101446%2Fitems%2FZRJI4HYN%22%5D%2C%22locator%22%3A%221%22%7D%7D\">\u201cdispensing\u201d</span> <span class=\"citation\" data-citation=\"%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F10101446%2Fitems%2FZRJI4HYN%22%5D%2C%22locator%22%3A%221%22%7D%5D%2C%22properties%22%3A%7B%7D%7D\">(<span class=\"citation-item\">Vaswani \u7b49, 2017, p. 1</span>)</span> \u7f8e<i>/</i>d\u026a\u02c8spens\u026a\u014b<br>n.\u914d\u836f\uff1b\u8c03\u5242v.\u914d\u836f\uff1b\u5206\u53d1\uff1b\u6267\u884c\uff1b\u7279\u8d66\uff08dispense \u7684 ing \u5f62\u5f0f\uff09</p><p><span class=\"highlight\" data-annotation=\"%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F10101446%2Fitems%2FGXDZU4NV%22%2C%22annotationKey%22%3A%22DD3WQ84S%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%221%22%2C%22position%22%3A%7B%22pageIndex%22%3A0%2C%22rects%22%3A%5B%5B143.866%2C365.667%2C174.91%2C374.574%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F10101446%2Fitems%2FZRJI4HYN%22%5D%2C%22locator%22%3A%221%22%7D%7D\">\u201centirely\u201d</span> <span class=\"citation\" data-citation=\"%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F10101446%2Fitems%2FZRJI4HYN%22%5D%2C%22locator%22%3A%221%22%7D%5D%2C%22properties%22%3A%7B%7D%7D\">(<span class=\"citation-item\">Vaswani \u7b49, 2017, p. 1</span>)</span> \u82f1<i>/</i>\u026an\u02c8ta\u026a\u0259li<i>/</i><br><i>\u5b8c\u5168\u7684</i></p><p><span class=\"highlight\" data-annotation=\"%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F10101446%2Fitems%2FGXDZU4NV%22%2C%22annotationKey%22%3A%22GT7HLBSY%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%221%22%2C%22position%22%3A%7B%22pageIndex%22%3A0%2C%22rects%22%3A%5B%5B221.254%2C210.181%2C326.957%2C219.088%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F10101446%2Fitems%2FZRJI4HYN%22%5D%2C%22locator%22%3A%221%22%7D%7D\">\u201clong short-term memory [\u201d</span> <span class=\"citation\" data-citation=\"%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F10101446%2Fitems%2FZRJI4HYN%22%5D%2C%22locator%22%3A%221%22%7D%5D%2C%22properties%22%3A%7B%7D%7D\">(<span class=\"citation-item\">Vaswani \u7b49, 2017, p. 1</span>)</span> \ud83d\udd24\u957f\u77ed\u671f\u8bb0\u5fc6[\ud83d\udd24</p><p><span class=\"highlight\" data-annotation=\"%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F10101446%2Fitems%2FGXDZU4NV%22%2C%22annotationKey%22%3A%22SRVJZQST%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%221%22%2C%22position%22%3A%7B%22pageIndex%22%3A0%2C%22rects%22%3A%5B%5B360.339%2C210.181%2C421.656%2C219.088%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F10101446%2Fitems%2FZRJI4HYN%22%5D%2C%22locator%22%3A%221%22%7D%7D\">\u201cgated recurrent\u201d</span> <span class=\"citation\" data-citation=\"%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F10101446%2Fitems%2FZRJI4HYN%22%5D%2C%22locator%22%3A%221%22%7D%5D%2C%22properties%22%3A%7B%7D%7D\">(<span class=\"citation-item\">Vaswani \u7b49, 2017, p. 1</span>)</span> \ud83d\udd24\u95e8\u63a7\u5faa\u73af\ud83d\udd24</p><p><span class=\"highlight\" data-annotation=\"%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F10101446%2Fitems%2FGXDZU4NV%22%2C%22annotationKey%22%3A%22YJ9J7IGL%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%221%22%2C%22position%22%3A%7B%22pageIndex%22%3A0%2C%22rects%22%3A%5B%5B204.73%2C199.272%2C229.503%2C208.179%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F10101446%2Fitems%2FZRJI4HYN%22%5D%2C%22locator%22%3A%221%22%7D%7D\">\u201cfirmly\u201d</span> <span class=\"citation\" data-citation=\"%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F10101446%2Fitems%2FZRJI4HYN%22%5D%2C%22locator%22%3A%221%22%7D%5D%2C%22properties%22%3A%7B%7D%7D\">(<span class=\"citation-item\">Vaswani \u7b49, 2017, p. 1</span>)</span> \ud83d\udd24firmly<br>\u82f1 [\u02c8f\u025c\u02d0mli]<br>\u7f8e [\u02c8f\u025c\u02d0rmli]<br>adv. \u575a\u56fa\u5730\uff0c\u7262\u56fa\u5730\uff1b\u5f3a\u800c\u6709\u529b\u5730\uff1b\u575a\u51b3\u5730\ud83d\udd24</p><p><span class=\"highlight\" data-annotation=\"%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F10101446%2Fitems%2FGXDZU4NV%22%2C%22annotationKey%22%3A%22ZGINCP6R%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%222%22%2C%22position%22%3A%7B%22pageIndex%22%3A1%2C%22rects%22%3A%5B%5B108%2C707.885%2C158.24%2C716.792%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F10101446%2Fitems%2FZRJI4HYN%22%5D%2C%22locator%22%3A%222%22%7D%7D\">\u201ctransduction\u201d</span> <span class=\"citation\" data-citation=\"%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F10101446%2Fitems%2FZRJI4HYN%22%5D%2C%22locator%22%3A%222%22%7D%5D%2C%22properties%22%3A%7B%7D%7D\">(<span class=\"citation-item\">Vaswani \u7b49, 2017, p. 2</span>)</span> \ud83d\udd24transduction<br>\u82f1 [tr\u00e6nz\u02c8d\u028ck\u0283\u0259n]<br>\u7f8e [tr\u00e6ns\u02c8d\u028ck\u0283n]<br>n. [\u9057] \u8f6c\u5bfc\uff1b\u8f6c\u6362\uff1b\u6362\u80fd\uff1b\u53d8\u9891\ud83d\udd24</p><p><span class=\"highlight\" data-annotation=\"%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F10101446%2Fitems%2FGXDZU4NV%22%2C%22annotationKey%22%3A%22AP3VD38D%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%222%22%2C%22position%22%3A%7B%22pageIndex%22%3A1%2C%22rects%22%3A%5B%5B461.668%2C707.885%2C504.002%2C716.792%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F10101446%2Fitems%2FZRJI4HYN%22%5D%2C%22locator%22%3A%222%22%7D%7D\">\u201cNumerous\u201d</span> <span class=\"citation\" data-citation=\"%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F10101446%2Fitems%2FZRJI4HYN%22%5D%2C%22locator%22%3A%222%22%7D%5D%2C%22properties%22%3A%7B%7D%7D\">(<span class=\"citation-item\">Vaswani \u7b49, 2017, p. 2</span>)</span> \ud83d\udd24numerous<br>\u82f1 [\u02c8nju\u02d0m\u0259r\u0259s]<br>\u7f8e [\u02c8nu\u02d0m\u0259r\u0259s]<br>adj. \u4f17\u591a\u7684\uff0c\u8bb8\u591a\u7684<br>[ \u6bd4\u8f83\u7ea7 more numerous \u6700\u9ad8\u7ea7 most numerous ]\ud83d\udd24</p><p><span class=\"highlight\" data-annotation=\"%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F10101446%2Fitems%2FGXDZU4NV%22%2C%22annotationKey%22%3A%22UDP8TQH7%22%2C%22color%22%3A%22%232ea8e5%22%2C%22pageLabel%22%3A%223%22%2C%22position%22%3A%7B%22pageIndex%22%3A2%2C%22rects%22%3A%5B%5B343.97%2C284.241%2C503.999%2C293.148%5D%2C%5B108%2C273.332%2C504.166%2C282.398%5D%2C%5B108%2C262.423%2C127.925%2C271.33%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F10101446%2Fitems%2FZRJI4HYN%22%5D%2C%22locator%22%3A%223%22%7D%7D\">\u201cThat is, the output of each sub-layer is LayerNorm(x + Sublayer(x)), where Sublayer(x) is the function implemented by the sub-layer itself\u201d</span> <span class=\"citation\" data-citation=\"%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F10101446%2Fitems%2FZRJI4HYN%22%5D%2C%22locator%22%3A%223%22%7D%5D%2C%22properties%22%3A%7B%7D%7D\">(<span class=\"citation-item\">Vaswani \u7b49, 2017, p. 3</span>)</span></p><p><span class=\"highlight\" data-annotation=\"%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F10101446%2Fitems%2FGXDZU4NV%22%2C%22annotationKey%22%3A%22R4AG5MKR%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%226%22%2C%22position%22%3A%7B%22pageIndex%22%3A5%2C%22rects%22%3A%5B%5B343.353%2C271.741%2C345.839%2C280.648%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F10101446%2Fitems%2FZRJI4HYN%22%5D%2C%22locator%22%3A%226%22%7D%7D\">\u201c.\u201d</span> <span class=\"citation\" data-citation=\"%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F10101446%2Fitems%2FZRJI4HYN%22%5D%2C%22locator%22%3A%226%22%7D%5D%2C%22properties%22%3A%7B%7D%7D\">(<span class=\"citation-item\">Vaswani \u7b49, 2017, p. 6</span>)</span> \u5728\u672c\u8282\u4e2d\uff0c\u6211\u4eec\u5c06\u81ea\u6ce8\u610f\u529b\u5c42\u7684\u5404\u4e2a\u65b9\u9762\u4e0e\u5faa\u73af\u5c42\u548c\u5377\u79ef\u5c42\u8fdb\u884c\u6bd4\u8f83\uff0c\u8fd9\u4e9b\u5c42\u901a\u5e38\u7528\u4e8e\u5c06\u7b26\u53f7\u8868\u793a\u7684\u4e00\u4e2a\u53ef\u53d8\u957f\u5ea6\u5e8f\u5217\uff08x1\uff0c...\uff0cxn\uff09\u6620\u5c04\u5230\u53e6\u4e00\u4e2a\u7b49\u957f\u5ea6\u5e8f\u5217\uff08z1\uff0c.. ., zn)\uff0c\u5176\u4e2d xi, zi \u2208 Rd\uff0c\u4f8b\u5982\u5178\u578b\u5e8f\u5217\u8f6c\u5bfc\u7f16\u7801\u5668\u6216\u89e3\u7801\u5668\u4e2d\u7684\u9690\u85cf\u5c42\u3002</p><p><span class=\"highlight\" data-annotation=\"%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F10101446%2Fitems%2FGXDZU4NV%22%2C%22annotationKey%22%3A%22K69BY35L%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%226%22%2C%22position%22%3A%7B%22pageIndex%22%3A5%2C%22rects%22%3A%5B%5B166.65%2C260.832%2C207.038%2C269.739%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F10101446%2Fitems%2FZRJI4HYN%22%5D%2C%22locator%22%3A%226%22%7D%7D\">\u201cdesiderata\u201d</span> <span class=\"citation\" data-citation=\"%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F10101446%2Fitems%2FZRJI4HYN%22%5D%2C%22locator%22%3A%226%22%7D%5D%2C%22properties%22%3A%7B%7D%7D\">(<span class=\"citation-item\">Vaswani \u7b49, 2017, p. 6</span>)</span> \ud83d\udd24desiderata<br>\u82f1 [d\u026a\u02ccz\u026ad\u0259\u02c8re\u026at\u0259]<br>\u7f8e [d\u026a\u02ccz\u026ad\u0259\u02c8ret\u0259m]<br>n. \uff08\u62c9\u4e01\uff09\u8feb\u5207\u9700\u8981\u5f97\u5230\u4e4b\u7269\uff08desideratum \u7684\u590d\u6570\uff09<br>n. \uff08Desiderata\uff09\u4eba\u540d\uff1b\uff08\u82f1\uff09\u5fb7\u897f\u5fb7\u857e\u5854\ud83d\udd24</p><p><span class=\"highlight\" data-annotation=\"%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F10101446%2Fitems%2FGXDZU4NV%22%2C%22annotationKey%22%3A%22EBMIELV4%22%2C%22color%22%3A%22%232ea8e5%22%2C%22pageLabel%22%3A%226%22%2C%22position%22%3A%7B%22pageIndex%22%3A5%2C%22rects%22%3A%5B%5B171.156%2C244.443%2C275.439%2C253.35%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F10101446%2Fitems%2FZRJI4HYN%22%5D%2C%22locator%22%3A%226%22%7D%7D\">\u201ccomputational complexity\u201d</span> <span class=\"citation\" data-citation=\"%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F10101446%2Fitems%2FZRJI4HYN%22%5D%2C%22locator%22%3A%226%22%7D%5D%2C%22properties%22%3A%7B%7D%7D\">(<span class=\"citation-item\">Vaswani \u7b49, 2017, p. 6</span>)</span> \ud83d\udd24\u8ba1\u7b97\u590d\u6742\u5ea6\ud83d\udd24</p><p><span class=\"highlight\" data-annotation=\"%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F10101446%2Fitems%2FGXDZU4NV%22%2C%22annotationKey%22%3A%22GJ5X4DQ9%22%2C%22color%22%3A%22%232ea8e5%22%2C%22pageLabel%22%3A%226%22%2C%22position%22%3A%7B%22pageIndex%22%3A5%2C%22rects%22%3A%5B%5B420.351%2C244.443%2C504%2C253.35%5D%2C%5B108%2C233.534%2C166.371%2C242.441%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F10101446%2Fitems%2FZRJI4HYN%22%5D%2C%22locator%22%3A%226%22%7D%7D\">\u201ccomputation that can be parallelized\u201d</span> <span class=\"citation\" data-citation=\"%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F10101446%2Fitems%2FZRJI4HYN%22%5D%2C%22locator%22%3A%226%22%7D%5D%2C%22properties%22%3A%7B%7D%7D\">(<span class=\"citation-item\">Vaswani \u7b49, 2017, p. 6</span>)</span> \ud83d\udd24\u53ef\u5e76\u884c\u8ba1\u7b97\ud83d\udd24</p><p><span class=\"highlight\" data-annotation=\"%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F10101446%2Fitems%2FGXDZU4NV%22%2C%22annotationKey%22%3A%223LVKYAXJ%22%2C%22color%22%3A%22%232ea8e5%22%2C%22pageLabel%22%3A%226%22%2C%22position%22%3A%7B%22pageIndex%22%3A5%2C%22rects%22%3A%5B%5B171.388%2C217.146%2C415.89%2C226.053%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F10101446%2Fitems%2FZRJI4HYN%22%5D%2C%22locator%22%3A%226%22%7D%7D\">\u201cpath length between long-range dependencies in the network\u201d</span> <span class=\"citation\" data-citation=\"%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F10101446%2Fitems%2FZRJI4HYN%22%5D%2C%22locator%22%3A%226%22%7D%5D%2C%22properties%22%3A%7B%7D%7D\">(<span class=\"citation-item\">Vaswani \u7b49, 2017, p. 6</span>)</span> \ud83d\udd24\u7f51\u7edc\u4e2d\u8fdc\u7a0b\u4f9d\u8d56\u4e4b\u95f4\u7684\u8def\u5f84\u957f\u5ea6\ud83d\udd24</p><p><span class=\"highlight\" data-annotation=\"%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F10101446%2Fitems%2FGXDZU4NV%22%2C%22annotationKey%22%3A%22VAD6FTWC%22%2C%22color%22%3A%22%232ea8e5%22%2C%22pageLabel%22%3A%226%22%2C%22position%22%3A%7B%22pageIndex%22%3A5%2C%22rects%22%3A%5B%5B206.006%2C184.418%2C503.998%2C193.325%5D%2C%5B108%2C173.509%2C385.351%2C182.416%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F10101446%2Fitems%2FZRJI4HYN%22%5D%2C%22locator%22%3A%226%22%7D%7D\">\u201cThe shorter these paths between any combination of positions in the input and output sequences, the easier it is to learn long-range dependencies\u201d</span> <span class=\"citation\" data-citation=\"%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F10101446%2Fitems%2FZRJI4HYN%22%5D%2C%22locator%22%3A%226%22%7D%5D%2C%22properties%22%3A%7B%7D%7D\">(<span class=\"citation-item\">Vaswani \u7b49, 2017, p. 6</span>)</span> \ud83d\udd24\u8f93\u5165\u548c\u8f93\u51fa\u5e8f\u5217\u4e2d\u7684\u4efb\u610f\u4f4d\u7f6e\u7ec4\u5408\u4e4b\u95f4\u7684\u8def\u5f84\u8d8a\u77ed\uff0c\u5b66\u4e60\u8fdc\u7a0b\u4f9d\u8d56\u5173\u7cfb\u5c31\u8d8a\u5bb9\u6613\ud83d\udd24</p><p><span class=\"highlight\" data-annotation=\"%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F10101446%2Fitems%2FGXDZU4NV%22%2C%22annotationKey%22%3A%226B62YBL7%22%2C%22color%22%3A%22%232ea8e5%22%2C%22pageLabel%22%3A%226%22%2C%22position%22%3A%7B%22pageIndex%22%3A5%2C%22rects%22%3A%5B%5B458.089%2C124.393%2C504%2C133.459%5D%2C%5B108%2C113.484%2C503.997%2C122.391%5D%2C%5B108%2C102.575%2C359.339%2C111.641%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F10101446%2Fitems%2FZRJI4HYN%22%5D%2C%22locator%22%3A%226%22%7D%7D\">\u201cIn terms of computational complexity, self-attention layers are faster than recurrent layers when the sequence length n is smaller than the representation dimensionality d,\u201d</span> <span class=\"citation\" data-citation=\"%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F10101446%2Fitems%2FZRJI4HYN%22%5D%2C%22locator%22%3A%226%22%7D%5D%2C%22properties%22%3A%7B%7D%7D\">(<span class=\"citation-item\">Vaswani \u7b49, 2017, p. 6</span>)</span> \ud83d\udd24\u5c31\u8ba1\u7b97\u590d\u6742\u5ea6\u800c\u8a00\uff0c\u5f53\u5e8f\u5217\u957f\u5ea6 n \u5c0f\u4e8e\u8868\u793a\u7ef4\u5ea6 d \u65f6\uff0c\u81ea\u6ce8\u610f\u529b\u5c42\u6bd4\u5faa\u73af\u5c42\u66f4\u5feb\uff0c\ud83d\udd24</p><p><span class=\"highlight\" data-annotation=\"%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F10101446%2Fitems%2FGXDZU4NV%22%2C%22annotationKey%22%3A%222TKAYR4Q%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%226%22%2C%22position%22%3A%7B%22pageIndex%22%3A5%2C%22rects%22%3A%5B%5B466.168%2C80.757%2C504.003%2C89.664%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F10101446%2Fitems%2FZRJI4HYN%22%5D%2C%22locator%22%3A%226%22%7D%7D\">\u201cinvolving\u201d</span> <span class=\"citation\" data-citation=\"%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F10101446%2Fitems%2FZRJI4HYN%22%5D%2C%22locator%22%3A%226%22%7D%5D%2C%22properties%22%3A%7B%7D%7D\">(<span class=\"citation-item\">Vaswani \u7b49, 2017, p. 6</span>)</span> \ud83d\udd24involving<br>v. \u6d89\u53ca\uff1b\u5305\u62ec\uff1b\u4f7f\u9677\u4e8e\uff08involve \u7684 ing \u5f62\u5f0f\uff09\ud83d\udd24</p><p><span class=\"highlight\" data-annotation=\"%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F10101446%2Fitems%2FGXDZU4NV%22%2C%22annotationKey%22%3A%22JPTF5PJU%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%226%22%2C%22position%22%3A%7B%22pageIndex%22%3A5%2C%22rects%22%3A%5B%5B281.226%2C69.848%2C317.556%2C78.914%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F10101446%2Fitems%2FZRJI4HYN%22%5D%2C%22locator%22%3A%226%22%7D%7D\">\u201crestricted\u201d</span> <span class=\"citation\" data-citation=\"%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F10101446%2Fitems%2FZRJI4HYN%22%5D%2C%22locator%22%3A%226%22%7D%5D%2C%22properties%22%3A%7B%7D%7D\">(<span class=\"citation-item\">Vaswani \u7b49, 2017, p. 6</span>)</span> \ud83d\udd24restricted<br>\u82f1 [r\u026a\u02c8str\u026akt\u026ad]<br>\u7f8e [r\u026a\u02c8str\u026akt\u026ad]<br>adj. \uff08\u5927\u5c0f\u6216\u6570\u91cf\uff09\u6709\u9650\u7684\uff0c\u5f88\u5c0f\u7684\uff1b\uff08\u6307\u80fd\u505a\u7684\u4e8b\uff09\u6709\u9650\u7684\uff0c\u53d7\u9650\u5236\u7684\uff1b\u53d7\uff08\u6cd5\u89c4\uff09\u5236\u7ea6\u7684\uff0c\u53d7\u63a7\u5236\u7684\uff1b\u4e0d\u5bf9\u516c\u4f17\u5f00\u653e\u7684\uff1b\uff08\u6587\u4ef6\uff09\u4fdd\u5bc6\u7684\uff0c\u9650\u4e8e\u5185\u90e8\u4f20\u9605\u7684\uff1b\uff08\u75c5\u6bd2\u7e41\u6b96\u901f\u7387\uff09\u88ab\u9650\u5236\u7684\uff1b\uff08DNA\uff09\u56e0\u9650\u5236\u9176\u9176\u5207\u7684<br>v. \u9650\u5236\uff0c\u9650\u5b9a\uff08\u6570\u91cf\u3001\u8303\u56f4\u7b49\uff09\uff1b\u7ea6\u675f\uff0c\u9650\u5236\uff08\u884c\u52a8\u6216\u6d3b\u52a8\uff09\uff1b\uff08\u4ee5\u6cd5\u89c4\uff09\u9650\u5236\uff08restrict \u7684\u8fc7\u53bb\u5f0f\u548c\u8fc7\u53bb\u5206\u8bcd\uff09\ud83d\udd24</p><p><span class=\"highlight\" data-annotation=\"%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F10101446%2Fitems%2FGXDZU4NV%22%2C%22annotationKey%22%3A%22SNC65WNL%22%2C%22color%22%3A%22%232ea8e5%22%2C%22pageLabel%22%3A%227%22%2C%22position%22%3A%7B%22pageIndex%22%3A6%2C%22rects%22%3A%5B%5B368.886%2C707.885%2C504.001%2C716.792%5D%2C%5B108%2C696.976%2C196.642%2C706.042%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F10101446%2Fitems%2FZRJI4HYN%22%5D%2C%22locator%22%3A%227%22%7D%7D\">\u201cThis would increase the maximum path length to O(n/r)\u201d</span> <span class=\"citation\" data-citation=\"%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F10101446%2Fitems%2FZRJI4HYN%22%5D%2C%22locator%22%3A%227%22%7D%5D%2C%22properties%22%3A%7B%7D%7D\">(<span class=\"citation-item\">Vaswani \u7b49, 2017, p. 7</span>)</span> \ud83d\udd24\u8fd9\u4f1a\u5c06\u6700\u5927\u8def\u5f84\u957f\u5ea6\u589e\u52a0\u5230 O(n/r)\ud83d\udd24</p><p><span class=\"highlight\" data-annotation=\"%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F10101446%2Fitems%2FGXDZU4NV%22%2C%22annotationKey%22%3A%22XI7252GW%22%2C%22color%22%3A%22%232ea8e5%22%2C%22pageLabel%22%3A%227%22%2C%22position%22%3A%7B%22pageIndex%22%3A6%2C%22rects%22%3A%5B%5B107.641%2C680.588%2C504%2C689.654%5D%2C%5B108%2C669.679%2C143.265%2C678.745%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F10101446%2Fitems%2FZRJI4HYN%22%5D%2C%22locator%22%3A%227%22%7D%7D\">\u201cA single convolutional layer with kernel width k &lt; n does not connect all pairs of input and output positions\u201d</span> <span class=\"citation\" data-citation=\"%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F10101446%2Fitems%2FZRJI4HYN%22%5D%2C%22locator%22%3A%227%22%7D%5D%2C%22properties%22%3A%7B%7D%7D\">(<span class=\"citation-item\">Vaswani \u7b49, 2017, p. 7</span>)</span> \u56e0\u4e3a\u5377\u79ef\u64cd\u4f5c\u662f\u901a\u8fc7\u6ed1\u52a8\u5377\u79ef\u6838\u6765\u6267\u884c\u7684\uff0c\u5bf9\u4e8e\u8f93\u5165\u7684\u6bcf\u4e2a\u4f4d\u7f6e\uff0c\u5377\u79ef\u6838\u5c06\u4e0e\u5176\u90e8\u5206\u50cf\u7d20\u76f8\u4e58\u5e76\u6c42\u548c\uff0c\u7136\u540e\u5c06\u7ed3\u679c\u653e\u7f6e\u5728\u8f93\u51fa\u7279\u5f81\u56fe\u7684\u5bf9\u5e94\u4f4d\u7f6e\u4e0a\u3002\u4f46\u7531\u4e8e\u5377\u79ef\u6838\u7684\u5bbd\u5ea6\u6709\u9650\uff0c\u5b83\u4e0d\u4f1a\u4e0e\u8f93\u5165\u7684\u6240\u6709\u50cf\u7d20\u90fd\u76f8\u4e58\uff0c\u56e0\u6b64\u4e0d\u4f1a\u8fde\u63a5\u6240\u6709\u8f93\u5165\u548c\u8f93\u51fa\u4f4d\u7f6e\u5bf9\u3002</p><p><span class=\"highlight\" data-annotation=\"%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F10101446%2Fitems%2FGXDZU4NV%22%2C%22annotationKey%22%3A%22T2L9WHU6%22%2C%22color%22%3A%22%232ea8e5%22%2C%22pageLabel%22%3A%227%22%2C%22position%22%3A%7B%22pageIndex%22%3A6%2C%22rects%22%3A%5B%5B259.993%2C669.679%2C505.242%2C678.745%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F10101446%2Fitems%2FZRJI4HYN%22%5D%2C%22locator%22%3A%227%22%7D%7D\">\u201cO(n/k) convolutional layers in the case of contiguous kernels,\u201d</span> <span class=\"citation\" data-citation=\"%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F10101446%2Fitems%2FZRJI4HYN%22%5D%2C%22locator%22%3A%227%22%7D%5D%2C%22properties%22%3A%7B%7D%7D\">(<span class=\"citation-item\">Vaswani \u7b49, 2017, p. 7</span>)</span> \ud83d\udd24\u5728\u8fde\u7eed\u5185\u6838\u7684\u60c5\u51b5\u4e0b\uff0cO(n/k) \u4e2a\u5377\u79ef\u5c42\uff0c\ud83d\udd24</p><p><span class=\"highlight\" data-annotation=\"%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F10101446%2Fitems%2FGXDZU4NV%22%2C%22annotationKey%22%3A%224RBKIK4A%22%2C%22color%22%3A%22%232ea8e5%22%2C%22pageLabel%22%3A%227%22%2C%22position%22%3A%7B%22pageIndex%22%3A6%2C%22rects%22%3A%5B%5B119.4%2C658.074%2C309.858%2C667.836%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F10101446%2Fitems%2FZRJI4HYN%22%5D%2C%22locator%22%3A%227%22%7D%7D\">\u201cO(logk(n)) in the case of dilated convolutions\u201d</span> <span class=\"citation\" data-citation=\"%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F10101446%2Fitems%2FZRJI4HYN%22%5D%2C%22locator%22%3A%227%22%7D%5D%2C%22properties%22%3A%7B%7D%7D\">(<span class=\"citation-item\">Vaswani \u7b49, 2017, p. 7</span>)</span> \ud83d\udd24\u5728\u6269\u5f20\u5377\u79ef\u7684\u60c5\u51b5\u4e0b\u4e3a O(logk(n))\ud83d\udd24</p><p><span class=\"highlight\" data-annotation=\"%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F10101446%2Fitems%2FGXDZU4NV%22%2C%22annotationKey%22%3A%227EVTG9AT%22%2C%22color%22%3A%22%232ea8e5%22%2C%22pageLabel%22%3A%227%22%2C%22position%22%3A%7B%22pageIndex%22%3A6%2C%22rects%22%3A%5B%5B280.698%2C647.86%2C503.999%2C656.767%5D%2C%5B108%2C636.951%2C504.351%2C646.017%5D%2C%5B108%2C626.042%2C262.473%2C636.65%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F10101446%2Fitems%2FZRJI4HYN%22%5D%2C%22locator%22%3A%227%22%7D%7D\">\u201cConvolutional layers are generally more expensive than recurrent layers, by a factor of k. Separable convolutions [6], however, decrease the complexity considerably, to O(k \u00b7 n \u00b7 d + n \u00b7 d2).\u201d</span> <span class=\"citation\" data-citation=\"%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F10101446%2Fitems%2FZRJI4HYN%22%5D%2C%22locator%22%3A%227%22%7D%5D%2C%22properties%22%3A%7B%7D%7D\">(<span class=\"citation-item\">Vaswani \u7b49, 2017, p. 7</span>)</span> \ud83d\udd24\u5377\u79ef\u5c42\u901a\u5e38\u6bd4\u5faa\u73af\u5c42\u8d35 k \u500d\u3002\u7136\u800c\uff0c\u53ef\u5206\u79bb\u5377\u79ef [6] \u5927\u5927\u964d\u4f4e\u4e86\u590d\u6742\u6027\uff0c\u8fbe\u5230 O(k\u00b7n\u00b7d + n\u00b7d2)\u3002\ud83d\udd24</p>\n</div>",
          "tags": [],
          "relations": {},
          "dateAdded": "2023-09-30T07:56:10Z",
          "dateModified": "2023-09-30T07:56:10Z",
          "uri": "http://zotero.org/users/10101446/items/X5TJU3WQ"
        }
      ],
      "citationKey": "vaswani2017-attention",
      "itemKey": "ZRJI4HYN",
      "libraryID": 1,
      "select": "zotero://select/library/items/ZRJI4HYN"
    },
    {
      "key": "TLCEN9R3",
      "version": 1377,
      "itemType": "preprint",
      "title": "The Instruction Hierarchy: Training LLMs to Prioritize Privileged Instructions",
      "abstractNote": "Today\u2019s LLMs are susceptible to prompt injections, jailbreaks, and other attacks that allow adversaries to overwrite a model\u2019s original instructions with their own malicious prompts. In this work, we argue that one of the primary vulnerabilities underlying these attacks is that LLMs often consider system prompts (e.g., text from an application developer) to be the same priority as text from untrusted users and third parties. To address this, we propose an instruction hierarchy that explicitly defines how models should behave when instructions of different priorities conflict. We then propose an automated data generation method to demonstrate this hierarchical instruction following behavior, which teaches LLMs to selectively ignore lower-privileged instructions. We apply this method to LLMs, showing that it drastically increases robustness\u2014even for attack types not seen during training\u2014while imposing minimal degradations on standard capabilities.",
      "date": "2024-04-19",
      "language": "en",
      "shortTitle": "The Instruction Hierarchy",
      "libraryCatalog": "arXiv.org",
      "url": "http://arxiv.org/abs/2404.13208",
      "accessDate": "2024-04-26T06:21:50Z",
      "extra": "arXiv:2404.13208 [cs]",
      "repository": "arXiv",
      "archiveID": "arXiv:2404.13208",
      "creators": [
        {
          "firstName": "Eric",
          "lastName": "Wallace",
          "creatorType": "author"
        },
        {
          "firstName": "Kai",
          "lastName": "Xiao",
          "creatorType": "author"
        },
        {
          "firstName": "Reimar",
          "lastName": "Leike",
          "creatorType": "author"
        },
        {
          "firstName": "Lilian",
          "lastName": "Weng",
          "creatorType": "author"
        },
        {
          "firstName": "Johannes",
          "lastName": "Heidecke",
          "creatorType": "author"
        },
        {
          "firstName": "Alex",
          "lastName": "Beutel",
          "creatorType": "author"
        }
      ],
      "tags": [
        {
          "tag": "Computer Science - Computation and Language",
          "type": 1
        },
        {
          "tag": "Computer Science - Machine Learning",
          "type": 1
        },
        {
          "tag": "Computer Science - Cryptography and Security",
          "type": 1
        }
      ],
      "relations": {},
      "dateAdded": "2024-04-26T06:21:50Z",
      "dateModified": "2024-04-26T06:21:51Z",
      "uri": "http://zotero.org/users/10101446/items/TLCEN9R3",
      "itemID": 571,
      "attachments": [
        {
          "itemType": "attachment",
          "title": "Wallace \u7b49 - 2024 - The Instruction Hierarchy Training LLMs to Priori.pdf",
          "tags": [],
          "relations": {},
          "dateAdded": "2024-04-26T06:21:45Z",
          "dateModified": "2024-04-26T06:21:51Z",
          "uri": "http://zotero.org/users/10101446/items/JE8CKEEN",
          "path": "C:\\Users\\gyh14\\Zotero\\storage\\JE8CKEEN\\Wallace \u7b49 - 2024 - The Instruction Hierarchy Training LLMs to Priori.pdf",
          "select": "zotero://select/library/items/JE8CKEEN"
        }
      ],
      "notes": [],
      "citationKey": "wallace2024-instruction",
      "itemKey": "TLCEN9R3",
      "libraryID": 1,
      "select": "zotero://select/library/items/TLCEN9R3"
    },
    {
      "key": "C3R8DANM",
      "version": 1085,
      "itemType": "preprint",
      "title": "Diffusion Policies as an Expressive Policy Class for Offline Reinforcement Learning",
      "abstractNote": "Offline reinforcement learning (RL), which aims to learn an optimal policy using a previously collected static dataset, is an important paradigm of RL. Standard RL methods often perform poorly in this regime due to the function approximation errors on out-of-distribution actions. While a variety of regularization methods have been proposed to mitigate this issue, they are often constrained by policy classes with limited expressiveness that can lead to highly suboptimal solutions. In this paper, we propose representing the policy as a diffusion model, a recent class of highly-expressive deep generative models. We introduce Diffusion Qlearning (Diffusion-QL) that utilizes a conditional diffusion model to represent the policy. In our approach, we learn an action-value function and we add a term maximizing action-values into the training loss of the conditional diffusion model, which results in a loss that seeks optimal actions that are near the behavior policy. We show the expressiveness of the diffusion model-based policy, and the coupling of the behavior cloning and policy improvement under the diffusion model both contribute to the outstanding performance of Diffusion-QL. We illustrate the superiority of our method compared to prior works in a simple 2D bandit example with a multimodal behavior policy. We then show that our method can achieve state-of-the-art performance on the majority of the D4RL benchmark tasks.",
      "date": "2023-08-25",
      "language": "en",
      "libraryCatalog": "arXiv.org",
      "url": "http://arxiv.org/abs/2208.06193",
      "accessDate": "2024-02-29T06:36:51Z",
      "extra": "arXiv:2208.06193 [cs, stat]",
      "repository": "arXiv",
      "archiveID": "arXiv:2208.06193",
      "creators": [
        {
          "firstName": "Zhendong",
          "lastName": "Wang",
          "creatorType": "author"
        },
        {
          "firstName": "Jonathan J.",
          "lastName": "Hunt",
          "creatorType": "author"
        },
        {
          "firstName": "Mingyuan",
          "lastName": "Zhou",
          "creatorType": "author"
        }
      ],
      "tags": [
        {
          "tag": "Computer Science - Machine Learning",
          "type": 1
        },
        {
          "tag": "Statistics - Machine Learning",
          "type": 1
        }
      ],
      "relations": {},
      "dateAdded": "2024-02-29T06:36:51Z",
      "dateModified": "2024-02-29T06:36:52Z",
      "uri": "http://zotero.org/users/10101446/items/C3R8DANM",
      "itemID": 489,
      "attachments": [
        {
          "itemType": "attachment",
          "title": "Wang \u7b49 - 2023 - Diffusion Policies as an Expressive Policy Class f.pdf",
          "tags": [],
          "relations": {},
          "dateAdded": "2024-02-29T06:36:42Z",
          "dateModified": "2024-02-29T06:36:53Z",
          "uri": "http://zotero.org/users/10101446/items/UYR389L7",
          "path": "C:\\Users\\gyh14\\Zotero\\storage\\UYR389L7\\Wang \u7b49 - 2023 - Diffusion Policies as an Expressive Policy Class f.pdf",
          "select": "zotero://select/library/items/UYR389L7"
        }
      ],
      "notes": [
        {
          "key": "EZYMLRPW",
          "version": 1085,
          "itemType": "note",
          "parentItem": "C3R8DANM",
          "note": "Comment: ICLR 2023",
          "tags": [],
          "relations": {},
          "dateAdded": "2024-02-29T06:36:51Z",
          "dateModified": "2024-02-29T06:36:51Z",
          "uri": "http://zotero.org/users/10101446/items/EZYMLRPW"
        }
      ],
      "citationKey": "wang2023-diffusion",
      "itemKey": "C3R8DANM",
      "libraryID": 1,
      "select": "zotero://select/library/items/C3R8DANM"
    },
    {
      "key": "3YGY5NG6",
      "version": 1351,
      "itemType": "preprint",
      "title": "RepViT: Revisiting Mobile CNN From ViT Perspective",
      "abstractNote": "Recently, lightweight Vision Transformers (ViTs) demonstrate superior performance and lower latency, compared with lightweight Convolutional Neural Networks (CNNs), on resource-constrained mobile devices. Researchers have discovered many structural connections between lightweight ViTs and lightweight CNNs. However, the notable architectural disparities in the block structure, macro, and micro designs between them have not been adequately examined. In this study, we revisit the efficient design of lightweight CNNs from ViT perspective and emphasize their promising prospect for mobile devices. Specifically, we incrementally enhance the mobile-friendliness of a standard lightweight CNN, i.e., MobileNetV3, by integrating the efficient architectural designs of lightweight ViTs. This ends up with a new family of pure lightweight CNNs, namely RepViT. Extensive experiments show that RepViT outperforms existing state-of-the-art lightweight ViTs and exhibits favorable latency in various vision tasks. Notably, on ImageNet, RepViT achieves over 80% top-1 accuracy with 1.0 ms latency on an iPhone 12, which is the first time for a lightweight model, to the best of our knowledge. Besides, when RepViT meets SAM, our RepViT-SAM can achieve nearly 10\u00d7 faster inference than the advanced MobileSAM. Codes and models are available at https: //github.com/THU-MIG/RepViT.",
      "date": "2024-03-14",
      "language": "en",
      "shortTitle": "RepViT",
      "libraryCatalog": "arXiv.org",
      "url": "http://arxiv.org/abs/2307.09283",
      "accessDate": "2024-04-19T05:50:29Z",
      "extra": "arXiv:2307.09283 [cs]",
      "repository": "arXiv",
      "archiveID": "arXiv:2307.09283",
      "creators": [
        {
          "firstName": "Ao",
          "lastName": "Wang",
          "creatorType": "author"
        },
        {
          "firstName": "Hui",
          "lastName": "Chen",
          "creatorType": "author"
        },
        {
          "firstName": "Zijia",
          "lastName": "Lin",
          "creatorType": "author"
        },
        {
          "firstName": "Jungong",
          "lastName": "Han",
          "creatorType": "author"
        },
        {
          "firstName": "Guiguang",
          "lastName": "Ding",
          "creatorType": "author"
        }
      ],
      "tags": [
        {
          "tag": "Computer Science - Computer Vision and Pattern Recognition",
          "type": 1
        }
      ],
      "relations": {},
      "dateAdded": "2024-04-19T05:50:29Z",
      "dateModified": "2024-04-19T05:50:29Z",
      "uri": "http://zotero.org/users/10101446/items/3YGY5NG6",
      "itemID": 559,
      "attachments": [
        {
          "itemType": "attachment",
          "title": "Wang \u7b49 - 2024 - RepViT Revisiting Mobile CNN From ViT Perspective.pdf",
          "tags": [],
          "relations": {},
          "dateAdded": "2024-04-19T05:50:23Z",
          "dateModified": "2024-04-19T05:50:30Z",
          "uri": "http://zotero.org/users/10101446/items/5TN9NYSR",
          "path": "C:\\Users\\gyh14\\Zotero\\storage\\5TN9NYSR\\Wang \u7b49 - 2024 - RepViT Revisiting Mobile CNN From ViT Perspective.pdf",
          "select": "zotero://select/library/items/5TN9NYSR"
        }
      ],
      "notes": [
        {
          "key": "4BSGFY49",
          "version": 1351,
          "itemType": "note",
          "parentItem": "3YGY5NG6",
          "note": "Comment: CVPR 2024 Camera-ready Version",
          "tags": [],
          "relations": {},
          "dateAdded": "2024-04-19T05:50:29Z",
          "dateModified": "2024-04-19T05:50:29Z",
          "uri": "http://zotero.org/users/10101446/items/4BSGFY49"
        }
      ],
      "citationKey": "wang2024-repvit",
      "itemKey": "3YGY5NG6",
      "libraryID": 1,
      "select": "zotero://select/library/items/3YGY5NG6"
    },
    {
      "key": "3V7KMJ2D",
      "version": 192,
      "itemType": "preprint",
      "title": "Cumulative Reasoning with Large Language Models",
      "abstractNote": "While language models are powerful and versatile, they often fail to address highly complex problems. This is because solving complex problems requires deliberate thinking, which has been only minimally guided during training. In this paper, we propose a new method called Cumulative Reasoning (CR), which employs language models in a cumulative and iterative manner to emulate human thought processes. By decomposing tasks into smaller components, CR streamlines the problem-solving process, rendering it both more manageable and effective. For logical inference tasks, CR consistently outperforms existing methods with an improvement up to 9.3%, and achieves the astonishing accuracy of 98.04% on the curated FOLIO wiki dataset. In the context of the Game of 24, CR achieves an accuracy of 98%, which signi\ufb01es a substantial enhancement of 24% over the previous state-of-the-art method. Finally, on the MATH dataset, we establish new state-of-the-art results with 58.0% overall accuracy, surpassing the previous best approach by a margin of 4.2%, and achieving 43% relative improvement on the hardest level 5 problems (22.4% \u2192 32.1%) \u2020.",
      "date": "2023-08-24",
      "language": "en",
      "libraryCatalog": "arXiv.org",
      "url": "http://arxiv.org/abs/2308.04371",
      "accessDate": "2023-09-05T06:30:28Z",
      "extra": "arXiv:2308.04371 [cs]",
      "repository": "arXiv",
      "archiveID": "arXiv:2308.04371",
      "creators": [
        {
          "firstName": "Yifan",
          "lastName": "Zhang",
          "creatorType": "author"
        },
        {
          "firstName": "Jingqin",
          "lastName": "Yang",
          "creatorType": "author"
        },
        {
          "firstName": "Yang",
          "lastName": "Yuan",
          "creatorType": "author"
        },
        {
          "firstName": "Andrew Chi-Chih",
          "lastName": "Yao",
          "creatorType": "author"
        }
      ],
      "tags": [
        {
          "tag": "Computer Science - Artificial Intelligence",
          "type": 1
        }
      ],
      "relations": {},
      "dateAdded": "2023-09-05T06:30:28Z",
      "dateModified": "2023-09-05T06:30:28Z",
      "uri": "http://zotero.org/users/10101446/items/3V7KMJ2D",
      "itemID": 81,
      "attachments": [
        {
          "itemType": "attachment",
          "title": "Zhang \u7b49 - 2023 - Cumulative Reasoning with Large Language Models.pdf",
          "tags": [],
          "relations": {},
          "dateAdded": "2023-09-05T06:30:22Z",
          "dateModified": "2023-09-05T06:30:29Z",
          "uri": "http://zotero.org/users/10101446/items/IDMY76FY",
          "path": "C:\\Users\\gyh14\\Zotero\\storage\\IDMY76FY\\Zhang \u7b49 - 2023 - Cumulative Reasoning with Large Language Models.pdf",
          "select": "zotero://select/library/items/IDMY76FY"
        }
      ],
      "notes": [],
      "citationKey": "zhangCumulativeReasoningLarge2023",
      "itemKey": "3V7KMJ2D",
      "libraryID": 1,
      "select": "zotero://select/library/items/3V7KMJ2D"
    },
    {
      "key": "2BE3HB69",
      "version": 550,
      "itemType": "journalArticle",
      "title": "Informer: Beyond Efficient Transformer for Long Sequence Time-Series Forecasting",
      "abstractNote": "Many real-world applications require the prediction of long sequence time-series, such as electricity consumption planning. Long sequence time-series forecasting (LSTF) demands a high prediction capacity of the model, which is the ability to capture precise long-range dependency coupling between output and input ef\ufb01ciently. Recent studies have shown the potential of Transformer to increase the prediction capacity. However, there are several severe issues with Transformer that prevent it from being directly applicable to LSTF, including quadratic time complexity, high memory usage, and inherent limitation of the encoder-decoder architecture. To address these issues, we design an ef\ufb01cient transformer-based model for LSTF, named Informer, with three distinctive characteristics: (i) a ProbSparse self-attention mechanism, which achieves O(L log L) in time complexity and memory usage, and has comparable performance on sequences\u2019 dependency alignment. (ii) the self-attention distilling highlights dominating attention by halving cascading layer input, and ef\ufb01ciently handles extreme long input sequences. (iii) the generative style decoder, while conceptually simple, predicts the long time-series sequences at one forward operation rather than a step-by-step way, which drastically improves the inference speed of long-sequence predictions. Extensive experiments on four large-scale datasets demonstrate that Informer signi\ufb01cantly outperforms existing methods and provides a new solution to the LSTF problem.",
      "date": "2021-05-18",
      "language": "en",
      "shortTitle": "Informer",
      "libraryCatalog": "DOI.org (Crossref)",
      "url": "https://ojs.aaai.org/index.php/AAAI/article/view/17325",
      "accessDate": "2023-03-07T22:36:10Z",
      "volume": "35",
      "pages": "11106-11115",
      "publicationTitle": "Proceedings of the AAAI Conference on Artificial Intelligence",
      "DOI": "10.1609/aaai.v35i12.17325",
      "issue": "12",
      "journalAbbreviation": "AAAI",
      "ISSN": "2374-3468, 2159-5399",
      "creators": [
        {
          "firstName": "Haoyi",
          "lastName": "Zhou",
          "creatorType": "author"
        },
        {
          "firstName": "Shanghang",
          "lastName": "Zhang",
          "creatorType": "author"
        },
        {
          "firstName": "Jieqi",
          "lastName": "Peng",
          "creatorType": "author"
        },
        {
          "firstName": "Shuai",
          "lastName": "Zhang",
          "creatorType": "author"
        },
        {
          "firstName": "Jianxin",
          "lastName": "Li",
          "creatorType": "author"
        },
        {
          "firstName": "Hui",
          "lastName": "Xiong",
          "creatorType": "author"
        },
        {
          "firstName": "Wancai",
          "lastName": "Zhang",
          "creatorType": "author"
        }
      ],
      "tags": [],
      "relations": {},
      "dateAdded": "2023-03-07T22:36:10Z",
      "dateModified": "2023-10-14T11:25:11Z",
      "uri": "http://zotero.org/users/10101446/items/2BE3HB69",
      "itemID": 15,
      "attachments": [
        {
          "itemType": "attachment",
          "title": "Zhou \u7b49 - 2021 - Informer Beyond Efficient Transformer for Long Se.pdf",
          "tags": [],
          "relations": {},
          "dateAdded": "2023-03-07T22:36:06Z",
          "dateModified": "2023-03-07T22:36:10Z",
          "uri": "http://zotero.org/users/10101446/items/ZVVAF6CE",
          "path": "C:\\Users\\gyh14\\Zotero\\storage\\ZVVAF6CE\\Zhou \u7b49 - 2021 - Informer Beyond Efficient Transformer for Long Se.pdf",
          "select": "zotero://select/library/items/ZVVAF6CE"
        }
      ],
      "notes": [],
      "citationKey": "zhou2021-informer",
      "itemKey": "2BE3HB69",
      "libraryID": 1,
      "select": "zotero://select/library/items/2BE3HB69"
    }
  ]
}