{
  "config": {
    "id": "36a3b0b5-bad0-4a04-b79b-441c7cef77db",
    "label": "BetterBibTeX JSON",
    "preferences": {
      "ascii": "",
      "asciiBibLaTeX": false,
      "asciiBibTeX": true,
      "autoAbbrev": false,
      "autoAbbrevStyle": "",
      "autoExport": "immediate",
      "autoExportDelay": 5,
      "autoExportIdleWait": 10,
      "autoExportPathReplaceDiacritics": false,
      "autoExportPathReplaceDirSep": "-",
      "autoExportPathReplaceSpace": " ",
      "automaticTags": true,
      "autoPinDelay": 0,
      "auxImport": false,
      "baseAttachmentPath": "",
      "biblatexExtendedDateFormat": true,
      "biblatexExtendedNameFormat": true,
      "biblatexExtractEprint": true,
      "bibtexEditionOrdinal": false,
      "bibtexParticleNoOp": false,
      "bibtexURL": "off",
      "cache": true,
      "cacheFlushInterval": 5,
      "charmap": "",
      "citeCommand": "cite",
      "citekeyFold": true,
      "citekeyFormat": "auth(n=0,m=1,creator=\"*\",initials=false).fold.lower + \"(\" + year + \")-\" + shorttitle(1,0).lower",
      "citekeySearch": true,
      "citekeyUnsafeChars": "\\\"#%'(),={}~",
      "csquotes": "",
      "DOIandURL": "both",
      "exportBibTeXStrings": "off",
      "exportBraceProtection": true,
      "exportTitleCase": true,
      "extraMergeCitekeys": false,
      "extraMergeCSL": false,
      "extraMergeTeX": false,
      "git": "config",
      "import": true,
      "importBibTeXStrings": true,
      "importCaseProtection": "as-needed",
      "importCitationKey": true,
      "importDetectURLs": true,
      "importExtra": true,
      "importJabRefAbbreviations": true,
      "importJabRefStrings": true,
      "importNoteToExtra": "",
      "importSentenceCase": "on+guess",
      "importSentenceCaseQuoted": true,
      "importUnknownTexCommand": "ignore",
      "itemObserverDelay": 5,
      "jabrefFormat": 0,
      "jieba": false,
      "keyConflictPolicy": "keep",
      "keyScope": "library",
      "kuroshiro": false,
      "language": "langid",
      "mapMath": "",
      "mapText": "",
      "mapUnicode": "conservative",
      "parseParticles": true,
      "patchDates": "dateadded=dateAdded, date-added=dateAdded, datemodified=dateModified, date-modified=dateModified",
      "postscript": "",
      "postscriptOverride": "",
      "preferencesOverride": "",
      "qualityReport": false,
      "quickCopyEta": "",
      "quickCopyMode": "latex",
      "quickCopyOrgMode": "zotero",
      "quickCopyPandocBrackets": false,
      "quickCopySelectLink": "zotero",
      "rawImports": false,
      "rawLaTag": "#LaTeX",
      "relativeFilePaths": false,
      "retainCache": false,
      "separatorList": "and",
      "separatorNames": "and",
      "skipFields": "",
      "skipWords": "a,ab,aboard,about,above,across,after,against,al,along,amid,among,an,and,anti,around,as,at,before,behind,below,beneath,beside,besides,between,beyond,but,by,d,da,das,de,del,dell,dello,dei,degli,della,dell,delle,dem,den,der,des,despite,die,do,down,du,during,ein,eine,einem,einen,einer,eines,el,en,et,except,for,from,gli,i,il,in,inside,into,is,l,la,las,le,les,like,lo,los,near,nor,of,off,on,onto,or,over,past,per,plus,round,save,since,so,some,sur,than,the,through,to,toward,towards,un,una,unas,under,underneath,une,unlike,uno,unos,until,up,upon,versus,via,von,while,with,within,without,yet,zu,zum",
      "startupProgress": "popup",
      "strings": "",
      "stringsOverride": "",
      "verbatimFields": "url,doi,file,pdf,ids,eprint,/^verb[a-z]$/,groups,/^citeulike-linkout-[0-9]+$/, /^bdsk-url-[0-9]+$/",
      "warnBulkModify": 10,
      "warnTitleCased": false
    },
    "options": {
      "exportNotes": 1,
      "exportFileData": false,
      "keepUpdated": false,
      "worker": true,
      "Normalize": false
    }
  },
  "version": {
    "zotero": "6.0.27",
    "bbt": "6.7.129"
  },
  "collections": {
    "NNUX237V": {
      "key": "NNUX237V",
      "parent": "",
      "name": "CV",
      "collections": [],
      "items": [
        14
      ]
    },
    "LIVRFJFF": {
      "key": "LIVRFJFF",
      "parent": "",
      "name": "LSTM",
      "collections": [],
      "items": [
        15
      ]
    },
    "K84JTQUN": {
      "key": "K84JTQUN",
      "parent": "",
      "name": "NLP",
      "collections": [],
      "items": [
        15,
        67,
        69,
        81,
        138,
        140,
        142,
        172,
        196,
        339
      ]
    }
  },
  "items": [
    {
      "key": "2QDAQPG3",
      "version": 122,
      "itemType": "attachment",
      "title": "cvpr20_san.pdf",
      "linkMode": "imported_file",
      "contentType": "application/pdf",
      "charset": "",
      "filename": "cvpr20_san.pdf",
      "tags": [],
      "collections": [
        "NNUX237V"
      ],
      "relations": {},
      "dateAdded": "2023-03-17T03:25:06Z",
      "dateModified": "2023-03-17T03:25:06Z",
      "uri": "http://zotero.org/users/10101446/items/2QDAQPG3",
      "itemID": 14,
      "localPath": "C:\\Users\\gyh14\\Zotero\\storage\\2QDAQPG3\\cvpr20_san.pdf",
      "defaultPath": "files/14/cvpr20_san.pdf",
      "itemKey": "2QDAQPG3",
      "libraryID": 1,
      "select": "zotero://select/library/items/2QDAQPG3"
    },
    {
      "key": "YEFMDXK5",
      "version": 501,
      "itemType": "preprint",
      "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding",
      "abstractNote": "We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models (Peters et al., 2018a; Radford et al., 2018), BERT is designed to pretrain deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be Ô¨Ånetuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial taskspeciÔ¨Åc architecture modiÔ¨Åcations.",
      "date": "2019-05-24",
      "language": "en",
      "shortTitle": "BERT",
      "libraryCatalog": "arXiv.org",
      "url": "http://arxiv.org/abs/1810.04805",
      "accessDate": "2023-09-25T03:28:37Z",
      "extra": "arXiv:1810.04805 [cs]",
      "repository": "arXiv",
      "archiveID": "arXiv:1810.04805",
      "creators": [
        {
          "firstName": "Jacob",
          "lastName": "Devlin",
          "creatorType": "author"
        },
        {
          "firstName": "Ming-Wei",
          "lastName": "Chang",
          "creatorType": "author"
        },
        {
          "firstName": "Kenton",
          "lastName": "Lee",
          "creatorType": "author"
        },
        {
          "firstName": "Kristina",
          "lastName": "Toutanova",
          "creatorType": "author"
        }
      ],
      "tags": [
        {
          "tag": "Computer Science - Computation and Language",
          "type": 1
        }
      ],
      "relations": [],
      "dateAdded": "2023-09-25T03:28:37Z",
      "dateModified": "2023-10-02T03:18:28Z",
      "uri": "http://zotero.org/users/10101446/items/YEFMDXK5",
      "itemID": 196,
      "attachments": [
        {
          "itemType": "attachment",
          "title": "Devlin Á≠â - 2019 - BERT Pre-training of Deep Bidirectional Transform.pdf",
          "tags": [],
          "relations": [],
          "dateAdded": "2023-09-25T03:28:32Z",
          "dateModified": "2023-09-25T03:28:37Z",
          "uri": "http://zotero.org/users/10101446/items/K4FEEV4X",
          "path": "C:\\Users\\gyh14\\Zotero\\storage\\K4FEEV4X\\Devlin Á≠â - 2019 - BERT Pre-training of Deep Bidirectional Transform.pdf",
          "select": "zotero://select/library/items/K4FEEV4X"
        }
      ],
      "notes": [],
      "citationKey": "devlin2019-bert",
      "itemKey": "YEFMDXK5",
      "libraryID": 1,
      "select": "zotero://select/library/items/YEFMDXK5"
    },
    {
      "key": "TC8XWH8A",
      "version": 97,
      "itemType": "preprint",
      "title": "Texture Synthesis Using Convolutional Neural Networks",
      "abstractNote": "Here we introduce a new model of natural textures based on the feature spaces of convolutional neural networks optimised for object recognition. Samples from the model are of high perceptual quality demonstrating the generative power of neural networks trained in a purely discriminative fashion. Within the model, textures are represented by the correlations between feature maps in several layers of the network. We show that across layers the texture representations increasingly capture the statistical properties of natural images while making object information more and more explicit. The model provides a new tool to generate stimuli for neuroscience and might offer insights into the deep representations learned by convolutional neural networks.",
      "date": "2015-11-06",
      "language": "en",
      "libraryCatalog": "arXiv.org",
      "url": "http://arxiv.org/abs/1505.07376",
      "accessDate": "2023-03-07T07:15:56Z",
      "extra": "arXiv:1505.07376 [cs, q-bio]",
      "repository": "arXiv",
      "archiveID": "arXiv:1505.07376",
      "creators": [
        {
          "firstName": "Leon A.",
          "lastName": "Gatys",
          "creatorType": "author"
        },
        {
          "firstName": "Alexander S.",
          "lastName": "Ecker",
          "creatorType": "author"
        },
        {
          "firstName": "Matthias",
          "lastName": "Bethge",
          "creatorType": "author"
        }
      ],
      "tags": [
        {
          "tag": "Computer Science - Computer Vision and Pattern Recognition",
          "type": 1
        },
        {
          "tag": "Computer Science - Neural and Evolutionary Computing",
          "type": 1
        },
        {
          "tag": "Quantitative Biology - Neurons and Cognition",
          "type": 1
        }
      ],
      "relations": [],
      "dateAdded": "2023-03-07T07:15:56Z",
      "dateModified": "2023-03-07T07:15:56Z",
      "uri": "http://zotero.org/users/10101446/items/TC8XWH8A",
      "itemID": 1,
      "attachments": [
        {
          "itemType": "attachment",
          "title": "Gatys Á≠â - 2015 - Texture Synthesis Using Convolutional Neural Netwo.pdf",
          "tags": [],
          "relations": [],
          "dateAdded": "2023-03-07T07:15:52Z",
          "dateModified": "2023-03-07T07:15:57Z",
          "uri": "http://zotero.org/users/10101446/items/RNTUP68M",
          "path": "C:\\Users\\gyh14\\Zotero\\storage\\RNTUP68M\\Gatys Á≠â - 2015 - Texture Synthesis Using Convolutional Neural Netwo.pdf",
          "select": "zotero://select/library/items/RNTUP68M"
        }
      ],
      "notes": [
        {
          "key": "FVXVPZAU",
          "version": 97,
          "itemType": "note",
          "parentItem": "TC8XWH8A",
          "note": "Comment: Revision for NIPS 2015 Camera Ready. In line with reviewer's comments we now focus on the texture model and texture synthesis performance. We limit the relationship of our texture model to the ventral stream and its potential use for neuroscience to the discussion of the paper",
          "tags": [],
          "relations": {},
          "dateAdded": "2023-03-07T07:15:56Z",
          "dateModified": "2023-03-07T07:15:56Z",
          "uri": "http://zotero.org/users/10101446/items/FVXVPZAU"
        }
      ],
      "citationKey": "gatysTextureSynthesisUsing2015",
      "itemKey": "TC8XWH8A",
      "libraryID": 1,
      "select": "zotero://select/library/items/TC8XWH8A"
    },
    {
      "key": "XBBRUGC7",
      "version": 166,
      "itemType": "preprint",
      "title": "Language Is Not All You Need: Aligning Perception with Language Models",
      "abstractNote": "A big convergence of language, multimodal perception, action, and world modeling is a key step toward artiÔ¨Åcial general intelligence. In this work, we introduce KOSMOS-12, a Multimodal Large Language Model (MLLM) that can perceive general modalities, learn in context (i.e., few-shot), and follow instructions (i.e., zero-shot). SpeciÔ¨Åcally, we train KOSMOS-1 from scratch on web-scale multimodal corpora, including arbitrarily interleaved text and images, image-caption pairs, and text data. We evaluate various settings, including zero-shot, few-shot, and multimodal chain-of-thought prompting, on a wide range of tasks without any gradient updates or Ô¨Ånetuning. Experimental results show that KOSMOS-1 achieves impressive performance on (i) language understanding, generation, and even OCR-free NLP (directly fed with document images), (ii) perception-language tasks, including multimodal dialogue, image captioning, visual question answering, and (iii) vision tasks, such as image recognition with descriptions (specifying classiÔ¨Åcation via text instructions). We also show that MLLMs can beneÔ¨Åt from cross-modal transfer, i.e., transfer knowledge from language to multimodal, and from multimodal to language. In addition, we introduce a dataset of Raven IQ test, which diagnoses the nonverbal reasoning capability of MLLMs.",
      "date": "2023-03-01",
      "language": "en",
      "shortTitle": "Language Is Not All You Need",
      "libraryCatalog": "arXiv.org",
      "url": "http://arxiv.org/abs/2302.14045",
      "accessDate": "2023-06-17T14:39:14Z",
      "extra": "arXiv:2302.14045 [cs]",
      "repository": "arXiv",
      "archiveID": "arXiv:2302.14045",
      "creators": [
        {
          "firstName": "Shaohan",
          "lastName": "Huang",
          "creatorType": "author"
        },
        {
          "firstName": "Li",
          "lastName": "Dong",
          "creatorType": "author"
        },
        {
          "firstName": "Wenhui",
          "lastName": "Wang",
          "creatorType": "author"
        },
        {
          "firstName": "Yaru",
          "lastName": "Hao",
          "creatorType": "author"
        },
        {
          "firstName": "Saksham",
          "lastName": "Singhal",
          "creatorType": "author"
        },
        {
          "firstName": "Shuming",
          "lastName": "Ma",
          "creatorType": "author"
        },
        {
          "firstName": "Tengchao",
          "lastName": "Lv",
          "creatorType": "author"
        },
        {
          "firstName": "Lei",
          "lastName": "Cui",
          "creatorType": "author"
        },
        {
          "firstName": "Owais Khan",
          "lastName": "Mohammed",
          "creatorType": "author"
        },
        {
          "firstName": "Barun",
          "lastName": "Patra",
          "creatorType": "author"
        },
        {
          "firstName": "Qiang",
          "lastName": "Liu",
          "creatorType": "author"
        },
        {
          "firstName": "Kriti",
          "lastName": "Aggarwal",
          "creatorType": "author"
        },
        {
          "firstName": "Zewen",
          "lastName": "Chi",
          "creatorType": "author"
        },
        {
          "firstName": "Johan",
          "lastName": "Bjorck",
          "creatorType": "author"
        },
        {
          "firstName": "Vishrav",
          "lastName": "Chaudhary",
          "creatorType": "author"
        },
        {
          "firstName": "Subhojit",
          "lastName": "Som",
          "creatorType": "author"
        },
        {
          "firstName": "Xia",
          "lastName": "Song",
          "creatorType": "author"
        },
        {
          "firstName": "Furu",
          "lastName": "Wei",
          "creatorType": "author"
        }
      ],
      "tags": [
        {
          "tag": "Computer Science - Computer Vision and Pattern Recognition",
          "type": 1
        },
        {
          "tag": "Computer Science - Computation and Language",
          "type": 1
        }
      ],
      "relations": [],
      "dateAdded": "2023-06-17T14:39:14Z",
      "dateModified": "2023-06-17T14:39:14Z",
      "uri": "http://zotero.org/users/10101446/items/XBBRUGC7",
      "itemID": 67,
      "attachments": [
        {
          "itemType": "attachment",
          "title": "Huang Á≠â - 2023 - Language Is Not All You Need Aligning Perception .pdf",
          "tags": [],
          "relations": [],
          "dateAdded": "2023-06-17T14:39:08Z",
          "dateModified": "2023-06-17T14:39:14Z",
          "uri": "http://zotero.org/users/10101446/items/U76G4KL2",
          "path": "C:\\Users\\gyh14\\Zotero\\storage\\U76G4KL2\\Huang Á≠â - 2023 - Language Is Not All You Need Aligning Perception .pdf",
          "select": "zotero://select/library/items/U76G4KL2"
        }
      ],
      "notes": [],
      "citationKey": "huangLanguageNotAll2023",
      "itemKey": "XBBRUGC7",
      "libraryID": 1,
      "select": "zotero://select/library/items/XBBRUGC7"
    },
    {
      "key": "6JZ2ZFBE",
      "version": 360,
      "itemType": "note",
      "note": "<div data-citation-items=\"%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F10101446%2Fitems%2FZRJI4HYN%22%5D%2C%22itemData%22%3A%7B%22id%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F10101446%2Fitems%2FZRJI4HYN%22%2C%22type%22%3A%22article%22%2C%22abstract%22%3A%22The%20dominant%20sequence%20transduction%20models%20are%20based%20on%20complex%20recurrent%20or%20convolutional%20neural%20networks%20that%20include%20an%20encoder%20and%20a%20decoder.%20The%20best%20performing%20models%20also%20connect%20the%20encoder%20and%20decoder%20through%20an%20attention%20mechanism.%20We%20propose%20a%20new%20simple%20network%20architecture%2C%20the%20Transformer%2C%20based%20solely%20on%20attention%20mechanisms%2C%20dispensing%20with%20recurrence%20and%20convolutions%20entirely.%20Experiments%20on%20two%20machine%20translation%20tasks%20show%20these%20models%20to%20be%20superior%20in%20quality%20while%20being%20more%20parallelizable%20and%20requiring%20signi%EF%AC%81cantly%20less%20time%20to%20train.%20Our%20model%20achieves%2028.4%20BLEU%20on%20the%20WMT%202014%20Englishto-German%20translation%20task%2C%20improving%20over%20the%20existing%20best%20results%2C%20including%20ensembles%2C%20by%20over%202%20BLEU.%20On%20the%20WMT%202014%20English-to-French%20translation%20task%2C%20our%20model%20establishes%20a%20new%20single-model%20state-of-the-art%20BLEU%20score%20of%2041.8%20after%20training%20for%203.5%20days%20on%20eight%20GPUs%2C%20a%20small%20fraction%20of%20the%20training%20costs%20of%20the%20best%20models%20from%20the%20literature.%20We%20show%20that%20the%20Transformer%20generalizes%20well%20to%20other%20tasks%20by%20applying%20it%20successfully%20to%20English%20constituency%20parsing%20both%20with%20large%20and%20limited%20training%20data.%22%2C%22language%22%3A%22en%22%2C%22note%22%3A%22arXiv%3A1706.03762%20%5Bcs%5D%22%2C%22number%22%3A%22arXiv%3A1706.03762%22%2C%22publisher%22%3A%22arXiv%22%2C%22source%22%3A%22arXiv.org%22%2C%22title%22%3A%22Attention%20Is%20All%20You%20Need%22%2C%22URL%22%3A%22http%3A%2F%2Farxiv.org%2Fabs%2F1706.03762%22%2C%22author%22%3A%5B%7B%22family%22%3A%22Vaswani%22%2C%22given%22%3A%22Ashish%22%7D%2C%7B%22family%22%3A%22Shazeer%22%2C%22given%22%3A%22Noam%22%7D%2C%7B%22family%22%3A%22Parmar%22%2C%22given%22%3A%22Niki%22%7D%2C%7B%22family%22%3A%22Uszkoreit%22%2C%22given%22%3A%22Jakob%22%7D%2C%7B%22family%22%3A%22Jones%22%2C%22given%22%3A%22Llion%22%7D%2C%7B%22family%22%3A%22Gomez%22%2C%22given%22%3A%22Aidan%20N.%22%7D%2C%7B%22family%22%3A%22Kaiser%22%2C%22given%22%3A%22Lukasz%22%7D%2C%7B%22family%22%3A%22Polosukhin%22%2C%22given%22%3A%22Illia%22%7D%5D%2C%22accessed%22%3A%7B%22date-parts%22%3A%5B%5B%222023%22%2C6%2C17%5D%5D%7D%2C%22issued%22%3A%7B%22date-parts%22%3A%5B%5B%222017%22%2C12%2C5%5D%5D%7D%7D%7D%5D\" data-schema-version=\"8\"><h1>Transformer</h1>\n<h2>‰∏∫‰ªÄ‰πà‰ΩøÁî®self-attention</h2>\n<ul>\n<li>\ncomputational complexity\n</li>\n<li>\nParallel computation\n</li>\n<li>\npath length between long-range dependencies in the network\n</li>\n</ul>\n<p></p>\n<p></p>\n</div>",
      "tags": [],
      "collections": [
        "K84JTQUN"
      ],
      "relations": {
        "dc:relation": [
          "http://zotero.org/users/10101446/items/ZRJI4HYN"
        ]
      },
      "dateAdded": "2023-09-23T15:28:23Z",
      "dateModified": "2023-09-24T07:53:49Z",
      "uri": "http://zotero.org/users/10101446/items/6JZ2ZFBE",
      "itemID": 172,
      "itemKey": "6JZ2ZFBE",
      "libraryID": 1,
      "select": "zotero://select/library/items/6JZ2ZFBE"
    },
    {
      "key": "HBXY5IN2",
      "version": 475,
      "itemType": "preprint",
      "title": "GPT-4 Technical Report",
      "abstractNote": "We report the development of GPT-4, a large-scale, multimodal model which can accept image and text inputs and produce text outputs. While less capable than humans in many real-world scenarios, GPT-4 exhibits human-level performance on various professional and academic benchmarks, including passing a simulated bar exam with a score around the top 10% of test takers. GPT-4 is a Transformerbased model pre-trained to predict the next token in a document. The post-training alignment process results in improved performance on measures of factuality and adherence to desired behavior. A core component of this project was developing infrastructure and optimization methods that behave predictably across a wide range of scales. This allowed us to accurately predict some aspects of GPT-4‚Äôs performance based on models trained with no more than 1/1,000th the compute of GPT-4.",
      "date": "2023-03-27",
      "language": "en",
      "libraryCatalog": "arXiv.org",
      "url": "http://arxiv.org/abs/2303.08774",
      "accessDate": "2023-09-07T03:28:31Z",
      "extra": "arXiv:2303.08774 [cs]",
      "repository": "arXiv",
      "archiveID": "arXiv:2303.08774",
      "creators": [
        {
          "firstName": "",
          "lastName": "OpenAI",
          "creatorType": "author"
        }
      ],
      "tags": [
        {
          "tag": "Computer Science - Computation and Language",
          "type": 1
        },
        {
          "tag": "Computer Science - Artificial Intelligence",
          "type": 1
        },
        {
          "tag": "ObsCite"
        }
      ],
      "relations": [],
      "dateAdded": "2023-09-07T03:28:31Z",
      "dateModified": "2023-09-30T07:47:55Z",
      "uri": "http://zotero.org/users/10101446/items/HBXY5IN2",
      "itemID": 142,
      "attachments": [
        {
          "itemType": "attachment",
          "title": "OpenAI - 2023 - GPT-4 Technical Report.pdf",
          "tags": [],
          "relations": [],
          "dateAdded": "2023-09-07T03:28:18Z",
          "dateModified": "2023-09-07T03:28:32Z",
          "uri": "http://zotero.org/users/10101446/items/TJ3Z5A7Y",
          "path": "C:\\Users\\gyh14\\Zotero\\storage\\TJ3Z5A7Y\\OpenAI - 2023 - GPT-4 Technical Report.pdf",
          "select": "zotero://select/library/items/TJ3Z5A7Y"
        }
      ],
      "notes": [
        {
          "key": "C53J44VK",
          "version": 263,
          "itemType": "note",
          "parentItem": "HBXY5IN2",
          "note": "Comment: 100 pages",
          "tags": [],
          "relations": {},
          "dateAdded": "2023-09-07T03:28:31Z",
          "dateModified": "2023-09-07T03:28:31Z",
          "uri": "http://zotero.org/users/10101446/items/C53J44VK"
        }
      ],
      "citationKey": "openai2023-gpt4",
      "itemKey": "HBXY5IN2",
      "libraryID": 1,
      "select": "zotero://select/library/items/HBXY5IN2"
    },
    {
      "key": "AR3GIJFD",
      "version": 256,
      "itemType": "journalArticle",
      "title": "Improving Language Understanding by Generative Pre-Training",
      "abstractNote": "Natural language understanding comprises a wide range of diverse tasks such as textual entailment, question answering, semantic similarity assessment, and document classiÔ¨Åcation. Although large unlabeled text corpora are abundant, labeled data for learning these speciÔ¨Åc tasks is scarce, making it challenging for discriminatively trained models to perform adequately. We demonstrate that large gains on these tasks can be realized by generative pre-training of a language model on a diverse corpus of unlabeled text, followed by discriminative Ô¨Åne-tuning on each speciÔ¨Åc task. In contrast to previous approaches, we make use of task-aware input transformations during Ô¨Åne-tuning to achieve effective transfer while requiring minimal changes to the model architecture. We demonstrate the effectiveness of our approach on a wide range of benchmarks for natural language understanding. Our general task-agnostic model outperforms discriminatively trained models that use architectures speciÔ¨Åcally crafted for each task, signiÔ¨Åcantly improving upon the state of the art in 9 out of the 12 tasks studied. For instance, we achieve absolute improvements of 8.9% on commonsense reasoning (Stories Cloze Test), 5.7% on question answering (RACE), and 1.5% on textual entailment (MultiNLI).",
      "language": "en",
      "libraryCatalog": "Zotero",
      "creators": [
        {
          "firstName": "Alec",
          "lastName": "Radford",
          "creatorType": "author"
        },
        {
          "firstName": "Karthik",
          "lastName": "Narasimhan",
          "creatorType": "author"
        },
        {
          "firstName": "Tim",
          "lastName": "Salimans",
          "creatorType": "author"
        },
        {
          "firstName": "Ilya",
          "lastName": "Sutskever",
          "creatorType": "author"
        }
      ],
      "tags": [],
      "relations": [],
      "dateAdded": "2023-09-07T03:28:05Z",
      "dateModified": "2023-09-07T03:28:05Z",
      "uri": "http://zotero.org/users/10101446/items/AR3GIJFD",
      "itemID": 138,
      "attachments": [
        {
          "itemType": "attachment",
          "title": "Radford Á≠â - Improving Language Understanding by Generative Pre.pdf",
          "tags": [],
          "relations": [],
          "dateAdded": "2023-09-07T03:28:02Z",
          "dateModified": "2023-09-07T03:28:05Z",
          "uri": "http://zotero.org/users/10101446/items/7IDJ5PYD",
          "path": "C:\\Users\\gyh14\\Zotero\\storage\\7IDJ5PYD\\Radford Á≠â - Improving Language Understanding by Generative Pre.pdf",
          "select": "zotero://select/library/items/7IDJ5PYD"
        }
      ],
      "notes": [],
      "citationKey": "radfordImprovingLanguageUnderstanding",
      "itemKey": "AR3GIJFD",
      "libraryID": 1,
      "select": "zotero://select/library/items/AR3GIJFD"
    },
    {
      "key": "7T5MVX42",
      "version": 259,
      "itemType": "journalArticle",
      "title": "Language Models are Unsupervised Multitask Learners",
      "abstractNote": "Natural language processing tasks, such as question answering, machine translation, reading comprehension, and summarization, are typically approached with supervised learning on taskspeciÔ¨Åc datasets. We demonstrate that language models begin to learn these tasks without any explicit supervision when trained on a new dataset of millions of webpages called WebText. When conditioned on a document plus questions, the answers generated by the language model reach 55 F1 on the CoQA dataset - matching or exceeding the performance of 3 out of 4 baseline systems without using the 127,000+ training examples. The capacity of the language model is essential to the success of zero-shot task transfer and increasing it improves performance in a log-linear fashion across tasks. Our largest model, GPT-2, is a 1.5B parameter Transformer that achieves state of the art results on 7 out of 8 tested language modeling datasets in a zero-shot setting but still underÔ¨Åts WebText. Samples from the model reÔ¨Çect these improvements and contain coherent paragraphs of text. These Ô¨Åndings suggest a promising path towards building language processing systems which learn to perform tasks from their naturally occurring demonstrations.",
      "language": "en",
      "libraryCatalog": "Zotero",
      "creators": [
        {
          "firstName": "Alec",
          "lastName": "Radford",
          "creatorType": "author"
        },
        {
          "firstName": "Jeffrey",
          "lastName": "Wu",
          "creatorType": "author"
        },
        {
          "firstName": "Rewon",
          "lastName": "Child",
          "creatorType": "author"
        },
        {
          "firstName": "David",
          "lastName": "Luan",
          "creatorType": "author"
        },
        {
          "firstName": "Dario",
          "lastName": "Amodei",
          "creatorType": "author"
        },
        {
          "firstName": "Ilya",
          "lastName": "Sutskever",
          "creatorType": "author"
        }
      ],
      "tags": [],
      "relations": [],
      "dateAdded": "2023-09-07T03:28:16Z",
      "dateModified": "2023-09-07T03:28:17Z",
      "uri": "http://zotero.org/users/10101446/items/7T5MVX42",
      "itemID": 140,
      "attachments": [
        {
          "itemType": "attachment",
          "title": "Radford Á≠â - Language Models are Unsupervised Multitask Learner.pdf",
          "tags": [],
          "relations": [],
          "dateAdded": "2023-09-07T03:28:13Z",
          "dateModified": "2023-09-07T03:28:17Z",
          "uri": "http://zotero.org/users/10101446/items/QQBJYCUR",
          "path": "C:\\Users\\gyh14\\Zotero\\storage\\QQBJYCUR\\Radford Á≠â - Language Models are Unsupervised Multitask Learner.pdf",
          "select": "zotero://select/library/items/QQBJYCUR"
        }
      ],
      "notes": [],
      "citationKey": "radfordLanguageModelsAre",
      "itemKey": "7T5MVX42",
      "libraryID": 1,
      "select": "zotero://select/library/items/7T5MVX42"
    },
    {
      "key": "99BHSFSW",
      "version": 381,
      "itemType": "book",
      "title": "Distributed systems",
      "date": "2023",
      "language": "en",
      "libraryCatalog": "Open WorldCat",
      "extra": "OCLC: 1373659118",
      "place": "Place of publication not identified",
      "publisher": "Maarten van Steen",
      "ISBN": "978-90-815406-3-6",
      "edition": "4th edition, Version 01 (January 2023)",
      "creators": [
        {
          "firstName": "Maarten van",
          "lastName": "Steen",
          "creatorType": "author"
        },
        {
          "firstName": "Andrew S.",
          "lastName": "Tanenbaum",
          "creatorType": "author"
        }
      ],
      "tags": [],
      "relations": [],
      "dateAdded": "2023-09-24T08:32:54Z",
      "dateModified": "2023-09-24T08:32:54Z",
      "uri": "http://zotero.org/users/10101446/items/99BHSFSW",
      "itemID": 194,
      "attachments": [
        {
          "itemType": "attachment",
          "title": "Steen Âíå Tanenbaum - 2023 - Distributed systems.pdf",
          "tags": [],
          "relations": [],
          "dateAdded": "2023-09-24T08:32:41Z",
          "dateModified": "2023-09-24T08:32:55Z",
          "uri": "http://zotero.org/users/10101446/items/V28G345J",
          "path": "C:\\Users\\gyh14\\Zotero\\storage\\V28G345J\\Steen Âíå Tanenbaum - 2023 - Distributed systems.pdf",
          "select": "zotero://select/library/items/V28G345J"
        }
      ],
      "notes": [],
      "citationKey": "steenDistributedSystems2023",
      "itemKey": "99BHSFSW",
      "libraryID": 1,
      "select": "zotero://select/library/items/99BHSFSW"
    },
    {
      "key": "D38IHND8",
      "version": 565,
      "itemType": "preprint",
      "title": "Retentive Network: A Successor to Transformer for Large Language Models",
      "abstractNote": "In this work, we propose Retentive Network (RETNET) as a foundation architecture for large language models, simultaneously achieving training parallelism, low-cost inference, and good performance. We theoretically derive the connection between recurrence and attention. Then we propose the retention mechanism for sequence modeling, which supports three computation paradigms, i.e., parallel, recurrent, and chunkwise recurrent. Specifically, the parallel representation allows for training parallelism. The recurrent representation enables low-cost O(1) inference, which improves decoding throughput, latency, and GPU memory without sacrificing performance. The chunkwise recurrent representation facilitates efficient long-sequence modeling with linear complexity, where each chunk is encoded parallelly while recurrently summarizing the chunks. Experimental results on language modeling show that RETNET achieves favorable scaling results, parallel training, low-cost deployment, and efficient inference. The intriguing properties make RETNET a strong successor to Transformer for large language models. Code will be available at https://aka.ms/retnet.",
      "date": "2023-08-09",
      "language": "en",
      "shortTitle": "Retentive Network",
      "libraryCatalog": "arXiv.org",
      "url": "http://arxiv.org/abs/2307.08621",
      "accessDate": "2023-10-15T07:06:09Z",
      "extra": "arXiv:2307.08621 [cs]",
      "repository": "arXiv",
      "archiveID": "arXiv:2307.08621",
      "creators": [
        {
          "firstName": "Yutao",
          "lastName": "Sun",
          "creatorType": "author"
        },
        {
          "firstName": "Li",
          "lastName": "Dong",
          "creatorType": "author"
        },
        {
          "firstName": "Shaohan",
          "lastName": "Huang",
          "creatorType": "author"
        },
        {
          "firstName": "Shuming",
          "lastName": "Ma",
          "creatorType": "author"
        },
        {
          "firstName": "Yuqing",
          "lastName": "Xia",
          "creatorType": "author"
        },
        {
          "firstName": "Jilong",
          "lastName": "Xue",
          "creatorType": "author"
        },
        {
          "firstName": "Jianyong",
          "lastName": "Wang",
          "creatorType": "author"
        },
        {
          "firstName": "Furu",
          "lastName": "Wei",
          "creatorType": "author"
        }
      ],
      "tags": [
        {
          "tag": "Computer Science - Computation and Language",
          "type": 1
        },
        {
          "tag": "Computer Science - Machine Learning",
          "type": 1
        },
        {
          "tag": "ObsCite"
        }
      ],
      "relations": [],
      "dateAdded": "2023-10-15T07:06:09Z",
      "dateModified": "2023-10-18T01:29:18Z",
      "uri": "http://zotero.org/users/10101446/items/D38IHND8",
      "itemID": 339,
      "attachments": [
        {
          "itemType": "attachment",
          "title": "Sun Á≠â - 2023 - Retentive Network A Successor to Transformer for .pdf",
          "tags": [],
          "relations": [],
          "dateAdded": "2023-10-15T07:05:57Z",
          "dateModified": "2023-10-15T07:06:09Z",
          "uri": "http://zotero.org/users/10101446/items/73EF3EEY",
          "path": "C:\\Users\\gyh14\\Zotero\\storage\\73EF3EEY\\Sun Á≠â - 2023 - Retentive Network A Successor to Transformer for .pdf",
          "select": "zotero://select/library/items/73EF3EEY"
        }
      ],
      "notes": [],
      "citationKey": "sun2023-retentive",
      "itemKey": "D38IHND8",
      "libraryID": 1,
      "select": "zotero://select/library/items/D38IHND8"
    },
    {
      "key": "ZRJI4HYN",
      "version": 535,
      "itemType": "preprint",
      "title": "Attention Is All You Need",
      "abstractNote": "The dominant sequence transduction models are based on complex recurrent or convolutional neural networks that include an encoder and a decoder. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring signiÔ¨Åcantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 Englishto-German translation task, improving over the existing best results, including ensembles, by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.",
      "date": "2017-12-05",
      "language": "en",
      "libraryCatalog": "arXiv.org",
      "url": "http://arxiv.org/abs/1706.03762",
      "accessDate": "2023-06-17T14:40:13Z",
      "extra": "arXiv:1706.03762 [cs]",
      "repository": "arXiv",
      "archiveID": "arXiv:1706.03762",
      "creators": [
        {
          "firstName": "Ashish",
          "lastName": "Vaswani",
          "creatorType": "author"
        },
        {
          "firstName": "Noam",
          "lastName": "Shazeer",
          "creatorType": "author"
        },
        {
          "firstName": "Niki",
          "lastName": "Parmar",
          "creatorType": "author"
        },
        {
          "firstName": "Jakob",
          "lastName": "Uszkoreit",
          "creatorType": "author"
        },
        {
          "firstName": "Llion",
          "lastName": "Jones",
          "creatorType": "author"
        },
        {
          "firstName": "Aidan N.",
          "lastName": "Gomez",
          "creatorType": "author"
        },
        {
          "firstName": "Lukasz",
          "lastName": "Kaiser",
          "creatorType": "author"
        },
        {
          "firstName": "Illia",
          "lastName": "Polosukhin",
          "creatorType": "author"
        }
      ],
      "tags": [
        {
          "tag": "Computer Science - Computation and Language",
          "type": 1
        },
        {
          "tag": "Computer Science - Machine Learning",
          "type": 1
        }
      ],
      "relations": [
        "http://zotero.org/users/10101446/items/6JZ2ZFBE"
      ],
      "dateAdded": "2023-06-17T14:40:13Z",
      "dateModified": "2023-10-12T09:36:21Z",
      "uri": "http://zotero.org/users/10101446/items/ZRJI4HYN",
      "itemID": 69,
      "attachments": [
        {
          "itemType": "attachment",
          "title": "Vaswani Á≠â - 2017 - Attention Is All You Need.pdf",
          "tags": [],
          "relations": [],
          "dateAdded": "2023-06-17T14:40:09Z",
          "dateModified": "2023-06-17T14:40:13Z",
          "uri": "http://zotero.org/users/10101446/items/GXDZU4NV",
          "path": "C:\\Users\\gyh14\\Zotero\\storage\\GXDZU4NV\\Vaswani Á≠â - 2017 - Attention Is All You Need.pdf",
          "select": "zotero://select/library/items/GXDZU4NV"
        }
      ],
      "notes": [
        {
          "key": "X5TJU3WQ",
          "version": 491,
          "itemType": "note",
          "parentItem": "ZRJI4HYN",
          "note": "<div data-citation-items=\"%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F10101446%2Fitems%2FZRJI4HYN%22%5D%2C%22itemData%22%3A%7B%22id%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F10101446%2Fitems%2FZRJI4HYN%22%2C%22type%22%3A%22article%22%2C%22abstract%22%3A%22The%20dominant%20sequence%20transduction%20models%20are%20based%20on%20complex%20recurrent%20or%20convolutional%20neural%20networks%20that%20include%20an%20encoder%20and%20a%20decoder.%20The%20best%20performing%20models%20also%20connect%20the%20encoder%20and%20decoder%20through%20an%20attention%20mechanism.%20We%20propose%20a%20new%20simple%20network%20architecture%2C%20the%20Transformer%2C%20based%20solely%20on%20attention%20mechanisms%2C%20dispensing%20with%20recurrence%20and%20convolutions%20entirely.%20Experiments%20on%20two%20machine%20translation%20tasks%20show%20these%20models%20to%20be%20superior%20in%20quality%20while%20being%20more%20parallelizable%20and%20requiring%20signi%EF%AC%81cantly%20less%20time%20to%20train.%20Our%20model%20achieves%2028.4%20BLEU%20on%20the%20WMT%202014%20Englishto-German%20translation%20task%2C%20improving%20over%20the%20existing%20best%20results%2C%20including%20ensembles%2C%20by%20over%202%20BLEU.%20On%20the%20WMT%202014%20English-to-French%20translation%20task%2C%20our%20model%20establishes%20a%20new%20single-model%20state-of-the-art%20BLEU%20score%20of%2041.8%20after%20training%20for%203.5%20days%20on%20eight%20GPUs%2C%20a%20small%20fraction%20of%20the%20training%20costs%20of%20the%20best%20models%20from%20the%20literature.%20We%20show%20that%20the%20Transformer%20generalizes%20well%20to%20other%20tasks%20by%20applying%20it%20successfully%20to%20English%20constituency%20parsing%20both%20with%20large%20and%20limited%20training%20data.%22%2C%22language%22%3A%22en%22%2C%22note%22%3A%22arXiv%3A1706.03762%20%5Bcs%5D%22%2C%22number%22%3A%22arXiv%3A1706.03762%22%2C%22publisher%22%3A%22arXiv%22%2C%22source%22%3A%22arXiv.org%22%2C%22title%22%3A%22Attention%20Is%20All%20You%20Need%22%2C%22URL%22%3A%22http%3A%2F%2Farxiv.org%2Fabs%2F1706.03762%22%2C%22author%22%3A%5B%7B%22family%22%3A%22Vaswani%22%2C%22given%22%3A%22Ashish%22%7D%2C%7B%22family%22%3A%22Shazeer%22%2C%22given%22%3A%22Noam%22%7D%2C%7B%22family%22%3A%22Parmar%22%2C%22given%22%3A%22Niki%22%7D%2C%7B%22family%22%3A%22Uszkoreit%22%2C%22given%22%3A%22Jakob%22%7D%2C%7B%22family%22%3A%22Jones%22%2C%22given%22%3A%22Llion%22%7D%2C%7B%22family%22%3A%22Gomez%22%2C%22given%22%3A%22Aidan%20N.%22%7D%2C%7B%22family%22%3A%22Kaiser%22%2C%22given%22%3A%22Lukasz%22%7D%2C%7B%22family%22%3A%22Polosukhin%22%2C%22given%22%3A%22Illia%22%7D%5D%2C%22accessed%22%3A%7B%22date-parts%22%3A%5B%5B%222023%22%2C6%2C17%5D%5D%7D%2C%22issued%22%3A%7B%22date-parts%22%3A%5B%5B%222017%22%2C12%2C5%5D%5D%7D%2C%22citation-key%22%3A%22vaswani2017-attention%22%7D%7D%5D\" data-schema-version=\"8\"><h1>Ê≥®Èáä<br/>(2023/9/30 ‰∏ãÂçà3:56:10)</h1>\n<p><span class=\"highlight\" data-annotation=\"%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F10101446%2Fitems%2FGXDZU4NV%22%2C%22annotationKey%22%3A%225EC5JCXU%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%221%22%2C%22position%22%3A%7B%22pageIndex%22%3A0%2C%22rects%22%3A%5B%5B162.442%2C420.212%2C325.987%2C429.119%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F10101446%2Fitems%2FZRJI4HYN%22%5D%2C%22locator%22%3A%221%22%7D%7D\">‚Äúdominant sequence transduction models‚Äù</span> <span class=\"citation\" data-citation=\"%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F10101446%2Fitems%2FZRJI4HYN%22%5D%2C%22locator%22%3A%221%22%7D%5D%2C%22properties%22%3A%7B%7D%7D\">(<span class=\"citation-item\">Vaswani Á≠â, 2017, p. 1</span>)</span> ÊòæÊÄßÂ∫èÂàóËΩ¨ÂØºÊ®°Âûã</p><p><span class=\"highlight\" data-annotation=\"%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F10101446%2Fitems%2FGXDZU4NV%22%2C%22annotationKey%22%3A%22XU6K6MYP%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%221%22%2C%22position%22%3A%7B%22pageIndex%22%3A0%2C%22rects%22%3A%5B%5B168.294%2C376.576%2C191.619%2C385.483%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F10101446%2Fitems%2FZRJI4HYN%22%5D%2C%22locator%22%3A%221%22%7D%7D\">‚Äúsolely‚Äù</span> <span class=\"citation\" data-citation=\"%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F10101446%2Fitems%2FZRJI4HYN%22%5D%2C%22locator%22%3A%221%22%7D%5D%2C%22properties%22%3A%7B%7D%7D\">(<span class=\"citation-item\">Vaswani Á≠â, 2017, p. 1</span>)</span> ‰ªÖ‰ªÖ<br><br>Ëã±<i>/</i>Ààs…ô älli<i>/</i></p><p><span class=\"highlight\" data-annotation=\"%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F10101446%2Fitems%2FGXDZU4NV%22%2C%22annotationKey%22%3A%22D9DPK8KC%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%221%22%2C%22position%22%3A%7B%22pageIndex%22%3A0%2C%22rects%22%3A%5B%5B295.09%2C376.576%2C336.858%2C385.483%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F10101446%2Fitems%2FZRJI4HYN%22%5D%2C%22locator%22%3A%221%22%7D%7D\">‚Äúdispensing‚Äù</span> <span class=\"citation\" data-citation=\"%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F10101446%2Fitems%2FZRJI4HYN%22%5D%2C%22locator%22%3A%221%22%7D%5D%2C%22properties%22%3A%7B%7D%7D\">(<span class=\"citation-item\">Vaswani Á≠â, 2017, p. 1</span>)</span> Áæé<i>/</i>d…™Ààspens…™≈ã<br>n.ÈÖçËçØÔºõË∞ÉÂâÇv.ÈÖçËçØÔºõÂàÜÂèëÔºõÊâßË°åÔºõÁâπËµ¶Ôºàdispense ÁöÑ ing ÂΩ¢ÂºèÔºâ</p><p><span class=\"highlight\" data-annotation=\"%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F10101446%2Fitems%2FGXDZU4NV%22%2C%22annotationKey%22%3A%22DD3WQ84S%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%221%22%2C%22position%22%3A%7B%22pageIndex%22%3A0%2C%22rects%22%3A%5B%5B143.866%2C365.667%2C174.91%2C374.574%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F10101446%2Fitems%2FZRJI4HYN%22%5D%2C%22locator%22%3A%221%22%7D%7D\">‚Äúentirely‚Äù</span> <span class=\"citation\" data-citation=\"%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F10101446%2Fitems%2FZRJI4HYN%22%5D%2C%22locator%22%3A%221%22%7D%5D%2C%22properties%22%3A%7B%7D%7D\">(<span class=\"citation-item\">Vaswani Á≠â, 2017, p. 1</span>)</span> Ëã±<i>/</i>…™nÀàta…™…ôli<i>/</i><br><i>ÂÆåÂÖ®ÁöÑ</i></p><p><span class=\"highlight\" data-annotation=\"%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F10101446%2Fitems%2FGXDZU4NV%22%2C%22annotationKey%22%3A%22GT7HLBSY%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%221%22%2C%22position%22%3A%7B%22pageIndex%22%3A0%2C%22rects%22%3A%5B%5B221.254%2C210.181%2C326.957%2C219.088%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F10101446%2Fitems%2FZRJI4HYN%22%5D%2C%22locator%22%3A%221%22%7D%7D\">‚Äúlong short-term memory [‚Äù</span> <span class=\"citation\" data-citation=\"%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F10101446%2Fitems%2FZRJI4HYN%22%5D%2C%22locator%22%3A%221%22%7D%5D%2C%22properties%22%3A%7B%7D%7D\">(<span class=\"citation-item\">Vaswani Á≠â, 2017, p. 1</span>)</span> üî§ÈïøÁü≠ÊúüËÆ∞ÂøÜ[üî§</p><p><span class=\"highlight\" data-annotation=\"%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F10101446%2Fitems%2FGXDZU4NV%22%2C%22annotationKey%22%3A%22SRVJZQST%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%221%22%2C%22position%22%3A%7B%22pageIndex%22%3A0%2C%22rects%22%3A%5B%5B360.339%2C210.181%2C421.656%2C219.088%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F10101446%2Fitems%2FZRJI4HYN%22%5D%2C%22locator%22%3A%221%22%7D%7D\">‚Äúgated recurrent‚Äù</span> <span class=\"citation\" data-citation=\"%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F10101446%2Fitems%2FZRJI4HYN%22%5D%2C%22locator%22%3A%221%22%7D%5D%2C%22properties%22%3A%7B%7D%7D\">(<span class=\"citation-item\">Vaswani Á≠â, 2017, p. 1</span>)</span> üî§Èó®ÊéßÂæ™ÁéØüî§</p><p><span class=\"highlight\" data-annotation=\"%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F10101446%2Fitems%2FGXDZU4NV%22%2C%22annotationKey%22%3A%22YJ9J7IGL%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%221%22%2C%22position%22%3A%7B%22pageIndex%22%3A0%2C%22rects%22%3A%5B%5B204.73%2C199.272%2C229.503%2C208.179%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F10101446%2Fitems%2FZRJI4HYN%22%5D%2C%22locator%22%3A%221%22%7D%7D\">‚Äúfirmly‚Äù</span> <span class=\"citation\" data-citation=\"%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F10101446%2Fitems%2FZRJI4HYN%22%5D%2C%22locator%22%3A%221%22%7D%5D%2C%22properties%22%3A%7B%7D%7D\">(<span class=\"citation-item\">Vaswani Á≠â, 2017, p. 1</span>)</span> üî§firmly<br>Ëã± [Ààf…úÀêmli]<br>Áæé [Ààf…úÀêrmli]<br>adv. ÂùöÂõ∫Âú∞ÔºåÁâ¢Âõ∫Âú∞ÔºõÂº∫ËÄåÊúâÂäõÂú∞ÔºõÂùöÂÜ≥Âú∞üî§</p><p><span class=\"highlight\" data-annotation=\"%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F10101446%2Fitems%2FGXDZU4NV%22%2C%22annotationKey%22%3A%22ZGINCP6R%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%222%22%2C%22position%22%3A%7B%22pageIndex%22%3A1%2C%22rects%22%3A%5B%5B108%2C707.885%2C158.24%2C716.792%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F10101446%2Fitems%2FZRJI4HYN%22%5D%2C%22locator%22%3A%222%22%7D%7D\">‚Äútransduction‚Äù</span> <span class=\"citation\" data-citation=\"%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F10101446%2Fitems%2FZRJI4HYN%22%5D%2C%22locator%22%3A%222%22%7D%5D%2C%22properties%22%3A%7B%7D%7D\">(<span class=\"citation-item\">Vaswani Á≠â, 2017, p. 2</span>)</span> üî§transduction<br>Ëã± [tr√¶nzÀàd åk É…ôn]<br>Áæé [tr√¶nsÀàd åk Én]<br>n. [ÈÅó] ËΩ¨ÂØºÔºõËΩ¨Êç¢ÔºõÊç¢ËÉΩÔºõÂèòÈ¢ëüî§</p><p><span class=\"highlight\" data-annotation=\"%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F10101446%2Fitems%2FGXDZU4NV%22%2C%22annotationKey%22%3A%22AP3VD38D%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%222%22%2C%22position%22%3A%7B%22pageIndex%22%3A1%2C%22rects%22%3A%5B%5B461.668%2C707.885%2C504.002%2C716.792%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F10101446%2Fitems%2FZRJI4HYN%22%5D%2C%22locator%22%3A%222%22%7D%7D\">‚ÄúNumerous‚Äù</span> <span class=\"citation\" data-citation=\"%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F10101446%2Fitems%2FZRJI4HYN%22%5D%2C%22locator%22%3A%222%22%7D%5D%2C%22properties%22%3A%7B%7D%7D\">(<span class=\"citation-item\">Vaswani Á≠â, 2017, p. 2</span>)</span> üî§numerous<br>Ëã± [ÀànjuÀêm…ôr…ôs]<br>Áæé [ÀànuÀêm…ôr…ôs]<br>adj. ‰ºóÂ§öÁöÑÔºåËÆ∏Â§öÁöÑ<br>[ ÊØîËæÉÁ∫ß more numerous ÊúÄÈ´òÁ∫ß most numerous ]üî§</p><p><span class=\"highlight\" data-annotation=\"%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F10101446%2Fitems%2FGXDZU4NV%22%2C%22annotationKey%22%3A%22UDP8TQH7%22%2C%22color%22%3A%22%232ea8e5%22%2C%22pageLabel%22%3A%223%22%2C%22position%22%3A%7B%22pageIndex%22%3A2%2C%22rects%22%3A%5B%5B343.97%2C284.241%2C503.999%2C293.148%5D%2C%5B108%2C273.332%2C504.166%2C282.398%5D%2C%5B108%2C262.423%2C127.925%2C271.33%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F10101446%2Fitems%2FZRJI4HYN%22%5D%2C%22locator%22%3A%223%22%7D%7D\">‚ÄúThat is, the output of each sub-layer is LayerNorm(x + Sublayer(x)), where Sublayer(x) is the function implemented by the sub-layer itself‚Äù</span> <span class=\"citation\" data-citation=\"%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F10101446%2Fitems%2FZRJI4HYN%22%5D%2C%22locator%22%3A%223%22%7D%5D%2C%22properties%22%3A%7B%7D%7D\">(<span class=\"citation-item\">Vaswani Á≠â, 2017, p. 3</span>)</span></p><p><span class=\"highlight\" data-annotation=\"%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F10101446%2Fitems%2FGXDZU4NV%22%2C%22annotationKey%22%3A%22R4AG5MKR%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%226%22%2C%22position%22%3A%7B%22pageIndex%22%3A5%2C%22rects%22%3A%5B%5B343.353%2C271.741%2C345.839%2C280.648%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F10101446%2Fitems%2FZRJI4HYN%22%5D%2C%22locator%22%3A%226%22%7D%7D\">‚Äú.‚Äù</span> <span class=\"citation\" data-citation=\"%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F10101446%2Fitems%2FZRJI4HYN%22%5D%2C%22locator%22%3A%226%22%7D%5D%2C%22properties%22%3A%7B%7D%7D\">(<span class=\"citation-item\">Vaswani Á≠â, 2017, p. 6</span>)</span> Âú®Êú¨ËäÇ‰∏≠ÔºåÊàë‰ª¨Â∞ÜËá™Ê≥®ÊÑèÂäõÂ±ÇÁöÑÂêÑ‰∏™ÊñπÈù¢‰∏éÂæ™ÁéØÂ±ÇÂíåÂç∑ÁßØÂ±ÇËøõË°åÊØîËæÉÔºåËøô‰∫õÂ±ÇÈÄöÂ∏∏Áî®‰∫éÂ∞ÜÁ¨¶Âè∑Ë°®Á§∫ÁöÑ‰∏Ä‰∏™ÂèØÂèòÈïøÂ∫¶Â∫èÂàóÔºàx1Ôºå...ÔºåxnÔºâÊò†Â∞ÑÂà∞Âè¶‰∏Ä‰∏™Á≠âÈïøÂ∫¶Â∫èÂàóÔºàz1Ôºå.. ., zn)ÔºåÂÖ∂‰∏≠ xi, zi ‚àà RdÔºå‰æãÂ¶ÇÂÖ∏ÂûãÂ∫èÂàóËΩ¨ÂØºÁºñÁ†ÅÂô®ÊàñËß£Á†ÅÂô®‰∏≠ÁöÑÈöêËóèÂ±Ç„ÄÇ</p><p><span class=\"highlight\" data-annotation=\"%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F10101446%2Fitems%2FGXDZU4NV%22%2C%22annotationKey%22%3A%22K69BY35L%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%226%22%2C%22position%22%3A%7B%22pageIndex%22%3A5%2C%22rects%22%3A%5B%5B166.65%2C260.832%2C207.038%2C269.739%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F10101446%2Fitems%2FZRJI4HYN%22%5D%2C%22locator%22%3A%226%22%7D%7D\">‚Äúdesiderata‚Äù</span> <span class=\"citation\" data-citation=\"%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F10101446%2Fitems%2FZRJI4HYN%22%5D%2C%22locator%22%3A%226%22%7D%5D%2C%22properties%22%3A%7B%7D%7D\">(<span class=\"citation-item\">Vaswani Á≠â, 2017, p. 6</span>)</span> üî§desiderata<br>Ëã± [d…™Àåz…™d…ôÀàre…™t…ô]<br>Áæé [d…™Àåz…™d…ôÀàret…ôm]<br>n. ÔºàÊãâ‰∏ÅÔºâËø´ÂàáÈúÄË¶ÅÂæóÂà∞‰πãÁâ©Ôºàdesideratum ÁöÑÂ§çÊï∞Ôºâ<br>n. ÔºàDesiderataÔºâ‰∫∫ÂêçÔºõÔºàËã±ÔºâÂæ∑Ë•øÂæ∑ËïæÂ°îüî§</p><p><span class=\"highlight\" data-annotation=\"%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F10101446%2Fitems%2FGXDZU4NV%22%2C%22annotationKey%22%3A%22EBMIELV4%22%2C%22color%22%3A%22%232ea8e5%22%2C%22pageLabel%22%3A%226%22%2C%22position%22%3A%7B%22pageIndex%22%3A5%2C%22rects%22%3A%5B%5B171.156%2C244.443%2C275.439%2C253.35%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F10101446%2Fitems%2FZRJI4HYN%22%5D%2C%22locator%22%3A%226%22%7D%7D\">‚Äúcomputational complexity‚Äù</span> <span class=\"citation\" data-citation=\"%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F10101446%2Fitems%2FZRJI4HYN%22%5D%2C%22locator%22%3A%226%22%7D%5D%2C%22properties%22%3A%7B%7D%7D\">(<span class=\"citation-item\">Vaswani Á≠â, 2017, p. 6</span>)</span> üî§ËÆ°ÁÆóÂ§çÊùÇÂ∫¶üî§</p><p><span class=\"highlight\" data-annotation=\"%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F10101446%2Fitems%2FGXDZU4NV%22%2C%22annotationKey%22%3A%22GJ5X4DQ9%22%2C%22color%22%3A%22%232ea8e5%22%2C%22pageLabel%22%3A%226%22%2C%22position%22%3A%7B%22pageIndex%22%3A5%2C%22rects%22%3A%5B%5B420.351%2C244.443%2C504%2C253.35%5D%2C%5B108%2C233.534%2C166.371%2C242.441%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F10101446%2Fitems%2FZRJI4HYN%22%5D%2C%22locator%22%3A%226%22%7D%7D\">‚Äúcomputation that can be parallelized‚Äù</span> <span class=\"citation\" data-citation=\"%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F10101446%2Fitems%2FZRJI4HYN%22%5D%2C%22locator%22%3A%226%22%7D%5D%2C%22properties%22%3A%7B%7D%7D\">(<span class=\"citation-item\">Vaswani Á≠â, 2017, p. 6</span>)</span> üî§ÂèØÂπ∂Ë°åËÆ°ÁÆóüî§</p><p><span class=\"highlight\" data-annotation=\"%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F10101446%2Fitems%2FGXDZU4NV%22%2C%22annotationKey%22%3A%223LVKYAXJ%22%2C%22color%22%3A%22%232ea8e5%22%2C%22pageLabel%22%3A%226%22%2C%22position%22%3A%7B%22pageIndex%22%3A5%2C%22rects%22%3A%5B%5B171.388%2C217.146%2C415.89%2C226.053%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F10101446%2Fitems%2FZRJI4HYN%22%5D%2C%22locator%22%3A%226%22%7D%7D\">‚Äúpath length between long-range dependencies in the network‚Äù</span> <span class=\"citation\" data-citation=\"%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F10101446%2Fitems%2FZRJI4HYN%22%5D%2C%22locator%22%3A%226%22%7D%5D%2C%22properties%22%3A%7B%7D%7D\">(<span class=\"citation-item\">Vaswani Á≠â, 2017, p. 6</span>)</span> üî§ÁΩëÁªú‰∏≠ËøúÁ®ã‰æùËµñ‰πãÈó¥ÁöÑË∑ØÂæÑÈïøÂ∫¶üî§</p><p><span class=\"highlight\" data-annotation=\"%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F10101446%2Fitems%2FGXDZU4NV%22%2C%22annotationKey%22%3A%22VAD6FTWC%22%2C%22color%22%3A%22%232ea8e5%22%2C%22pageLabel%22%3A%226%22%2C%22position%22%3A%7B%22pageIndex%22%3A5%2C%22rects%22%3A%5B%5B206.006%2C184.418%2C503.998%2C193.325%5D%2C%5B108%2C173.509%2C385.351%2C182.416%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F10101446%2Fitems%2FZRJI4HYN%22%5D%2C%22locator%22%3A%226%22%7D%7D\">‚ÄúThe shorter these paths between any combination of positions in the input and output sequences, the easier it is to learn long-range dependencies‚Äù</span> <span class=\"citation\" data-citation=\"%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F10101446%2Fitems%2FZRJI4HYN%22%5D%2C%22locator%22%3A%226%22%7D%5D%2C%22properties%22%3A%7B%7D%7D\">(<span class=\"citation-item\">Vaswani Á≠â, 2017, p. 6</span>)</span> üî§ËæìÂÖ•ÂíåËæìÂá∫Â∫èÂàó‰∏≠ÁöÑ‰ªªÊÑè‰ΩçÁΩÆÁªÑÂêà‰πãÈó¥ÁöÑË∑ØÂæÑË∂äÁü≠ÔºåÂ≠¶‰π†ËøúÁ®ã‰æùËµñÂÖ≥Á≥ªÂ∞±Ë∂äÂÆπÊòìüî§</p><p><span class=\"highlight\" data-annotation=\"%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F10101446%2Fitems%2FGXDZU4NV%22%2C%22annotationKey%22%3A%226B62YBL7%22%2C%22color%22%3A%22%232ea8e5%22%2C%22pageLabel%22%3A%226%22%2C%22position%22%3A%7B%22pageIndex%22%3A5%2C%22rects%22%3A%5B%5B458.089%2C124.393%2C504%2C133.459%5D%2C%5B108%2C113.484%2C503.997%2C122.391%5D%2C%5B108%2C102.575%2C359.339%2C111.641%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F10101446%2Fitems%2FZRJI4HYN%22%5D%2C%22locator%22%3A%226%22%7D%7D\">‚ÄúIn terms of computational complexity, self-attention layers are faster than recurrent layers when the sequence length n is smaller than the representation dimensionality d,‚Äù</span> <span class=\"citation\" data-citation=\"%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F10101446%2Fitems%2FZRJI4HYN%22%5D%2C%22locator%22%3A%226%22%7D%5D%2C%22properties%22%3A%7B%7D%7D\">(<span class=\"citation-item\">Vaswani Á≠â, 2017, p. 6</span>)</span> üî§Â∞±ËÆ°ÁÆóÂ§çÊùÇÂ∫¶ËÄåË®ÄÔºåÂΩìÂ∫èÂàóÈïøÂ∫¶ n Â∞è‰∫éË°®Á§∫Áª¥Â∫¶ d Êó∂ÔºåËá™Ê≥®ÊÑèÂäõÂ±ÇÊØîÂæ™ÁéØÂ±ÇÊõ¥Âø´Ôºåüî§</p><p><span class=\"highlight\" data-annotation=\"%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F10101446%2Fitems%2FGXDZU4NV%22%2C%22annotationKey%22%3A%222TKAYR4Q%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%226%22%2C%22position%22%3A%7B%22pageIndex%22%3A5%2C%22rects%22%3A%5B%5B466.168%2C80.757%2C504.003%2C89.664%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F10101446%2Fitems%2FZRJI4HYN%22%5D%2C%22locator%22%3A%226%22%7D%7D\">‚Äúinvolving‚Äù</span> <span class=\"citation\" data-citation=\"%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F10101446%2Fitems%2FZRJI4HYN%22%5D%2C%22locator%22%3A%226%22%7D%5D%2C%22properties%22%3A%7B%7D%7D\">(<span class=\"citation-item\">Vaswani Á≠â, 2017, p. 6</span>)</span> üî§involving<br>v. Ê∂âÂèäÔºõÂåÖÊã¨Ôºõ‰ΩøÈô∑‰∫éÔºàinvolve ÁöÑ ing ÂΩ¢ÂºèÔºâüî§</p><p><span class=\"highlight\" data-annotation=\"%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F10101446%2Fitems%2FGXDZU4NV%22%2C%22annotationKey%22%3A%22JPTF5PJU%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%226%22%2C%22position%22%3A%7B%22pageIndex%22%3A5%2C%22rects%22%3A%5B%5B281.226%2C69.848%2C317.556%2C78.914%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F10101446%2Fitems%2FZRJI4HYN%22%5D%2C%22locator%22%3A%226%22%7D%7D\">‚Äúrestricted‚Äù</span> <span class=\"citation\" data-citation=\"%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F10101446%2Fitems%2FZRJI4HYN%22%5D%2C%22locator%22%3A%226%22%7D%5D%2C%22properties%22%3A%7B%7D%7D\">(<span class=\"citation-item\">Vaswani Á≠â, 2017, p. 6</span>)</span> üî§restricted<br>Ëã± [r…™Ààstr…™kt…™d]<br>Áæé [r…™Ààstr…™kt…™d]<br>adj. ÔºàÂ§ßÂ∞èÊàñÊï∞ÈáèÔºâÊúâÈôêÁöÑÔºåÂæàÂ∞èÁöÑÔºõÔºàÊåáËÉΩÂÅöÁöÑ‰∫ãÔºâÊúâÈôêÁöÑÔºåÂèóÈôêÂà∂ÁöÑÔºõÂèóÔºàÊ≥ïËßÑÔºâÂà∂Á∫¶ÁöÑÔºåÂèóÊéßÂà∂ÁöÑÔºõ‰∏çÂØπÂÖ¨‰ºóÂºÄÊîæÁöÑÔºõÔºàÊñá‰ª∂Ôºâ‰øùÂØÜÁöÑÔºåÈôê‰∫éÂÜÖÈÉ®‰º†ÈòÖÁöÑÔºõÔºàÁóÖÊØíÁπÅÊÆñÈÄüÁéáÔºâË¢´ÈôêÂà∂ÁöÑÔºõÔºàDNAÔºâÂõ†ÈôêÂà∂ÈÖ∂ÈÖ∂ÂàáÁöÑ<br>v. ÈôêÂà∂ÔºåÈôêÂÆöÔºàÊï∞Èáè„ÄÅËåÉÂõ¥Á≠âÔºâÔºõÁ∫¶ÊùüÔºåÈôêÂà∂ÔºàË°åÂä®ÊàñÊ¥ªÂä®ÔºâÔºõÔºà‰ª•Ê≥ïËßÑÔºâÈôêÂà∂Ôºàrestrict ÁöÑËøáÂéªÂºèÂíåËøáÂéªÂàÜËØçÔºâüî§</p><p><span class=\"highlight\" data-annotation=\"%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F10101446%2Fitems%2FGXDZU4NV%22%2C%22annotationKey%22%3A%22SNC65WNL%22%2C%22color%22%3A%22%232ea8e5%22%2C%22pageLabel%22%3A%227%22%2C%22position%22%3A%7B%22pageIndex%22%3A6%2C%22rects%22%3A%5B%5B368.886%2C707.885%2C504.001%2C716.792%5D%2C%5B108%2C696.976%2C196.642%2C706.042%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F10101446%2Fitems%2FZRJI4HYN%22%5D%2C%22locator%22%3A%227%22%7D%7D\">‚ÄúThis would increase the maximum path length to O(n/r)‚Äù</span> <span class=\"citation\" data-citation=\"%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F10101446%2Fitems%2FZRJI4HYN%22%5D%2C%22locator%22%3A%227%22%7D%5D%2C%22properties%22%3A%7B%7D%7D\">(<span class=\"citation-item\">Vaswani Á≠â, 2017, p. 7</span>)</span> üî§Ëøô‰ºöÂ∞ÜÊúÄÂ§ßË∑ØÂæÑÈïøÂ∫¶Â¢ûÂä†Âà∞ O(n/r)üî§</p><p><span class=\"highlight\" data-annotation=\"%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F10101446%2Fitems%2FGXDZU4NV%22%2C%22annotationKey%22%3A%22XI7252GW%22%2C%22color%22%3A%22%232ea8e5%22%2C%22pageLabel%22%3A%227%22%2C%22position%22%3A%7B%22pageIndex%22%3A6%2C%22rects%22%3A%5B%5B107.641%2C680.588%2C504%2C689.654%5D%2C%5B108%2C669.679%2C143.265%2C678.745%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F10101446%2Fitems%2FZRJI4HYN%22%5D%2C%22locator%22%3A%227%22%7D%7D\">‚ÄúA single convolutional layer with kernel width k &lt; n does not connect all pairs of input and output positions‚Äù</span> <span class=\"citation\" data-citation=\"%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F10101446%2Fitems%2FZRJI4HYN%22%5D%2C%22locator%22%3A%227%22%7D%5D%2C%22properties%22%3A%7B%7D%7D\">(<span class=\"citation-item\">Vaswani Á≠â, 2017, p. 7</span>)</span> Âõ†‰∏∫Âç∑ÁßØÊìç‰ΩúÊòØÈÄöËøáÊªëÂä®Âç∑ÁßØÊ†∏Êù•ÊâßË°åÁöÑÔºåÂØπ‰∫éËæìÂÖ•ÁöÑÊØè‰∏™‰ΩçÁΩÆÔºåÂç∑ÁßØÊ†∏Â∞Ü‰∏éÂÖ∂ÈÉ®ÂàÜÂÉèÁ¥†Áõ∏‰πòÂπ∂Ê±ÇÂíåÔºåÁÑ∂ÂêéÂ∞ÜÁªìÊûúÊîæÁΩÆÂú®ËæìÂá∫ÁâπÂæÅÂõæÁöÑÂØπÂ∫î‰ΩçÁΩÆ‰∏ä„ÄÇ‰ΩÜÁî±‰∫éÂç∑ÁßØÊ†∏ÁöÑÂÆΩÂ∫¶ÊúâÈôêÔºåÂÆÉ‰∏ç‰ºö‰∏éËæìÂÖ•ÁöÑÊâÄÊúâÂÉèÁ¥†ÈÉΩÁõ∏‰πòÔºåÂõ†Ê≠§‰∏ç‰ºöËøûÊé•ÊâÄÊúâËæìÂÖ•ÂíåËæìÂá∫‰ΩçÁΩÆÂØπ„ÄÇ</p><p><span class=\"highlight\" data-annotation=\"%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F10101446%2Fitems%2FGXDZU4NV%22%2C%22annotationKey%22%3A%22T2L9WHU6%22%2C%22color%22%3A%22%232ea8e5%22%2C%22pageLabel%22%3A%227%22%2C%22position%22%3A%7B%22pageIndex%22%3A6%2C%22rects%22%3A%5B%5B259.993%2C669.679%2C505.242%2C678.745%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F10101446%2Fitems%2FZRJI4HYN%22%5D%2C%22locator%22%3A%227%22%7D%7D\">‚ÄúO(n/k) convolutional layers in the case of contiguous kernels,‚Äù</span> <span class=\"citation\" data-citation=\"%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F10101446%2Fitems%2FZRJI4HYN%22%5D%2C%22locator%22%3A%227%22%7D%5D%2C%22properties%22%3A%7B%7D%7D\">(<span class=\"citation-item\">Vaswani Á≠â, 2017, p. 7</span>)</span> üî§Âú®ËøûÁª≠ÂÜÖÊ†∏ÁöÑÊÉÖÂÜµ‰∏ãÔºåO(n/k) ‰∏™Âç∑ÁßØÂ±ÇÔºåüî§</p><p><span class=\"highlight\" data-annotation=\"%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F10101446%2Fitems%2FGXDZU4NV%22%2C%22annotationKey%22%3A%224RBKIK4A%22%2C%22color%22%3A%22%232ea8e5%22%2C%22pageLabel%22%3A%227%22%2C%22position%22%3A%7B%22pageIndex%22%3A6%2C%22rects%22%3A%5B%5B119.4%2C658.074%2C309.858%2C667.836%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F10101446%2Fitems%2FZRJI4HYN%22%5D%2C%22locator%22%3A%227%22%7D%7D\">‚ÄúO(logk(n)) in the case of dilated convolutions‚Äù</span> <span class=\"citation\" data-citation=\"%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F10101446%2Fitems%2FZRJI4HYN%22%5D%2C%22locator%22%3A%227%22%7D%5D%2C%22properties%22%3A%7B%7D%7D\">(<span class=\"citation-item\">Vaswani Á≠â, 2017, p. 7</span>)</span> üî§Âú®Êâ©Âº†Âç∑ÁßØÁöÑÊÉÖÂÜµ‰∏ã‰∏∫ O(logk(n))üî§</p><p><span class=\"highlight\" data-annotation=\"%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F10101446%2Fitems%2FGXDZU4NV%22%2C%22annotationKey%22%3A%227EVTG9AT%22%2C%22color%22%3A%22%232ea8e5%22%2C%22pageLabel%22%3A%227%22%2C%22position%22%3A%7B%22pageIndex%22%3A6%2C%22rects%22%3A%5B%5B280.698%2C647.86%2C503.999%2C656.767%5D%2C%5B108%2C636.951%2C504.351%2C646.017%5D%2C%5B108%2C626.042%2C262.473%2C636.65%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F10101446%2Fitems%2FZRJI4HYN%22%5D%2C%22locator%22%3A%227%22%7D%7D\">‚ÄúConvolutional layers are generally more expensive than recurrent layers, by a factor of k. Separable convolutions [6], however, decrease the complexity considerably, to O(k ¬∑ n ¬∑ d + n ¬∑ d2).‚Äù</span> <span class=\"citation\" data-citation=\"%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F10101446%2Fitems%2FZRJI4HYN%22%5D%2C%22locator%22%3A%227%22%7D%5D%2C%22properties%22%3A%7B%7D%7D\">(<span class=\"citation-item\">Vaswani Á≠â, 2017, p. 7</span>)</span> üî§Âç∑ÁßØÂ±ÇÈÄöÂ∏∏ÊØîÂæ™ÁéØÂ±ÇË¥µ k ÂÄç„ÄÇÁÑ∂ËÄåÔºåÂèØÂàÜÁ¶ªÂç∑ÁßØ [6] Â§ßÂ§ßÈôç‰Ωé‰∫ÜÂ§çÊùÇÊÄßÔºåËææÂà∞ O(k¬∑n¬∑d + n¬∑d2)„ÄÇüî§</p>\n</div>",
          "tags": [],
          "relations": {},
          "dateAdded": "2023-09-30T07:56:10Z",
          "dateModified": "2023-09-30T07:56:10Z",
          "uri": "http://zotero.org/users/10101446/items/X5TJU3WQ"
        }
      ],
      "citationKey": "vaswani2017-attention",
      "itemKey": "ZRJI4HYN",
      "libraryID": 1,
      "select": "zotero://select/library/items/ZRJI4HYN"
    },
    {
      "key": "3V7KMJ2D",
      "version": 192,
      "itemType": "preprint",
      "title": "Cumulative Reasoning with Large Language Models",
      "abstractNote": "While language models are powerful and versatile, they often fail to address highly complex problems. This is because solving complex problems requires deliberate thinking, which has been only minimally guided during training. In this paper, we propose a new method called Cumulative Reasoning (CR), which employs language models in a cumulative and iterative manner to emulate human thought processes. By decomposing tasks into smaller components, CR streamlines the problem-solving process, rendering it both more manageable and effective. For logical inference tasks, CR consistently outperforms existing methods with an improvement up to 9.3%, and achieves the astonishing accuracy of 98.04% on the curated FOLIO wiki dataset. In the context of the Game of 24, CR achieves an accuracy of 98%, which signiÔ¨Åes a substantial enhancement of 24% over the previous state-of-the-art method. Finally, on the MATH dataset, we establish new state-of-the-art results with 58.0% overall accuracy, surpassing the previous best approach by a margin of 4.2%, and achieving 43% relative improvement on the hardest level 5 problems (22.4% ‚Üí 32.1%) ‚Ä†.",
      "date": "2023-08-24",
      "language": "en",
      "libraryCatalog": "arXiv.org",
      "url": "http://arxiv.org/abs/2308.04371",
      "accessDate": "2023-09-05T06:30:28Z",
      "extra": "arXiv:2308.04371 [cs]",
      "repository": "arXiv",
      "archiveID": "arXiv:2308.04371",
      "creators": [
        {
          "firstName": "Yifan",
          "lastName": "Zhang",
          "creatorType": "author"
        },
        {
          "firstName": "Jingqin",
          "lastName": "Yang",
          "creatorType": "author"
        },
        {
          "firstName": "Yang",
          "lastName": "Yuan",
          "creatorType": "author"
        },
        {
          "firstName": "Andrew Chi-Chih",
          "lastName": "Yao",
          "creatorType": "author"
        }
      ],
      "tags": [
        {
          "tag": "Computer Science - Artificial Intelligence",
          "type": 1
        }
      ],
      "relations": [],
      "dateAdded": "2023-09-05T06:30:28Z",
      "dateModified": "2023-09-05T06:30:28Z",
      "uri": "http://zotero.org/users/10101446/items/3V7KMJ2D",
      "itemID": 81,
      "attachments": [
        {
          "itemType": "attachment",
          "title": "Zhang Á≠â - 2023 - Cumulative Reasoning with Large Language Models.pdf",
          "tags": [],
          "relations": [],
          "dateAdded": "2023-09-05T06:30:22Z",
          "dateModified": "2023-09-05T06:30:29Z",
          "uri": "http://zotero.org/users/10101446/items/IDMY76FY",
          "path": "C:\\Users\\gyh14\\Zotero\\storage\\IDMY76FY\\Zhang Á≠â - 2023 - Cumulative Reasoning with Large Language Models.pdf",
          "select": "zotero://select/library/items/IDMY76FY"
        }
      ],
      "notes": [],
      "citationKey": "zhangCumulativeReasoningLarge2023",
      "itemKey": "3V7KMJ2D",
      "libraryID": 1,
      "select": "zotero://select/library/items/3V7KMJ2D"
    },
    {
      "key": "2BE3HB69",
      "version": 550,
      "itemType": "journalArticle",
      "title": "Informer: Beyond Efficient Transformer for Long Sequence Time-Series Forecasting",
      "abstractNote": "Many real-world applications require the prediction of long sequence time-series, such as electricity consumption planning. Long sequence time-series forecasting (LSTF) demands a high prediction capacity of the model, which is the ability to capture precise long-range dependency coupling between output and input efÔ¨Åciently. Recent studies have shown the potential of Transformer to increase the prediction capacity. However, there are several severe issues with Transformer that prevent it from being directly applicable to LSTF, including quadratic time complexity, high memory usage, and inherent limitation of the encoder-decoder architecture. To address these issues, we design an efÔ¨Åcient transformer-based model for LSTF, named Informer, with three distinctive characteristics: (i) a ProbSparse self-attention mechanism, which achieves O(L log L) in time complexity and memory usage, and has comparable performance on sequences‚Äô dependency alignment. (ii) the self-attention distilling highlights dominating attention by halving cascading layer input, and efÔ¨Åciently handles extreme long input sequences. (iii) the generative style decoder, while conceptually simple, predicts the long time-series sequences at one forward operation rather than a step-by-step way, which drastically improves the inference speed of long-sequence predictions. Extensive experiments on four large-scale datasets demonstrate that Informer signiÔ¨Åcantly outperforms existing methods and provides a new solution to the LSTF problem.",
      "date": "2021-05-18",
      "language": "en",
      "shortTitle": "Informer",
      "libraryCatalog": "DOI.org (Crossref)",
      "url": "https://ojs.aaai.org/index.php/AAAI/article/view/17325",
      "accessDate": "2023-03-07T22:36:10Z",
      "volume": "35",
      "pages": "11106-11115",
      "publicationTitle": "Proceedings of the AAAI Conference on Artificial Intelligence",
      "DOI": "10.1609/aaai.v35i12.17325",
      "issue": "12",
      "journalAbbreviation": "AAAI",
      "ISSN": "2374-3468, 2159-5399",
      "creators": [
        {
          "firstName": "Haoyi",
          "lastName": "Zhou",
          "creatorType": "author"
        },
        {
          "firstName": "Shanghang",
          "lastName": "Zhang",
          "creatorType": "author"
        },
        {
          "firstName": "Jieqi",
          "lastName": "Peng",
          "creatorType": "author"
        },
        {
          "firstName": "Shuai",
          "lastName": "Zhang",
          "creatorType": "author"
        },
        {
          "firstName": "Jianxin",
          "lastName": "Li",
          "creatorType": "author"
        },
        {
          "firstName": "Hui",
          "lastName": "Xiong",
          "creatorType": "author"
        },
        {
          "firstName": "Wancai",
          "lastName": "Zhang",
          "creatorType": "author"
        }
      ],
      "tags": [],
      "relations": [],
      "dateAdded": "2023-03-07T22:36:10Z",
      "dateModified": "2023-10-14T11:25:11Z",
      "uri": "http://zotero.org/users/10101446/items/2BE3HB69",
      "itemID": 15,
      "attachments": [
        {
          "itemType": "attachment",
          "title": "Zhou Á≠â - 2021 - Informer Beyond Efficient Transformer for Long Se.pdf",
          "tags": [],
          "relations": [],
          "dateAdded": "2023-03-07T22:36:06Z",
          "dateModified": "2023-03-07T22:36:10Z",
          "uri": "http://zotero.org/users/10101446/items/ZVVAF6CE",
          "path": "C:\\Users\\gyh14\\Zotero\\storage\\ZVVAF6CE\\Zhou Á≠â - 2021 - Informer Beyond Efficient Transformer for Long Se.pdf",
          "select": "zotero://select/library/items/ZVVAF6CE"
        }
      ],
      "notes": [],
      "citationKey": "zhou2021-informer",
      "itemKey": "2BE3HB69",
      "libraryID": 1,
      "select": "zotero://select/library/items/2BE3HB69"
    }
  ]
}